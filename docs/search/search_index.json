{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyGnome: Python Library for Genome Annotations","text":"<p>PyGnome is a Python library for working with genomic annotations and sequences. It provides efficient data structures and parsers for common genomic file formats, making it easy to work with genomic data in Python.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Genomic Feature Models: Comprehensive object models for genes, transcripts, exons, variants, and more</li> <li>Efficient Feature Storage: Multiple implementations for fast genomic feature queries</li> <li>File Format Parsers: Support for FASTA/FASTQ, GFF/GTF, VCF, and MSI formats</li> <li>Sequence Handling: Memory-efficient representations of DNA and RNA sequences</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pygnome\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pathlib import Path\nfrom pygnome.parsers.genome_loader import GenomeLoader\n\n# Load a genome from GTF and FASTA files\nloader = GenomeLoader(genome_name=\"GRCh38\", species=\"Homo sapiens\")\ngenome = loader.load(\n    gtf_file=Path(\"path/to/annotations.gtf\"),\n    fasta_file=Path(\"path/to/genome.fa.gz\")\n)\n\n# Access genomic features\nfor gene in genome.genes.values():\n    print(f\"Gene: {gene.id} ({gene.name}) - {gene.chrom}:{gene.start}-{gene.end}\")\n\n    for transcript in gene.transcripts:\n        print(f\"  Transcript: {transcript.id} - Exons: {len(transcript.exons)}\")\n</code></pre>"},{"location":"#usage-examples","title":"Usage Examples","text":""},{"location":"#parsing-fasta-files","title":"Parsing FASTA Files","text":"<pre><code>from pathlib import Path\nfrom pygnome.parsers.fasta.fasta_parser import FastaParser\n\n# Parse a FASTA file\nparser = FastaParser(Path(\"path/to/sequences.fa\"))\nrecords = parser.load()\n\n# Access sequences\nfor record in records:\n    print(f\"Sequence: {record.identifier}\")\n    print(f\"Length: {len(record.sequence)}\")\n\n    # Convert to string if needed\n    seq_str = str(record.sequence)\n    print(f\"First 10 bases: {seq_str[:10]}\")\n\n# Load as dictionary for quick access by identifier\nsequences = FastaParser(Path(\"path/to/sequences.fa\")).load_as_dict()\nmy_seq = sequences[\"chr1\"].sequence\n</code></pre>"},{"location":"#parsing-gffgtf-files","title":"Parsing GFF/GTF Files","text":"<pre><code>from pathlib import Path\nfrom pygnome.parsers.gff.gff3_parser import Gff3Parser\nfrom pygnome.parsers.gff.gtf_parser import GtfParser\n\n# Parse a GFF3 file\ngff_parser = Gff3Parser(Path(\"path/to/annotations.gff3\"))\nfor record in gff_parser:\n    print(f\"{record.type}: {record.chrom}:{record.start}-{record.end}\")\n    print(f\"Attributes: {record.attributes}\")\n\n# Parse a GTF file\ngtf_parser = GtfParser(Path(\"path/to/annotations.gtf\"))\nfor record in gtf_parser:\n    if record.type == \"gene\":\n        gene_id = record.attributes.get(\"gene_id\")\n        gene_name = record.attributes.get(\"gene_name\")\n        print(f\"Gene: {gene_id} ({gene_name}) - {record.chrom}:{record.start}-{record.end}\")\n</code></pre>"},{"location":"#parsing-vcf-files","title":"Parsing VCF Files","text":"<pre><code>from pathlib import Path\nfrom pygnome.parsers.vcf.vcf_reader import VcfReader\n\n# Open a VCF file\nwith VcfReader(Path(\"path/to/variants.vcf\")) as reader:\n    # Get sample names\n    samples = reader.get_samples()\n    print(f\"Samples: {samples}\")\n\n    # Iterate through records\n    for record in reader:\n        print(f\"Record: {record.get_chrom()}:{record.get_pos()} {record.get_ref()}&gt;{','.join(record.get_alt())}\")\n\n        # Create variant objects from the record using VariantFactory\n        for variant in record:  # Uses VariantFactory internally\n            print(f\"Variant: {variant}\")\n\n        # Access genotypes\n        genotypes = record.get_genotypes()\n        for i, genotype in enumerate(genotypes):\n            print(f\"  {samples[i]}: {genotype}\")\n\n    # Query a specific region\n    for record in reader.fetch(\"chr1\", 1000000, 2000000):\n        for variant in record:\n            print(f\"Region variant: {variant}\")\n</code></pre>"},{"location":"#using-feature-stores","title":"Using Feature Stores","text":"<pre><code>from pygnome.feature_store.genomic_feature_store import GenomicFeatureStore, StoreType\nfrom pygnome.genomics.gene import Gene\nfrom pathlib import Path\n\n# Create a feature store using interval trees (default)\nstore = GenomicFeatureStore()\n\n# Or choose a different implementation\nbinned_store = GenomicFeatureStore(store_type=StoreType.BINNED, bin_size=100000)\nbrute_force_store = GenomicFeatureStore(store_type=StoreType.BRUTE_FORCE)\n\n# Add features to the store\nwith store:  # Use context manager to ensure proper indexing\n    for gene in genome.genes.values():\n        store.add(gene)\n\n        # Add transcripts and other features\n        for transcript in gene.transcripts:\n            store.add(transcript)\n            for exon in transcript.exons:\n                store.add(exon)\n\n# Query features\nfeatures_at_position = store.get_by_position(\"chr1\", 1000000)\nfeatures_in_range = store.get_by_interval(\"chr1\", 1000000, 2000000)\nnearest_feature = store.get_nearest(\"chr1\", 1500000)\n\n# Save and load the store\nstore.save(Path(\"path/to/store.pkl\"))\nloaded_store = GenomicFeatureStore.load(Path(\"path/to/store.pkl\"))\n</code></pre>"},{"location":"#working-with-dnarna-sequences","title":"Working with DNA/RNA Sequences","text":"<pre><code>from pygnome.sequences.dna_string import DnaString\nfrom pygnome.sequences.rna_string import RnaString\n\n# Create a DNA sequence\ndna = DnaString(\"ATGCATGCATGC\")\nprint(f\"Length: {len(dna)}\")\nprint(f\"GC content: {dna.gc_content()}\")\n\n# Get a subsequence\nsubseq = dna[3:9]  # Returns a new DnaString\n\n# Complement and reverse complement\ncomp = dna.complement()\nrev_comp = dna.reverse_complement()\n\n# Transcribe DNA to RNA\nrna = dna.transcribe()  # Returns an RnaString\n\n# Create an RNA sequence\nrna = RnaString(\"AUGCAUGCAUGC\")\n\n# Translate RNA to protein\nprotein = rna.translate()\nprint(f\"Protein: {protein}\")\n</code></pre>"},{"location":"#advanced-usage","title":"Advanced Usage","text":""},{"location":"#loading-a-complete-genome","title":"Loading a Complete Genome","text":"<pre><code>from pathlib import Path\nfrom pygnome.parsers.genome_loader import GenomeLoader\n\n# Create a genome loader\nloader = GenomeLoader(\n    genome_name=\"GRCh38\",\n    species=\"Homo sapiens\",\n    verbose=True  # Print progress information\n)\n\n# Load genome structure and sequence\ngenome = loader.load(\n    gtf_file=Path(\"path/to/annotations.gtf\"),\n    fasta_file=Path(\"path/to/genome.fa.gz\")\n)\n\n# Access genome components\nprint(f\"Genome: {genome.name} ({genome.species})\")\nprint(f\"Chromosomes: {len(genome.chromosomes)}\")\nprint(f\"Genes: {len(genome.genes)}\")\n\n# Get a specific chromosome\nchr1 = genome.chromosomes.get(\"chr1\")\nif chr1:\n    print(f\"Chromosome: {chr1.name}, Length: {chr1.length}\")\n    print(f\"Genes on chr1: {len(chr1.genes)}\")\n\n    # Get sequence for a region\n    region_seq = chr1.get_sequence(1000000, 1000100)\n    print(f\"Sequence: {region_seq}\")\n\n# Get a specific gene\ntp53 = genome.genes.get(\"ENSG00000141510\")\nif tp53:\n    print(f\"TP53: {tp53.chrom}:{tp53.start}-{tp53.end} ({tp53.strand})\")\n\n    # Get gene sequence\n    gene_seq = tp53.get_sequence()\n\n    # Get coding sequence\n    for transcript in tp53.transcripts:\n        cds_seq = transcript.get_coding_sequence()\n        protein = transcript.get_protein()\n        print(f\"Transcript {transcript.id}: CDS length: {len(cds_seq)}, Protein length: {len(protein)}\")\n</code></pre>"},{"location":"#working-with-msi-sites","title":"Working with MSI Sites","text":"<pre><code>from pathlib import Path\nfrom pygnome.parsers.msi.msi_sites_reader import MsiSitesReader\nfrom pygnome.feature_store.genomic_feature_store import GenomicFeatureStore, StoreType\n\n# Parse MSI sites file\nreader = MsiSitesReader(Path(\"path/to/msi_sites.txt\"))\nmsi_sites = reader.read_all()\n\n# Create a specialized MSI store\nmsi_store = GenomicFeatureStore(store_type=StoreType.MSI)\n\n# Add MSI sites to the store\nwith msi_store:\n    for site in msi_sites:\n        msi_store.add(site)\n\n# Query MSI sites\nsites_in_region = msi_store.get_by_interval(\"chr1\", 1000000, 2000000)\nfor site in sites_in_region:\n    print(f\"MSI site: {site.chrom}:{site.start}-{site.end}, Repeat: {site.repeat_unit}\")\n</code></pre>"},{"location":"#performance-considerations","title":"Performance Considerations","text":"<p>PyGnome offers multiple feature store implementations with different performance characteristics:</p> <ul> <li>IntervalTreeStore: Best for random access queries (default)</li> <li>BinnedGenomicStore: Good balance between memory usage and query speed</li> <li>BruteForceFeatureStore: Lowest memory usage but slower queries</li> <li>MsiChromosomeStore: Specialized for MSI sites</li> </ul> <p>For large genomes, consider:</p> <ol> <li>Using the context manager pattern when adding features to ensure proper indexing</li> <li>Calling <code>store.trim()</code> to reduce memory usage before serialization</li> <li>Saving the populated store to disk with <code>store.save()</code> for faster loading in future sessions</li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please feel free to submit a Pull Request.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>genomics</li> <li>parsers</li> <li>sequences</li> <li>feature_store</li> </ul>"},{"location":"api/feature_store/","title":"pygnome.feature_store","text":"<p>Feature store module for efficient genomic feature storage and search.</p>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore","title":"<code>BinnedGenomicStore</code>","text":"<p>               Bases: <code>ChromosomeFeatureStore</code></p> <p>Store genomic features using a memory-efficient binning approach.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>class BinnedGenomicStore(ChromosomeFeatureStore):\n    \"\"\"Store genomic features using a memory-efficient binning approach.\"\"\"\n\n    def __init__(self, chromosome: str, bin_size: int = DEFAULT_BIN_SIZE):\n        \"\"\"\n        Initialize a binned genomic store.\n\n        Args:\n            chromosome: Name of the chromosome\n            bin_size: Size of each bin in base pairs\n        \"\"\"\n        super().__init__(chromosome=chromosome)\n        self.bin_size = bin_size\n\n        # Use dictionary of numpy arrays for memory efficiency\n        # Each key is a bin_id, and the value is a numpy array of feature indices\n        self.bins: dict[int, np.ndarray] = {}\n\n        # Track features per bin for efficient array sizing\n        self._bin_counts: dict[int, int] = {}\n\n        # Buffer for collecting indices before creating arrays\n        self._bin_buffers: dict[int, list[int]] = {}\n\n        # Threshold for converting buffer to array\n        self._buffer_threshold = 100\n\n    def _get_bin_ids(self, start: int, end: int) -&gt; set[int]:\n        \"\"\"Get all bin IDs that this range spans.\"\"\"\n        start_bin = start // self.bin_size\n        # Special case for zero-length features\n        if start == end:\n            return {start_bin}\n        end_bin = (end - 1) // self.bin_size\n        return set(range(start_bin, end_bin + 1))\n\n    def _add_to_bin(self, bin_id: int, feature_idx: int) -&gt; None:\n        \"\"\"Add a feature index to a bin, using buffer for small counts.\"\"\"\n        # Initialize buffer if needed\n        if bin_id not in self._bin_buffers:\n            self._bin_buffers[bin_id] = []\n            self._bin_counts[bin_id] = 0\n\n        # Add to buffer\n        self._bin_buffers[bin_id].append(feature_idx)\n        self._bin_counts[bin_id] += 1\n\n        # Convert buffer to array if it reaches threshold\n        if len(self._bin_buffers[bin_id]) &gt;= self._buffer_threshold:\n            self._convert_buffer_to_array(bin_id)\n\n    def _convert_buffer_to_array(self, bin_id: int) -&gt; None:\n        \"\"\"Convert a bin buffer to a numpy array for memory efficiency.\"\"\"\n        if bin_id in self._bin_buffers and self._bin_buffers[bin_id]:\n            # Create array from buffer\n            if bin_id in self.bins:\n                # Append to existing array\n                old_array = self.bins[bin_id]\n                new_array = np.concatenate([\n                    old_array,\n                    np.array(self._bin_buffers[bin_id], dtype=np.int32)\n                ])\n                self.bins[bin_id] = new_array\n            else:\n                # Create new array\n                self.bins[bin_id] = np.array(self._bin_buffers[bin_id], dtype=np.int32)\n\n            # Clear buffer\n            self._bin_buffers[bin_id] = []\n\n    def add(self, feature: GenomicFeature) -&gt; None:\n        \"\"\"Add a feature to the binned store.\"\"\"\n        super().add(feature)\n        feature_idx = len(self.features) - 1\n\n        # Add to all bins this feature spans\n        for bin_id in self._get_bin_ids(feature.start, feature.end):\n            self._add_to_bin(bin_id, feature_idx)\n\n    def _get_bin_indices(self, bin_id: int) -&gt; np.ndarray | None:\n        \"\"\"Get all feature indices for a bin.\"\"\"\n        return self.bins.get(bin_id)\n\n    def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features at a specific position.\"\"\"\n        bin_id = position // self.bin_size\n\n        # Get indices from this bin\n        indices = self._get_bin_indices(bin_id)\n        if indices is None:\n            return []\n\n        # Filter features that contain the position\n        result = []\n        for idx in indices:\n            feature: GenomicFeature = self.features[idx]\n            if feature.intersects_point(position):\n                result.append(feature)\n        return result\n\n    def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features that overlap with the given range.\"\"\"\n        bin_ids = self._get_bin_ids(start, end)\n\n        # Get unique feature indices from all relevant bins\n        feature_indices = set()\n        for bin_id in bin_ids:\n            indices = self._get_bin_indices(bin_id)\n            if indices is not None:\n                feature_indices.update(indices)\n\n        # Filter features that actually overlap\n        result = []\n        for idx in feature_indices:\n            feature = self.features[idx]\n            if feature.intersects_interval(start, end):\n                result.append(feature)\n        return result\n\n    def index_build_end(self) -&gt; None:\n        \"\"\"Finalize the index build process.\"\"\"\n        super().index_build_end()\n        # Convert all remaining buffers to arrays\n        for bin_id in list(self._bin_buffers.keys()):\n            if self._bin_buffers[bin_id]:\n                self._convert_buffer_to_array(bin_id)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the binned genomic store.\"\"\"\n        # Get basic info from parent class\n        status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n\n        # Calculate bin statistics\n        bin_count = len(self.bins)\n        avg_features_per_bin = len(self.features) / max(1, bin_count) if bin_count &gt; 0 else 0\n\n        # Find most populated bins\n        bin_sizes = {bin_id: len(indices) for bin_id, indices in self.bins.items()}\n        top_bins = sorted(bin_sizes.items(), key=lambda x: x[1], reverse=True)[:3] if bin_sizes else []\n\n        # Sample of features\n        sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n        sample = self.features[:sample_size] if self.features else []\n        sample_str = \"\"\n        if sample:\n            sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n        # Bin statistics\n        bin_stats = \"\"\n        if top_bins:\n            bin_stats = f\", top bins: {', '.join(f'bin_{bin_id}({count})' for bin_id, count in top_bins)}\"\n\n        return (f\"BinnedGenomicStore(chromosome='{self.chromosome}', features={len(self.features)}, \"\n                f\"status={status}, bin_size={self.bin_size}, bins={bin_count}, \"\n                f\"avg_features_per_bin={avg_features_per_bin:.1f}{bin_stats}{sample_str})\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the binned genomic store.\"\"\"\n        return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.__init__","title":"<code>__init__(chromosome, bin_size=DEFAULT_BIN_SIZE)</code>","text":"<p>Initialize a binned genomic store.</p> <p>Parameters:</p> Name Type Description Default <code>chromosome</code> <code>str</code> <p>Name of the chromosome</p> required <code>bin_size</code> <code>int</code> <p>Size of each bin in base pairs</p> <code>DEFAULT_BIN_SIZE</code> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def __init__(self, chromosome: str, bin_size: int = DEFAULT_BIN_SIZE):\n    \"\"\"\n    Initialize a binned genomic store.\n\n    Args:\n        chromosome: Name of the chromosome\n        bin_size: Size of each bin in base pairs\n    \"\"\"\n    super().__init__(chromosome=chromosome)\n    self.bin_size = bin_size\n\n    # Use dictionary of numpy arrays for memory efficiency\n    # Each key is a bin_id, and the value is a numpy array of feature indices\n    self.bins: dict[int, np.ndarray] = {}\n\n    # Track features per bin for efficient array sizing\n    self._bin_counts: dict[int, int] = {}\n\n    # Buffer for collecting indices before creating arrays\n    self._bin_buffers: dict[int, list[int]] = {}\n\n    # Threshold for converting buffer to array\n    self._buffer_threshold = 100\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the binned genomic store.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the binned genomic store.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the binned genomic store.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the binned genomic store.\"\"\"\n    # Get basic info from parent class\n    status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n\n    # Calculate bin statistics\n    bin_count = len(self.bins)\n    avg_features_per_bin = len(self.features) / max(1, bin_count) if bin_count &gt; 0 else 0\n\n    # Find most populated bins\n    bin_sizes = {bin_id: len(indices) for bin_id, indices in self.bins.items()}\n    top_bins = sorted(bin_sizes.items(), key=lambda x: x[1], reverse=True)[:3] if bin_sizes else []\n\n    # Sample of features\n    sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n    sample = self.features[:sample_size] if self.features else []\n    sample_str = \"\"\n    if sample:\n        sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n    # Bin statistics\n    bin_stats = \"\"\n    if top_bins:\n        bin_stats = f\", top bins: {', '.join(f'bin_{bin_id}({count})' for bin_id, count in top_bins)}\"\n\n    return (f\"BinnedGenomicStore(chromosome='{self.chromosome}', features={len(self.features)}, \"\n            f\"status={status}, bin_size={self.bin_size}, bins={bin_count}, \"\n            f\"avg_features_per_bin={avg_features_per_bin:.1f}{bin_stats}{sample_str})\")\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.add","title":"<code>add(feature)</code>","text":"<p>Add a feature to the binned store.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def add(self, feature: GenomicFeature) -&gt; None:\n    \"\"\"Add a feature to the binned store.\"\"\"\n    super().add(feature)\n    feature_idx = len(self.features) - 1\n\n    # Add to all bins this feature spans\n    for bin_id in self._get_bin_ids(feature.start, feature.end):\n        self._add_to_bin(bin_id, feature_idx)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.get_by_interval","title":"<code>get_by_interval(start, end)</code>","text":"<p>Get all features that overlap with the given range.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features that overlap with the given range.\"\"\"\n    bin_ids = self._get_bin_ids(start, end)\n\n    # Get unique feature indices from all relevant bins\n    feature_indices = set()\n    for bin_id in bin_ids:\n        indices = self._get_bin_indices(bin_id)\n        if indices is not None:\n            feature_indices.update(indices)\n\n    # Filter features that actually overlap\n    result = []\n    for idx in feature_indices:\n        feature = self.features[idx]\n        if feature.intersects_interval(start, end):\n            result.append(feature)\n    return result\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.get_by_position","title":"<code>get_by_position(position)</code>","text":"<p>Get all features at a specific position.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features at a specific position.\"\"\"\n    bin_id = position // self.bin_size\n\n    # Get indices from this bin\n    indices = self._get_bin_indices(bin_id)\n    if indices is None:\n        return []\n\n    # Filter features that contain the position\n    result = []\n    for idx in indices:\n        feature: GenomicFeature = self.features[idx]\n        if feature.intersects_point(position):\n            result.append(feature)\n    return result\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BinnedGenomicStore.index_build_end","title":"<code>index_build_end()</code>","text":"<p>Finalize the index build process.</p> Source code in <code>pygnome/feature_store/binned_store.py</code> <pre><code>def index_build_end(self) -&gt; None:\n    \"\"\"Finalize the index build process.\"\"\"\n    super().index_build_end()\n    # Convert all remaining buffers to arrays\n    for bin_id in list(self._bin_buffers.keys()):\n        if self._bin_buffers[bin_id]:\n            self._convert_buffer_to_array(bin_id)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore","title":"<code>BruteForceFeatureStore</code>","text":"<p>               Bases: <code>ChromosomeFeatureStore</code></p> <p>A naive brute-force implementation for genomic feature storage. This is not memory efficient and is not recommended for large datasets. It is primarily for testing purposes.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>class BruteForceFeatureStore(ChromosomeFeatureStore):\n    \"\"\"\n    A naive brute-force implementation for genomic feature storage.\n    This is not memory efficient and is not recommended for large datasets.\n    It is primarily for testing purposes.\n    \"\"\"\n\n    def __init__(self, chromosome: str):\n        super().__init__(chromosome)\n\n    def add(self, feature: GenomicFeature) -&gt; None:\n        \"\"\"Add a feature to this chromosome's store.\"\"\"\n        self.features.append(feature)\n\n    def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features at a specific position.\"\"\"\n        return [f for f in self.features if f.intersects_point(position)]\n\n    def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features that overlap with the given range.\"\"\"\n        return [f for f in self.features if f.intersects_interval(start, end)]\n\n    def get_nearest(self, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n        \"\"\"Get the nearest feature to a specific position.\"\"\"\n        nearest_feature = None\n        min_distance = max_distance\n\n        for feature in self.features:\n            distance = feature.distance(position)\n            if distance &lt; min_distance:\n                min_distance = distance\n                nearest_feature = feature\n        return nearest_feature\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the brute force feature store.\"\"\"\n        status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n\n        # Sample of features\n        sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n        sample = self.features[:sample_size] if self.features else []\n        sample_str = \"\"\n        if sample:\n            sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n        return (f\"BruteForceFeatureStore(chromosome='{self.chromosome}', features={len(self.features)}, \"\n                f\"status={status}{sample_str})\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the brute force feature store.\"\"\"\n        return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the brute force feature store.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the brute force feature store.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the brute force feature store.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the brute force feature store.\"\"\"\n    status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n\n    # Sample of features\n    sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n    sample = self.features[:sample_size] if self.features else []\n    sample_str = \"\"\n    if sample:\n        sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n    return (f\"BruteForceFeatureStore(chromosome='{self.chromosome}', features={len(self.features)}, \"\n            f\"status={status}{sample_str})\")\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore.add","title":"<code>add(feature)</code>","text":"<p>Add a feature to this chromosome's store.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>def add(self, feature: GenomicFeature) -&gt; None:\n    \"\"\"Add a feature to this chromosome's store.\"\"\"\n    self.features.append(feature)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore.get_by_interval","title":"<code>get_by_interval(start, end)</code>","text":"<p>Get all features that overlap with the given range.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features that overlap with the given range.\"\"\"\n    return [f for f in self.features if f.intersects_interval(start, end)]\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore.get_by_position","title":"<code>get_by_position(position)</code>","text":"<p>Get all features at a specific position.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features at a specific position.\"\"\"\n    return [f for f in self.features if f.intersects_point(position)]\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.BruteForceFeatureStore.get_nearest","title":"<code>get_nearest(position, max_distance=MAX_DISTANCE)</code>","text":"<p>Get the nearest feature to a specific position.</p> Source code in <code>pygnome/feature_store/brute_force_store.py</code> <pre><code>def get_nearest(self, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n    \"\"\"Get the nearest feature to a specific position.\"\"\"\n    nearest_feature = None\n    min_distance = max_distance\n\n    for feature in self.features:\n        distance = feature.distance(position)\n        if distance &lt; min_distance:\n            min_distance = distance\n            nearest_feature = feature\n    return nearest_feature\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore","title":"<code>ChromosomeFeatureStore</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for chromosome-specific genomic feature storage. It has a list of features and provides methods to add and query them.</p> <p>Sub-classes typically implement more efficient search mechanisms, by adding an index to the features.</p> Usage <p>chrom_store = ChromosomeFeatureStore(\"chr1\")</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>class ChromosomeFeatureStore(ABC):\n    \"\"\"\n    Base class for chromosome-specific genomic feature storage.\n    It has a list of features and provides methods to add and query them.\n\n    Sub-classes typically implement more efficient search mechanisms, by adding an index to the features.\n\n    Usage:\n        chrom_store = ChromosomeFeatureStore(\"chr1\")\n\n        # When adding features you can use in a context manager to ensure index build mode is active\n        with chrom_store:\n            for feature in features:\n                chrom_store.add(feature)\n\n        # Alternatively, you can call index_build_start() and index_build_end() manually\n        chrom_store.index_build_start()\n        for feature in features:\n            chrom_store.add(feature)\n        chrom_store.index_build_end()\n    \"\"\"\n\n    def __init__(self, chromosome: str) -&gt; None:\n        self.features: list[GenomicFeature] = []\n        self.index_build_mode = False\n        self.index_finished = False\n        self.chromosome = chromosome\n\n    def add(self, feature: GenomicFeature) -&gt; None:\n        \"\"\"Add a feature to this chromosome's store.\"\"\"\n        if not self.index_build_mode:\n            raise RuntimeError(\"Index build mode is not active. Call index_build_start() before adding features.\")\n        self.features.append(feature)\n\n    @abstractmethod\n    def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features at a specific position.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features that overlap with the given range.\"\"\"\n        pass\n\n    def get_features(self) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features.\"\"\"\n        return self.features\n\n    def __getitem__(self, index: int) -&gt; GenomicFeature:\n        \"\"\"Get all features at a specific index.\"\"\"\n        return self.features[index]\n\n\n    def get_nearest(self, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n        \"\"\"Get the nearest feature to the given position.\"\"\"\n        # Start with a small window and expand until we find features\n        window = 1\n        while window &lt;= max_distance:\n            features = self.get_by_interval(position - window, position + window)\n            if features:\n                # Find the feature with the smallest distance to the position\n                closest_feature = features[0]\n                min_distance = closest_feature.distance(position)\n                for feature in features:\n                    distance = feature.distance(position)\n                    if distance &lt; min_distance:\n                        min_distance = distance\n                        closest_feature = feature\n                return closest_feature\n            window *= 2        \n        return None\n\n    def index_build_start(self) -&gt; None:\n        \"\"\" This method must be called to build the index before adding features. \"\"\"\n        self.index_build_mode = True\n        self.index_finished = False\n\n    def index_build_end(self) -&gt; None:\n        \"\"\" This method must be called to finish building the index, after adding features, but before quering. \"\"\"\n        self.index_build_mode = False\n        self.index_finished = True\n\n    def __enter__(self):\n        \"\"\"Enter the context manager.\"\"\"\n        self.index_build_start()\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Exit the context manager.\"\"\"\n        self.index_build_end()\n\n    def __len__(self) -&gt; int:\n        \"\"\"Get the number of features in this chromosome's store.\"\"\"\n        return len(self.features)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the chromosome feature store.\"\"\"\n        status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n        sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n        sample = self.features[:sample_size] if self.features else []\n\n        sample_str = \"\"\n        if sample:\n            sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n        return f\"ChromosomeFeatureStore(chromosome='{self.chromosome}', features={len(self.features)}, status={status}{sample_str})\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the chromosome feature store.\"\"\"\n        return self.__str__()\n\n    def trim(self) -&gt; None:\n        \"\"\"\n        Trim internal data structures to reduce memory usage.\n\n        This method should be implemented by subclasses to reduce memory usage\n        before serialization. The base implementation does nothing since the\n        standard list-based storage doesn't have excess allocation.\n        \"\"\"\n        # Base implementation does nothing\n        pass\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore--when-adding-features-you-can-use-in-a-context-manager-to-ensure-index-build-mode-is-active","title":"When adding features you can use in a context manager to ensure index build mode is active","text":"<p>with chrom_store:     for feature in features:         chrom_store.add(feature)</p>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore--alternatively-you-can-call-index_build_start-and-index_build_end-manually","title":"Alternatively, you can call index_build_start() and index_build_end() manually","text":"<p>chrom_store.index_build_start() for feature in features:     chrom_store.add(feature) chrom_store.index_build_end()</p>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter the context manager.\"\"\"\n    self.index_build_start()\n    return self\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Exit the context manager.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def __exit__(self, exc_type, exc_value, traceback):\n    \"\"\"Exit the context manager.\"\"\"\n    self.index_build_end()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Get all features at a specific index.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def __getitem__(self, index: int) -&gt; GenomicFeature:\n    \"\"\"Get all features at a specific index.\"\"\"\n    return self.features[index]\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of features in this chromosome's store.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the number of features in this chromosome's store.\"\"\"\n    return len(self.features)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the chromosome feature store.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the chromosome feature store.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the chromosome feature store.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the chromosome feature store.\"\"\"\n    status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n    sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n    sample = self.features[:sample_size] if self.features else []\n\n    sample_str = \"\"\n    if sample:\n        sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n    return f\"ChromosomeFeatureStore(chromosome='{self.chromosome}', features={len(self.features)}, status={status}{sample_str})\"\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.add","title":"<code>add(feature)</code>","text":"<p>Add a feature to this chromosome's store.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def add(self, feature: GenomicFeature) -&gt; None:\n    \"\"\"Add a feature to this chromosome's store.\"\"\"\n    if not self.index_build_mode:\n        raise RuntimeError(\"Index build mode is not active. Call index_build_start() before adding features.\")\n    self.features.append(feature)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.get_by_interval","title":"<code>get_by_interval(start, end)</code>  <code>abstractmethod</code>","text":"<p>Get all features that overlap with the given range.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>@abstractmethod\ndef get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features that overlap with the given range.\"\"\"\n    pass\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.get_by_position","title":"<code>get_by_position(position)</code>  <code>abstractmethod</code>","text":"<p>Get all features at a specific position.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>@abstractmethod\ndef get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features at a specific position.\"\"\"\n    pass\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.get_features","title":"<code>get_features()</code>","text":"<p>Get all features.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def get_features(self) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features.\"\"\"\n    return self.features\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.get_nearest","title":"<code>get_nearest(position, max_distance=MAX_DISTANCE)</code>","text":"<p>Get the nearest feature to the given position.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def get_nearest(self, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n    \"\"\"Get the nearest feature to the given position.\"\"\"\n    # Start with a small window and expand until we find features\n    window = 1\n    while window &lt;= max_distance:\n        features = self.get_by_interval(position - window, position + window)\n        if features:\n            # Find the feature with the smallest distance to the position\n            closest_feature = features[0]\n            min_distance = closest_feature.distance(position)\n            for feature in features:\n                distance = feature.distance(position)\n                if distance &lt; min_distance:\n                    min_distance = distance\n                    closest_feature = feature\n            return closest_feature\n        window *= 2        \n    return None\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.index_build_end","title":"<code>index_build_end()</code>","text":"<p>This method must be called to finish building the index, after adding features, but before quering.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def index_build_end(self) -&gt; None:\n    \"\"\" This method must be called to finish building the index, after adding features, but before quering. \"\"\"\n    self.index_build_mode = False\n    self.index_finished = True\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.index_build_start","title":"<code>index_build_start()</code>","text":"<p>This method must be called to build the index before adding features.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def index_build_start(self) -&gt; None:\n    \"\"\" This method must be called to build the index before adding features. \"\"\"\n    self.index_build_mode = True\n    self.index_finished = False\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.ChromosomeFeatureStore.trim","title":"<code>trim()</code>","text":"<p>Trim internal data structures to reduce memory usage.</p> <p>This method should be implemented by subclasses to reduce memory usage before serialization. The base implementation does nothing since the standard list-based storage doesn't have excess allocation.</p> Source code in <code>pygnome/feature_store/chromosome_feature_store.py</code> <pre><code>def trim(self) -&gt; None:\n    \"\"\"\n    Trim internal data structures to reduce memory usage.\n\n    This method should be implemented by subclasses to reduce memory usage\n    before serialization. The base implementation does nothing since the\n    standard list-based storage doesn't have excess allocation.\n    \"\"\"\n    # Base implementation does nothing\n    pass\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore","title":"<code>GenomicFeatureStore</code>","text":"<p>               Bases: <code>GenomicFeatureStoreProtocol</code></p> <p>Implementation of the genomic feature store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>class GenomicFeatureStore(GenomicFeatureStoreProtocol):\n    \"\"\"Implementation of the genomic feature store.\"\"\"\n\n    def __init__(self, store_type: StoreType | str = StoreType.INTERVAL_TREE, bin_size: int = 100000):\n        \"\"\"\n        Initialize the genomic feature store.\n\n        Args:\n            store_type: Type of store to use\n            bin_size: Size of bins for the binned store\n        \"\"\"\n        self.chromosomes: dict[str, ChromosomeFeatureStore] = {}\n\n        if isinstance(store_type, str):\n            try:\n                self.store_type = StoreType(store_type)\n            except ValueError:\n                raise ValueError(f\"Unknown store type: {store_type}\")\n        else:\n            self.store_type = store_type\n\n        self.bin_size = bin_size\n\n    def __enter__(self):\n        \"\"\"Enter the context manager when adding features\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Exit the context manager after adding features, ensures all indeces are built\"\"\"\n        # No special cleanup needed for this store\n        for chrom in self.chromosomes.values():\n            chrom.index_build_end()\n        return False\n\n    def _get_or_create_chrom_store(self, chrom: str) -&gt; ChromosomeFeatureStore:\n        \"\"\"Get or create a chromosome store.\"\"\"\n        if chrom not in self.chromosomes:\n            match self.store_type:\n                case StoreType.INTERVAL_TREE:\n                    self.chromosomes[chrom] = IntervalTreeStore(chrom)\n                case StoreType.BINNED:\n                    self.chromosomes[chrom] = BinnedGenomicStore(chrom, self.bin_size)\n                case StoreType.BRUTE_FORCE:\n                    self.chromosomes[chrom] = BruteForceFeatureStore(chrom)\n                case StoreType.MSI:\n                    self.chromosomes[chrom] = MsiChromosomeStore(chrom)\n                case _:\n                    raise ValueError(f\"Unknown store type: {self.store_type}\")\n            # Make sure the chromosome store is in 'index build' mode\n            self.chromosomes[chrom].index_build_start()\n        return self.chromosomes[chrom]\n\n    def add(self, feature: GenomicFeature) -&gt; None:\n        \"\"\"Add a genomic feature to the store.\"\"\"\n        chrom_store = self._get_or_create_chrom_store(feature.chrom)\n        chrom_store.add(feature)\n\n    def add_features(self, features: list[GenomicFeature]) -&gt; None:\n        \"\"\"Add multiple genomic features to the store.\"\"\"\n        for feature in features:\n            self.add(feature)\n\n    def get_by_position(self, chrom: str, position: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features at a specific position.\"\"\"\n        if chrom not in self.chromosomes:\n            return []\n        return self.chromosomes[chrom].get_by_position(position)\n\n    def get_by_interval(self, chrom: str, start: int, end: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features that overlap with the given range.\"\"\"\n        if chrom not in self.chromosomes:\n            return []\n        return self.chromosomes[chrom].get_by_interval(start, end)\n\n    def get_nearest(self, chrom: str, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n        \"\"\"Get the nearest feature to the given position.\"\"\"\n        if chrom not in self.chromosomes:\n            return None\n        return self.chromosomes[chrom].get_nearest(position, max_distance)\n\n    def get_chromosomes(self) -&gt; list[str]:\n        \"\"\"Get all chromosome names in the store.\"\"\"\n        return list(self.chromosomes.keys())\n\n    def __getitem__(self, chrom):\n        return self.chromosomes.get(chrom)\n\n    def get_feature_count(self, chrom: str | None = None) -&gt; int:\n        \"\"\"\n        Get the number of features in the store.\n\n        Args:\n            chrom: If provided, count only features in this chromosome\n        \"\"\"\n        if chrom is not None:\n            if chrom not in self.chromosomes:\n                return 0\n            return len(self.chromosomes[chrom].features)\n\n        # Count across all chromosomes\n        return sum(len(store) for store in self.chromosomes.values())\n\n    def __iterator__(self):\n        \"\"\"Iterate over all features in the store.\"\"\"\n        return self\n\n    def __iter__(self):\n        \"\"\"Iterate over all features in the store.\"\"\"\n        return iter(self.chromosomes.values())\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the feature store.\"\"\"\n        chrom_counts = [f\"{chrom}: {len(store)}\" for chrom, store in self.chromosomes.items()]\n        keys = sorted(list(self.chromosomes.keys()))\n        stores = [f\"\\t{self.chromosomes[chr]}\" for chr in keys]\n        return (f\"GenomicFeatureStore(type={self.store_type.value}, \"\n                + f\"chromosomes={len(self.chromosomes)}, \"\n                + f\"features={self.get_feature_count()}, \"\n                + f\"{', '.join(chrom_counts)})\\n\"\n                + '\\n'.join(stores)\n                )\n\n    def __repr__(self) -&gt; str:\n        return self.__str__()\n\n    def trim(self) -&gt; None:\n        \"\"\"\n        Trim internal data structures to reduce memory usage.\n\n        This method calls trim() on all chromosome stores\n        to reduce memory usage before serialization.\n        \"\"\"\n        for chrom_store in self.chromosomes.values():\n            chrom_store.trim()\n\n    def save(self, filepath: Path) -&gt; None:\n        \"\"\"\n        Save the genomic feature store to a file using pickle.\n\n        Args:\n            filepath: Path to save the store to\n        \"\"\"\n        # Ensure the directory exists\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        # Make sure all indices are built before saving\n        for chrom in self.chromosomes.values():\n            if chrom.index_build_mode:\n                chrom.index_build_end()\n\n        # Trim all stores to reduce memory usage before serialization\n        self.trim()\n\n        with open(filepath, 'wb') as f:\n            pickle.dump(self, f)\n\n    @classmethod\n    def load(cls, filepath: Path) -&gt; 'GenomicFeatureStore':\n        \"\"\"\n        Load a genomic feature store from a file.\n\n        Args:\n            filepath: Path to load the store from\n\n        Returns:\n            The loaded genomic feature store\n        \"\"\"\n        if not filepath.exists():\n            raise FileNotFoundError(f\"File not found: {filepath}\")\n\n        with open(filepath, 'rb') as f:\n            store = pickle.load(f)\n\n        # Validate the loaded object\n        if not isinstance(store, GenomicFeatureStore):\n            raise TypeError(f\"Loaded object is not a GenomicFeatureStore: {type(store)}\")\n\n        return store\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager when adding features</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter the context manager when adding features\"\"\"\n    return self\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Exit the context manager after adding features, ensures all indeces are built</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def __exit__(self, exc_type, exc_value, traceback):\n    \"\"\"Exit the context manager after adding features, ensures all indeces are built\"\"\"\n    # No special cleanup needed for this store\n    for chrom in self.chromosomes.values():\n        chrom.index_build_end()\n    return False\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.__init__","title":"<code>__init__(store_type=StoreType.INTERVAL_TREE, bin_size=100000)</code>","text":"<p>Initialize the genomic feature store.</p> <p>Parameters:</p> Name Type Description Default <code>store_type</code> <code>StoreType | str</code> <p>Type of store to use</p> <code>INTERVAL_TREE</code> <code>bin_size</code> <code>int</code> <p>Size of bins for the binned store</p> <code>100000</code> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def __init__(self, store_type: StoreType | str = StoreType.INTERVAL_TREE, bin_size: int = 100000):\n    \"\"\"\n    Initialize the genomic feature store.\n\n    Args:\n        store_type: Type of store to use\n        bin_size: Size of bins for the binned store\n    \"\"\"\n    self.chromosomes: dict[str, ChromosomeFeatureStore] = {}\n\n    if isinstance(store_type, str):\n        try:\n            self.store_type = StoreType(store_type)\n        except ValueError:\n            raise ValueError(f\"Unknown store type: {store_type}\")\n    else:\n        self.store_type = store_type\n\n    self.bin_size = bin_size\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over all features in the store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over all features in the store.\"\"\"\n    return iter(self.chromosomes.values())\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.__iterator__","title":"<code>__iterator__()</code>","text":"<p>Iterate over all features in the store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def __iterator__(self):\n    \"\"\"Iterate over all features in the store.\"\"\"\n    return self\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the feature store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the feature store.\"\"\"\n    chrom_counts = [f\"{chrom}: {len(store)}\" for chrom, store in self.chromosomes.items()]\n    keys = sorted(list(self.chromosomes.keys()))\n    stores = [f\"\\t{self.chromosomes[chr]}\" for chr in keys]\n    return (f\"GenomicFeatureStore(type={self.store_type.value}, \"\n            + f\"chromosomes={len(self.chromosomes)}, \"\n            + f\"features={self.get_feature_count()}, \"\n            + f\"{', '.join(chrom_counts)})\\n\"\n            + '\\n'.join(stores)\n            )\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.add","title":"<code>add(feature)</code>","text":"<p>Add a genomic feature to the store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def add(self, feature: GenomicFeature) -&gt; None:\n    \"\"\"Add a genomic feature to the store.\"\"\"\n    chrom_store = self._get_or_create_chrom_store(feature.chrom)\n    chrom_store.add(feature)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.add_features","title":"<code>add_features(features)</code>","text":"<p>Add multiple genomic features to the store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def add_features(self, features: list[GenomicFeature]) -&gt; None:\n    \"\"\"Add multiple genomic features to the store.\"\"\"\n    for feature in features:\n        self.add(feature)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.get_by_interval","title":"<code>get_by_interval(chrom, start, end)</code>","text":"<p>Get all features that overlap with the given range.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def get_by_interval(self, chrom: str, start: int, end: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features that overlap with the given range.\"\"\"\n    if chrom not in self.chromosomes:\n        return []\n    return self.chromosomes[chrom].get_by_interval(start, end)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.get_by_position","title":"<code>get_by_position(chrom, position)</code>","text":"<p>Get all features at a specific position.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def get_by_position(self, chrom: str, position: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features at a specific position.\"\"\"\n    if chrom not in self.chromosomes:\n        return []\n    return self.chromosomes[chrom].get_by_position(position)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.get_chromosomes","title":"<code>get_chromosomes()</code>","text":"<p>Get all chromosome names in the store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def get_chromosomes(self) -&gt; list[str]:\n    \"\"\"Get all chromosome names in the store.\"\"\"\n    return list(self.chromosomes.keys())\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.get_feature_count","title":"<code>get_feature_count(chrom=None)</code>","text":"<p>Get the number of features in the store.</p> <p>Parameters:</p> Name Type Description Default <code>chrom</code> <code>str | None</code> <p>If provided, count only features in this chromosome</p> <code>None</code> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def get_feature_count(self, chrom: str | None = None) -&gt; int:\n    \"\"\"\n    Get the number of features in the store.\n\n    Args:\n        chrom: If provided, count only features in this chromosome\n    \"\"\"\n    if chrom is not None:\n        if chrom not in self.chromosomes:\n            return 0\n        return len(self.chromosomes[chrom].features)\n\n    # Count across all chromosomes\n    return sum(len(store) for store in self.chromosomes.values())\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.get_nearest","title":"<code>get_nearest(chrom, position, max_distance=MAX_DISTANCE)</code>","text":"<p>Get the nearest feature to the given position.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def get_nearest(self, chrom: str, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n    \"\"\"Get the nearest feature to the given position.\"\"\"\n    if chrom not in self.chromosomes:\n        return None\n    return self.chromosomes[chrom].get_nearest(position, max_distance)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.load","title":"<code>load(filepath)</code>  <code>classmethod</code>","text":"<p>Load a genomic feature store from a file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to load the store from</p> required <p>Returns:</p> Type Description <code>GenomicFeatureStore</code> <p>The loaded genomic feature store</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>@classmethod\ndef load(cls, filepath: Path) -&gt; 'GenomicFeatureStore':\n    \"\"\"\n    Load a genomic feature store from a file.\n\n    Args:\n        filepath: Path to load the store from\n\n    Returns:\n        The loaded genomic feature store\n    \"\"\"\n    if not filepath.exists():\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n\n    with open(filepath, 'rb') as f:\n        store = pickle.load(f)\n\n    # Validate the loaded object\n    if not isinstance(store, GenomicFeatureStore):\n        raise TypeError(f\"Loaded object is not a GenomicFeatureStore: {type(store)}\")\n\n    return store\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.save","title":"<code>save(filepath)</code>","text":"<p>Save the genomic feature store to a file using pickle.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to save the store to</p> required Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def save(self, filepath: Path) -&gt; None:\n    \"\"\"\n    Save the genomic feature store to a file using pickle.\n\n    Args:\n        filepath: Path to save the store to\n    \"\"\"\n    # Ensure the directory exists\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n\n    # Make sure all indices are built before saving\n    for chrom in self.chromosomes.values():\n        if chrom.index_build_mode:\n            chrom.index_build_end()\n\n    # Trim all stores to reduce memory usage before serialization\n    self.trim()\n\n    with open(filepath, 'wb') as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStore.trim","title":"<code>trim()</code>","text":"<p>Trim internal data structures to reduce memory usage.</p> <p>This method calls trim() on all chromosome stores to reduce memory usage before serialization.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>def trim(self) -&gt; None:\n    \"\"\"\n    Trim internal data structures to reduce memory usage.\n\n    This method calls trim() on all chromosome stores\n    to reduce memory usage before serialization.\n    \"\"\"\n    for chrom_store in self.chromosomes.values():\n        chrom_store.trim()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol","title":"<code>GenomicFeatureStoreProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for genomic feature stores.</p> <p>Feature stores MUST also be context managers (enter and exit methods), which is used during index creation</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>@runtime_checkable\nclass GenomicFeatureStoreProtocol(Protocol):\n    \"\"\"\n    Protocol for genomic feature stores.\n\n    Feature stores MUST also be context managers (__enter__ and __exit__ methods), which is used during index creation\n    \"\"\"\n\n    def add(self, feature: GenomicFeature) -&gt; None:\n        \"\"\"Add a genomic feature to the store.\"\"\"\n        ...\n\n    def get_by_position(self, chrom: str, position: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features at a specific position.\"\"\"\n        ...\n\n    def get_by_interval(self, chrom: str, start: int, end: int) -&gt; list[GenomicFeature]:\n        \"\"\"Get all features that overlap with the given range.\"\"\"\n        ...\n\n    def get_nearest(self, chrom: str, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n        \"\"\"Get the nearest feature to the given position.\"\"\"\n        ...\n\n    def __getitem__(self, chrom: str) -&gt; 'ChromosomeFeatureStore': # type: ignore\n        \"\"\"Get a chromosome store by name.\"\"\"\n        ...\n\n    def __iterator__(self):\n        \"\"\"Iterate over all chromosome stores.\"\"\"\n        ...\n\n    def trim(self) -&gt; None:\n        \"\"\"\n        Trim internal data structures to reduce memory usage.\n\n        This method should be called before serialization to reduce\n        the size of pickled objects by removing unused allocated memory.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.__getitem__","title":"<code>__getitem__(chrom)</code>","text":"<p>Get a chromosome store by name.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def __getitem__(self, chrom: str) -&gt; 'ChromosomeFeatureStore': # type: ignore\n    \"\"\"Get a chromosome store by name.\"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.__iterator__","title":"<code>__iterator__()</code>","text":"<p>Iterate over all chromosome stores.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def __iterator__(self):\n    \"\"\"Iterate over all chromosome stores.\"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.add","title":"<code>add(feature)</code>","text":"<p>Add a genomic feature to the store.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def add(self, feature: GenomicFeature) -&gt; None:\n    \"\"\"Add a genomic feature to the store.\"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.get_by_interval","title":"<code>get_by_interval(chrom, start, end)</code>","text":"<p>Get all features that overlap with the given range.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def get_by_interval(self, chrom: str, start: int, end: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features that overlap with the given range.\"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.get_by_position","title":"<code>get_by_position(chrom, position)</code>","text":"<p>Get all features at a specific position.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def get_by_position(self, chrom: str, position: int) -&gt; list[GenomicFeature]:\n    \"\"\"Get all features at a specific position.\"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.get_nearest","title":"<code>get_nearest(chrom, position, max_distance=MAX_DISTANCE)</code>","text":"<p>Get the nearest feature to the given position.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def get_nearest(self, chrom: str, position: int, max_distance: int = MAX_DISTANCE) -&gt; GenomicFeature | None:\n    \"\"\"Get the nearest feature to the given position.\"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.GenomicFeatureStoreProtocol.trim","title":"<code>trim()</code>","text":"<p>Trim internal data structures to reduce memory usage.</p> <p>This method should be called before serialization to reduce the size of pickled objects by removing unused allocated memory.</p> Source code in <code>pygnome/feature_store/genomic_feature_store_protocol.py</code> <pre><code>def trim(self) -&gt; None:\n    \"\"\"\n    Trim internal data structures to reduce memory usage.\n\n    This method should be called before serialization to reduce\n    the size of pickled objects by removing unused allocated memory.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore","title":"<code>IntervalTreeStore</code>","text":"<p>               Bases: <code>ChromosomeFeatureStore</code></p> <p>Store genomic features using an efficient interval tree.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>class IntervalTreeStore(ChromosomeFeatureStore):\n    \"\"\"Store genomic features using an efficient interval tree.\"\"\"\n\n    def __init__(self, chromosome: str):\n        super().__init__(chromosome=chromosome)\n        self.interval_tree = IntervalTree()\n        self.tree_built = False\n\n    def add(self, feature: GenomicFeature) -&gt; None:\n        \"\"\"Add a feature to the interval tree.\"\"\"\n        super().add(feature)\n        # Store the index in the features list\n        feature_idx = len(self.features) - 1\n        self.interval_tree.add(feature.start, feature.end, feature_idx)\n        # Mark tree as needing rebuild\n        self.tree_built = False\n\n    def index_build_end(self) -&gt; None:\n        \"\"\"Ensure the interval tree is built before querying.\"\"\"\n        super().index_build_end()\n        if not self.tree_built:\n            self.interval_tree.build()\n            self.tree_built = True\n\n    def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n        \"\"\"\n        Get all features at a specific position.\n\n        Uses half-open intervals [start, end) where start is included but end is excluded.\n        \"\"\"\n        indices = self.interval_tree.at(position)\n        return [self.features[idx] for idx in indices]\n\n    def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n        \"\"\"\n        Get all features that overlap with the given range.\n\n        Uses half-open intervals [start, end) where start is included but end is excluded.\n        \"\"\"\n        # Handle invalid ranges\n        if end &lt;= start:\n            return []\n        # Get indices from interval tree\n        indices = self.interval_tree.overlap(start, end)\n        return [self.features[idx] for idx in indices]\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the interval tree store.\"\"\"\n        status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n        tree_status = \"built\" if self.tree_built else \"not built\"\n\n        # Get tree statistics if available\n        tree_stats = \"\"\n        if self.tree_built and self.interval_tree.root:\n            # Count nodes in the tree (simple BFS)\n            node_count = 0\n            queue = [self.interval_tree.root]\n            while queue:\n                node = queue.pop(0)\n                node_count += 1\n                if node.left:\n                    queue.append(node.left)\n                if node.right:\n                    queue.append(node.right)\n\n            # Count intervals at the root level\n            root_intervals = len(self.interval_tree.root.intervals) if self.interval_tree.root else 0\n            tree_stats = f\", tree_nodes={node_count}, root_intervals={root_intervals}\"\n\n        # Sample of features\n        sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n        sample = self.features[:sample_size] if self.features else []\n        sample_str = \"\"\n        if sample:\n            sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n        return (f\"IntervalTreeStore(chromosome='{self.chromosome}', features={len(self.features)}, \"\n                f\"status={status}, tree_status={tree_status}{tree_stats}{sample_str})\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the interval tree store.\"\"\"\n        return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the interval tree store.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the interval tree store.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the interval tree store.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the interval tree store.\"\"\"\n    status = \"building\" if self.index_build_mode else \"built\" if self.index_finished else \"uninitialized\"\n    tree_status = \"built\" if self.tree_built else \"not built\"\n\n    # Get tree statistics if available\n    tree_stats = \"\"\n    if self.tree_built and self.interval_tree.root:\n        # Count nodes in the tree (simple BFS)\n        node_count = 0\n        queue = [self.interval_tree.root]\n        while queue:\n            node = queue.pop(0)\n            node_count += 1\n            if node.left:\n                queue.append(node.left)\n            if node.right:\n                queue.append(node.right)\n\n        # Count intervals at the root level\n        root_intervals = len(self.interval_tree.root.intervals) if self.interval_tree.root else 0\n        tree_stats = f\", tree_nodes={node_count}, root_intervals={root_intervals}\"\n\n    # Sample of features\n    sample_size = min(MAX_SAMPLES_TO_SHOW, len(self.features))\n    sample = self.features[:sample_size] if self.features else []\n    sample_str = \"\"\n    if sample:\n        sample_str = f\", sample: [{', '.join(str(f.id) for f in sample)}\" + (\", ...]\" if len(self.features) &gt; sample_size else \"]\")\n\n    return (f\"IntervalTreeStore(chromosome='{self.chromosome}', features={len(self.features)}, \"\n            f\"status={status}, tree_status={tree_status}{tree_stats}{sample_str})\")\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore.add","title":"<code>add(feature)</code>","text":"<p>Add a feature to the interval tree.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>def add(self, feature: GenomicFeature) -&gt; None:\n    \"\"\"Add a feature to the interval tree.\"\"\"\n    super().add(feature)\n    # Store the index in the features list\n    feature_idx = len(self.features) - 1\n    self.interval_tree.add(feature.start, feature.end, feature_idx)\n    # Mark tree as needing rebuild\n    self.tree_built = False\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore.get_by_interval","title":"<code>get_by_interval(start, end)</code>","text":"<p>Get all features that overlap with the given range.</p> <p>Uses half-open intervals [start, end) where start is included but end is excluded.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>def get_by_interval(self, start: int, end: int) -&gt; list[GenomicFeature]:\n    \"\"\"\n    Get all features that overlap with the given range.\n\n    Uses half-open intervals [start, end) where start is included but end is excluded.\n    \"\"\"\n    # Handle invalid ranges\n    if end &lt;= start:\n        return []\n    # Get indices from interval tree\n    indices = self.interval_tree.overlap(start, end)\n    return [self.features[idx] for idx in indices]\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore.get_by_position","title":"<code>get_by_position(position)</code>","text":"<p>Get all features at a specific position.</p> <p>Uses half-open intervals [start, end) where start is included but end is excluded.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>def get_by_position(self, position: int) -&gt; list[GenomicFeature]:\n    \"\"\"\n    Get all features at a specific position.\n\n    Uses half-open intervals [start, end) where start is included but end is excluded.\n    \"\"\"\n    indices = self.interval_tree.at(position)\n    return [self.features[idx] for idx in indices]\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.IntervalTreeStore.index_build_end","title":"<code>index_build_end()</code>","text":"<p>Ensure the interval tree is built before querying.</p> Source code in <code>pygnome/feature_store/interval_tree_store.py</code> <pre><code>def index_build_end(self) -&gt; None:\n    \"\"\"Ensure the interval tree is built before querying.\"\"\"\n    super().index_build_end()\n    if not self.tree_built:\n        self.interval_tree.build()\n        self.tree_built = True\n</code></pre>"},{"location":"api/feature_store/#pygnome.feature_store.StoreType","title":"<code>StoreType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Types of genomic feature stores.</p> Source code in <code>pygnome/feature_store/genomic_feature_store.py</code> <pre><code>class StoreType(str, Enum):\n    \"\"\"Types of genomic feature stores.\"\"\"\n    INTERVAL_TREE = \"interval_tree\"\n    BINNED = \"binned\"\n    BRUTE_FORCE = \"brute_force\"\n    MSI = \"msi\"\n</code></pre>"},{"location":"api/genomics/","title":"pygnome.genomics","text":"<p>Genomics module for genome annotations.</p>"},{"location":"api/parsers/","title":"pygnome.parsers","text":"<p>PyGnome parsers module for genomic annotation formats.</p> <p>This module provides parsers for GFF2, GFF3, GTF, FASTA, and FASTQ formats with a unified interface for working with genomic annotations and sequences.</p>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy","title":"<code>FeatureHierarchy</code>","text":"<p>Represents parent-child relationships between features.</p> <p>This class provides methods to navigate hierarchical relationships between features, particularly useful for GFF3 files with complex feature hierarchies.</p> Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>class FeatureHierarchy:\n    \"\"\"\n    Represents parent-child relationships between features.\n\n    This class provides methods to navigate hierarchical relationships\n    between features, particularly useful for GFF3 files with complex\n    feature hierarchies.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty feature hierarchy.\"\"\"\n        self.parent_to_children = defaultdict(list)  # parent_id -&gt; [child_records]\n        self.child_to_parents = defaultdict(list)    # child_id -&gt; [parent_records]\n        self.id_to_record = {}                       # id -&gt; record\n\n    def add_record(self, record: GffRecord) -&gt; None:\n        \"\"\"\n        Add a record to the hierarchy.\n\n        Args:\n            record: The Record object to add\n        \"\"\"\n        # Get record ID\n        record_id = record.get_attribute('ID')\n        if record_id:\n            self.id_to_record[record_id] = record\n\n        # Process parent-child relationships\n        parents = record.get_attribute('Parent')\n        if parents:\n            # Convert to list if it's a single value\n            if not isinstance(parents, list):\n                parents = [parents]\n\n            for parent_id in parents:\n                self.child_to_parents[record_id].append(parent_id)\n                self.parent_to_children[parent_id].append(record)\n\n    def build_from_records(self, records: List[GffRecord]) -&gt; None:\n        \"\"\"\n        Build the hierarchy from a list of records.\n\n        Args:\n            records: List of Record objects\n        \"\"\"\n        for record in records:\n            self.add_record(record)\n\n    def get_children(self, parent_id: str) -&gt; List[GffRecord]:\n        \"\"\"\n        Get all direct children of a feature.\n\n        Args:\n            parent_id: ID of the parent feature\n\n        Returns:\n            List of child Record objects\n        \"\"\"\n        return self.parent_to_children.get(parent_id, [])\n\n    def get_parents(self, child_id: str) -&gt; List[GffRecord]:\n        \"\"\"\n        Get all direct parents of a feature.\n\n        Args:\n            child_id: ID of the child feature\n\n        Returns:\n            List of parent Record objects\n        \"\"\"\n        parent_ids = self.child_to_parents.get(child_id, [])\n        return [self.id_to_record.get(pid) for pid in parent_ids if pid in self.id_to_record]\n\n    def get_descendants(self, parent_id: str, max_depth: int | None = None) -&gt; List[GffRecord]:\n        \"\"\"\n        Get all descendants of a feature (children, grandchildren, etc.).\n\n        Args:\n            parent_id: ID of the parent feature\n            max_depth: Maximum depth to traverse (None for unlimited)\n\n        Returns:\n            List of descendant Record objects\n        \"\"\"\n        descendants = []\n        visited = set()\n        added_record_ids = set()\n\n        def _traverse(pid, depth=0):\n            if pid in visited or (max_depth is not None and depth &gt;= max_depth):\n                return\n\n            visited.add(pid)\n            children = self.get_children(pid)\n            for child in children:\n                child_id = child.get_attribute('ID')\n                if child_id and child_id not in added_record_ids:\n                    descendants.append(child)\n                    added_record_ids.add(child_id)\n\n            for child in children:\n                child_id = child.get_attribute('ID')\n                if child_id:\n                    _traverse(child_id, depth + 1)\n\n        _traverse(parent_id)\n        return descendants\n\n    def get_ancestors(self, child_id: str, max_depth: int | None = None) -&gt; List[GffRecord]:\n        \"\"\"\n        Get all ancestors of a feature (parents, grandparents, etc.).\n\n        Args:\n            child_id: ID of the child feature\n            max_depth: Maximum depth to traverse (None for unlimited)\n\n        Returns:\n            List of ancestor Record objects\n        \"\"\"\n        ancestors = []\n        visited = set()\n\n        def _traverse(cid, depth=0):\n            if cid in visited or (max_depth is not None and depth &gt;= max_depth):\n                return\n\n            visited.add(cid)\n            parents = self.get_parents(cid)\n            ancestors.extend(parents)\n\n            for parent in parents:\n                parent_id = parent.get_attribute('ID')\n                if parent_id:\n                    _traverse(parent_id, depth + 1)\n\n        _traverse(child_id)\n        return ancestors\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.__init__","title":"<code>__init__()</code>","text":"<p>Initialize an empty feature hierarchy.</p> Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize an empty feature hierarchy.\"\"\"\n    self.parent_to_children = defaultdict(list)  # parent_id -&gt; [child_records]\n    self.child_to_parents = defaultdict(list)    # child_id -&gt; [parent_records]\n    self.id_to_record = {}                       # id -&gt; record\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.add_record","title":"<code>add_record(record)</code>","text":"<p>Add a record to the hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>GffRecord</code> <p>The Record object to add</p> required Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def add_record(self, record: GffRecord) -&gt; None:\n    \"\"\"\n    Add a record to the hierarchy.\n\n    Args:\n        record: The Record object to add\n    \"\"\"\n    # Get record ID\n    record_id = record.get_attribute('ID')\n    if record_id:\n        self.id_to_record[record_id] = record\n\n    # Process parent-child relationships\n    parents = record.get_attribute('Parent')\n    if parents:\n        # Convert to list if it's a single value\n        if not isinstance(parents, list):\n            parents = [parents]\n\n        for parent_id in parents:\n            self.child_to_parents[record_id].append(parent_id)\n            self.parent_to_children[parent_id].append(record)\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.build_from_records","title":"<code>build_from_records(records)</code>","text":"<p>Build the hierarchy from a list of records.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[GffRecord]</code> <p>List of Record objects</p> required Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def build_from_records(self, records: List[GffRecord]) -&gt; None:\n    \"\"\"\n    Build the hierarchy from a list of records.\n\n    Args:\n        records: List of Record objects\n    \"\"\"\n    for record in records:\n        self.add_record(record)\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.get_ancestors","title":"<code>get_ancestors(child_id, max_depth=None)</code>","text":"<p>Get all ancestors of a feature (parents, grandparents, etc.).</p> <p>Parameters:</p> Name Type Description Default <code>child_id</code> <code>str</code> <p>ID of the child feature</p> required <code>max_depth</code> <code>int | None</code> <p>Maximum depth to traverse (None for unlimited)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of ancestor Record objects</p> Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def get_ancestors(self, child_id: str, max_depth: int | None = None) -&gt; List[GffRecord]:\n    \"\"\"\n    Get all ancestors of a feature (parents, grandparents, etc.).\n\n    Args:\n        child_id: ID of the child feature\n        max_depth: Maximum depth to traverse (None for unlimited)\n\n    Returns:\n        List of ancestor Record objects\n    \"\"\"\n    ancestors = []\n    visited = set()\n\n    def _traverse(cid, depth=0):\n        if cid in visited or (max_depth is not None and depth &gt;= max_depth):\n            return\n\n        visited.add(cid)\n        parents = self.get_parents(cid)\n        ancestors.extend(parents)\n\n        for parent in parents:\n            parent_id = parent.get_attribute('ID')\n            if parent_id:\n                _traverse(parent_id, depth + 1)\n\n    _traverse(child_id)\n    return ancestors\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.get_children","title":"<code>get_children(parent_id)</code>","text":"<p>Get all direct children of a feature.</p> <p>Parameters:</p> Name Type Description Default <code>parent_id</code> <code>str</code> <p>ID of the parent feature</p> required <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of child Record objects</p> Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def get_children(self, parent_id: str) -&gt; List[GffRecord]:\n    \"\"\"\n    Get all direct children of a feature.\n\n    Args:\n        parent_id: ID of the parent feature\n\n    Returns:\n        List of child Record objects\n    \"\"\"\n    return self.parent_to_children.get(parent_id, [])\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.get_descendants","title":"<code>get_descendants(parent_id, max_depth=None)</code>","text":"<p>Get all descendants of a feature (children, grandchildren, etc.).</p> <p>Parameters:</p> Name Type Description Default <code>parent_id</code> <code>str</code> <p>ID of the parent feature</p> required <code>max_depth</code> <code>int | None</code> <p>Maximum depth to traverse (None for unlimited)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of descendant Record objects</p> Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def get_descendants(self, parent_id: str, max_depth: int | None = None) -&gt; List[GffRecord]:\n    \"\"\"\n    Get all descendants of a feature (children, grandchildren, etc.).\n\n    Args:\n        parent_id: ID of the parent feature\n        max_depth: Maximum depth to traverse (None for unlimited)\n\n    Returns:\n        List of descendant Record objects\n    \"\"\"\n    descendants = []\n    visited = set()\n    added_record_ids = set()\n\n    def _traverse(pid, depth=0):\n        if pid in visited or (max_depth is not None and depth &gt;= max_depth):\n            return\n\n        visited.add(pid)\n        children = self.get_children(pid)\n        for child in children:\n            child_id = child.get_attribute('ID')\n            if child_id and child_id not in added_record_ids:\n                descendants.append(child)\n                added_record_ids.add(child_id)\n\n        for child in children:\n            child_id = child.get_attribute('ID')\n            if child_id:\n                _traverse(child_id, depth + 1)\n\n    _traverse(parent_id)\n    return descendants\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.FeatureHierarchy.get_parents","title":"<code>get_parents(child_id)</code>","text":"<p>Get all direct parents of a feature.</p> <p>Parameters:</p> Name Type Description Default <code>child_id</code> <code>str</code> <p>ID of the child feature</p> required <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of parent Record objects</p> Source code in <code>pygnome/parsers/gff/feature_hierarchy.py</code> <pre><code>def get_parents(self, child_id: str) -&gt; List[GffRecord]:\n    \"\"\"\n    Get all direct parents of a feature.\n\n    Args:\n        child_id: ID of the child feature\n\n    Returns:\n        List of parent Record objects\n    \"\"\"\n    parent_ids = self.child_to_parents.get(child_id, [])\n    return [self.id_to_record.get(pid) for pid in parent_ids if pid in self.id_to_record]\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Format","title":"<code>Format</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of supported genomic annotation file formats.</p> Values <p>GFF2: Gene Finding Format version 2 GFF3: Generic Feature Format version 3 GTF: Gene Transfer Format (GTF2.2)</p> Source code in <code>pygnome/parsers/gff/format.py</code> <pre><code>class Format(str, Enum):\n    \"\"\"\n    Enumeration of supported genomic annotation file formats.\n\n    Values:\n        GFF2: Gene Finding Format version 2\n        GFF3: Generic Feature Format version 3\n        GTF: Gene Transfer Format (GTF2.2)\n    \"\"\"\n    GFF2 = \"gff2\"\n    GFF3 = \"gff3\"\n    GTF = \"gtf\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string value of the format.\"\"\"\n        return self.value\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Format.__str__","title":"<code>__str__()</code>","text":"<p>Return the string value of the format.</p> Source code in <code>pygnome/parsers/gff/format.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string value of the format.\"\"\"\n    return self.value\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff","title":"<code>Gff</code>","text":"<p>Main interface for reading and working with GFF/GTF files.</p> <p>This class is implemented as a context manager for efficient file handling and provides methods for filtering and accessing features.</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>class Gff:\n    \"\"\"\n    Main interface for reading and working with GFF/GTF files.\n\n    This class is implemented as a context manager for efficient file handling\n    and provides methods for filtering and accessing features.\n    \"\"\"\n\n    def __init__(self, file_path: str, format: Format | None = None):\n        \"\"\"\n        Initialize the Gff context manager.\n\n        Args:\n            file_path: Path to the GFF/GTF file\n            format: Optional format specification (Format.GFF2, Format.GFF3, Format.GTF)\n                   If not provided, format will be auto-detected\n        \"\"\"\n        self.file_path = file_path\n        self.format = format\n        self.parser = None\n        self.file_handle = None\n        self.records = []\n        self._hierarchy = None\n\n    def __enter__(self):\n        \"\"\"Enter the context manager.\"\"\"\n        # Auto-detect format if not specified\n        if not self.format:\n            self.format = self._detect_format()\n\n        # Create appropriate parser\n        if self.format == Format.GFF2:\n            self.parser = Gff2Parser()\n        elif self.format == Format.GFF3:\n            self.parser = Gff3Parser()\n        elif self.format == Format.GTF:\n            self.parser = GtfParser()\n        else:\n            raise ValueError(f\"Unsupported format: {self.format}\")\n\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Exit the context manager.\"\"\"\n        # Clean up resources\n        self.file_handle = None\n\n        # Don't suppress exceptions\n        return False\n\n    def __iter__(self) -&gt; Iterator[GffRecord]:\n        \"\"\"Iterate over records in the file.\"\"\"\n        # Parse the file and yield records\n        for record in self.parser.parse(self.file_path):\n            self.records.append(record)\n            yield record\n\n    def _detect_format(self) -&gt; Format:\n        \"\"\"Detect the format of the file.\"\"\"\n        return BaseParser.detect_format(self.file_path)\n\n    def build_hierarchy(self) -&gt; FeatureHierarchy:\n        \"\"\"\n        Build and return a feature hierarchy for parent-child relationships.\n\n        Returns:\n            FeatureHierarchy object for navigating feature relationships\n        \"\"\"\n        if self._hierarchy is None:\n            self._hierarchy = FeatureHierarchy()\n            self._hierarchy.build_from_records(self.records)\n\n        return self._hierarchy\n\n    def get_features_by_type(self, type_: str) -&gt; List[GffRecord]:\n        \"\"\"\n        Get all features of a specific type (e.g., 'gene', 'exon', 'CDS').\n\n        Args:\n            type_: Feature type to filter by\n\n        Returns:\n            List of matching Record objects\n        \"\"\"\n        return [r for r in self.records if r.type == type_]\n\n    def get_features_by_location(self, seqid: str, start: int, end: int) -&gt; List[GffRecord]:\n        \"\"\"\n        Get all features that overlap with the specified genomic region.\n\n        Args:\n            seqid: Reference sequence identifier\n            start: 1-based start coordinate of the region\n            end: End coordinate of the region (inclusive)\n\n        Returns:\n            List of features that overlap with the region\n        \"\"\"\n        return [\n            r for r in self.records\n            if r.chrom == seqid and\n               not (r.end &lt; start or r.start &gt; end)  # Overlap check\n        ]\n\n    def get_features_by_attribute(self, attr_name: str, attr_value: str | None = None) -&gt; List[GffRecord]:\n        \"\"\"\n        Get features based on their attributes.\n\n        Args:\n            attr_name: Name of the attribute to search for (e.g., 'ID', 'Name', 'gene_id')\n            attr_value: If provided, only return features where the attribute equals this value\n\n        Returns:\n            List of features with matching attributes\n        \"\"\"\n        if attr_value is None:\n            # Just check for presence of attribute\n            return [r for r in self.records if attr_name in r.attributes]\n        else:\n            # Check for specific value\n            return [\n                r for r in self.records \n                if attr_name in r.attributes and r.attributes[attr_name] == attr_value\n            ]\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter the context manager.\"\"\"\n    # Auto-detect format if not specified\n    if not self.format:\n        self.format = self._detect_format()\n\n    # Create appropriate parser\n    if self.format == Format.GFF2:\n        self.parser = Gff2Parser()\n    elif self.format == Format.GFF3:\n        self.parser = Gff3Parser()\n    elif self.format == Format.GTF:\n        self.parser = GtfParser()\n    else:\n        raise ValueError(f\"Unsupported format: {self.format}\")\n\n    return self\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Exit the context manager.</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Exit the context manager.\"\"\"\n    # Clean up resources\n    self.file_handle = None\n\n    # Don't suppress exceptions\n    return False\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.__init__","title":"<code>__init__(file_path, format=None)</code>","text":"<p>Initialize the Gff context manager.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the GFF/GTF file</p> required <code>format</code> <code>Format | None</code> <p>Optional format specification (Format.GFF2, Format.GFF3, Format.GTF)    If not provided, format will be auto-detected</p> <code>None</code> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def __init__(self, file_path: str, format: Format | None = None):\n    \"\"\"\n    Initialize the Gff context manager.\n\n    Args:\n        file_path: Path to the GFF/GTF file\n        format: Optional format specification (Format.GFF2, Format.GFF3, Format.GTF)\n               If not provided, format will be auto-detected\n    \"\"\"\n    self.file_path = file_path\n    self.format = format\n    self.parser = None\n    self.file_handle = None\n    self.records = []\n    self._hierarchy = None\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over records in the file.</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def __iter__(self) -&gt; Iterator[GffRecord]:\n    \"\"\"Iterate over records in the file.\"\"\"\n    # Parse the file and yield records\n    for record in self.parser.parse(self.file_path):\n        self.records.append(record)\n        yield record\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.build_hierarchy","title":"<code>build_hierarchy()</code>","text":"<p>Build and return a feature hierarchy for parent-child relationships.</p> <p>Returns:</p> Type Description <code>FeatureHierarchy</code> <p>FeatureHierarchy object for navigating feature relationships</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def build_hierarchy(self) -&gt; FeatureHierarchy:\n    \"\"\"\n    Build and return a feature hierarchy for parent-child relationships.\n\n    Returns:\n        FeatureHierarchy object for navigating feature relationships\n    \"\"\"\n    if self._hierarchy is None:\n        self._hierarchy = FeatureHierarchy()\n        self._hierarchy.build_from_records(self.records)\n\n    return self._hierarchy\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.get_features_by_attribute","title":"<code>get_features_by_attribute(attr_name, attr_value=None)</code>","text":"<p>Get features based on their attributes.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>Name of the attribute to search for (e.g., 'ID', 'Name', 'gene_id')</p> required <code>attr_value</code> <code>str | None</code> <p>If provided, only return features where the attribute equals this value</p> <code>None</code> <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of features with matching attributes</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def get_features_by_attribute(self, attr_name: str, attr_value: str | None = None) -&gt; List[GffRecord]:\n    \"\"\"\n    Get features based on their attributes.\n\n    Args:\n        attr_name: Name of the attribute to search for (e.g., 'ID', 'Name', 'gene_id')\n        attr_value: If provided, only return features where the attribute equals this value\n\n    Returns:\n        List of features with matching attributes\n    \"\"\"\n    if attr_value is None:\n        # Just check for presence of attribute\n        return [r for r in self.records if attr_name in r.attributes]\n    else:\n        # Check for specific value\n        return [\n            r for r in self.records \n            if attr_name in r.attributes and r.attributes[attr_name] == attr_value\n        ]\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.get_features_by_location","title":"<code>get_features_by_location(seqid, start, end)</code>","text":"<p>Get all features that overlap with the specified genomic region.</p> <p>Parameters:</p> Name Type Description Default <code>seqid</code> <code>str</code> <p>Reference sequence identifier</p> required <code>start</code> <code>int</code> <p>1-based start coordinate of the region</p> required <code>end</code> <code>int</code> <p>End coordinate of the region (inclusive)</p> required <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of features that overlap with the region</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def get_features_by_location(self, seqid: str, start: int, end: int) -&gt; List[GffRecord]:\n    \"\"\"\n    Get all features that overlap with the specified genomic region.\n\n    Args:\n        seqid: Reference sequence identifier\n        start: 1-based start coordinate of the region\n        end: End coordinate of the region (inclusive)\n\n    Returns:\n        List of features that overlap with the region\n    \"\"\"\n    return [\n        r for r in self.records\n        if r.chrom == seqid and\n           not (r.end &lt; start or r.start &gt; end)  # Overlap check\n    ]\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Gff.get_features_by_type","title":"<code>get_features_by_type(type_)</code>","text":"<p>Get all features of a specific type (e.g., 'gene', 'exon', 'CDS').</p> <p>Parameters:</p> Name Type Description Default <code>type_</code> <code>str</code> <p>Feature type to filter by</p> required <p>Returns:</p> Type Description <code>List[GffRecord]</code> <p>List of matching Record objects</p> Source code in <code>pygnome/parsers/gff/gff.py</code> <pre><code>def get_features_by_type(self, type_: str) -&gt; List[GffRecord]:\n    \"\"\"\n    Get all features of a specific type (e.g., 'gene', 'exon', 'CDS').\n\n    Args:\n        type_: Feature type to filter by\n\n    Returns:\n        List of matching Record objects\n    \"\"\"\n    return [r for r in self.records if r.type == type_]\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Strand","title":"<code>Strand</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of possible strand values in genomic annotation formats.</p> Values <p>POSITIVE: Forward strand ('+') NEGATIVE: Reverse strand ('-') UNSTRANDED: Feature is not stranded ('.') UNKNOWN: Strandedness is relevant but unknown ('?')</p> Source code in <code>pygnome/genomics/strand.py</code> <pre><code>class Strand(str, Enum):\n    \"\"\"\n    Enumeration of possible strand values in genomic annotation formats.\n\n    Values:\n        POSITIVE: Forward strand ('+')\n        NEGATIVE: Reverse strand ('-')\n        UNSTRANDED: Feature is not stranded ('.')\n        UNKNOWN: Strandedness is relevant but unknown ('?')\n    \"\"\"\n    POSITIVE = \"+\"\n    NEGATIVE = \"-\"\n    UNSTRANDED = \".\"\n    UNKNOWN = \"?\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string value of the strand.\"\"\"\n        return self.value\n</code></pre>"},{"location":"api/parsers/#pygnome.parsers.Strand.__str__","title":"<code>__str__()</code>","text":"<p>Return the string value of the strand.</p> Source code in <code>pygnome/genomics/strand.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string value of the strand.\"\"\"\n    return self.value\n</code></pre>"},{"location":"api/sequences/","title":"pygnome.sequences","text":"<p>Sequence representation module for DNA and RNA sequences.</p>"},{"location":"api/sequences/#pygnome.sequences.DnaString","title":"<code>DnaString</code>","text":"<p>               Bases: <code>BaseSequence</code></p> <p>Efficient 2-bit representation of DNA sequences.</p> <p>This class stores DNA sequences (A, C, G, T) using 2 bits per nucleotide, allowing 16 nucleotides to be packed into a single 32-bit integer.</p> <p>Ambiguous nucleotides (N, R, Y, etc.) are not directly supported in the 2-bit representation and will be converted to 'A' by default.</p> Source code in <code>pygnome/sequences/dna_string.py</code> <pre><code>class DnaString(BaseSequence):\n    \"\"\"\n    Efficient 2-bit representation of DNA sequences.\n\n    This class stores DNA sequences (A, C, G, T) using 2 bits per nucleotide,\n    allowing 16 nucleotides to be packed into a single 32-bit integer.\n\n    Ambiguous nucleotides (N, R, Y, etc.) are not directly supported in the\n    2-bit representation and will be converted to 'A' by default.\n    \"\"\"\n\n    @property\n    def _NT_TO_BITS(self) -&gt; dict[str, int]:\n        \"\"\"Mapping from nucleotide characters to 2-bit values.\"\"\"\n        return DNA_NT_TO_BITS\n\n    @property\n    def _BITS_TO_NT(self) -&gt; list[str]:\n        return DNA_BITS_TO_NT\n</code></pre>"},{"location":"api/sequences/#pygnome.sequences.RnaString","title":"<code>RnaString</code>","text":"<p>               Bases: <code>BaseSequence</code></p> <p>Efficient 2-bit representation of RNA sequences.</p> <p>This class stores RNA sequences (A, C, G, U) using 2 bits per nucleotide, allowing 16 nucleotides to be packed into a single 32-bit integer.</p> <p>Ambiguous nucleotides (N, R, Y, etc.) are not directly supported in the 2-bit representation and will be converted to 'A' by default.</p> Source code in <code>pygnome/sequences/rna_string.py</code> <pre><code>class RnaString(BaseSequence):\n    \"\"\"\n    Efficient 2-bit representation of RNA sequences.\n\n    This class stores RNA sequences (A, C, G, U) using 2 bits per nucleotide,\n    allowing 16 nucleotides to be packed into a single 32-bit integer.\n\n    Ambiguous nucleotides (N, R, Y, etc.) are not directly supported in the\n    2-bit representation and will be converted to 'A' by default.\n    \"\"\"\n\n    @property\n    def _NT_TO_BITS(self) -&gt; dict[str, int]:\n        \"\"\"Mapping from nucleotide characters to 2-bit values.\"\"\"\n        return RNA_NT_TO_BITS\n\n    @property\n    def _BITS_TO_NT(self) -&gt; list[str]:\n        return RNA_BITS_TO_NT\n</code></pre>"},{"location":"format_specifications/fasta/","title":"FASTA File format for DNA or protein sequences","text":"<p>| Filename extensions | .fasta, .fas, .fa, .fna, .ffn, .faa, .mpfa, .frn | | Internet media\u00a0type | <code>text/x-fasta</code> | | Uniform Type Identifier\u00a0(UTI) | no | | Developed\u00a0by | David J. LipmanWilliam R. Pearson[1][2] | | Initial release | 1985 | | Type of format | Bioinformatics | | Extended\u00a0from | ASCII for FASTA | | Extended\u00a0to | FASTQ format[3] | | Website | www.ncbi.nlm.nih.gov/BLAST/fasta.shtml |</p> <p>FASTA format</p> <p>In bioinformatics and biochemistry, the FASTA format is a text-based format for representing either nucleotide sequences or amino acid (protein) sequences, in which nucleotides or amino acids are represented using single-letter codes.</p> <p>The format allows for sequence names and comments to precede the sequences. It originated from the FASTA software package and has since become a near-universal standard in bioinformatics.[4]</p> <p>The simplicity of FASTA format makes it easy to manipulate and parse sequences using text-processing tools and scripting languages.</p>"},{"location":"format_specifications/fasta/#overview","title":"Overview","text":"<p>[ edit]</p> <p>A sequence begins with a greater-than character (\"&gt;\") followed by a description of the sequence (all in a single line). The lines immediately following the description line are the sequence representation, with one letter per amino acid or nucleic acid, and are typically no more than 80 characters in length.</p> <p>For example:</p> <pre><code>&gt;MCHU - Calmodulin - Human, rabbit, bovine, rat, and chicken\nMADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTID\nFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREA\nDIDGDGQVNYEEFVQMMTAK*\n</code></pre>"},{"location":"format_specifications/fasta/#original-format","title":"Original format","text":"<p>[ edit]</p> <p>The original FASTA/ Pearson format is described in the documentation for the FASTA suite of programs. It can be downloaded with any free distribution of FASTA (see fasta20.doc, fastaVN.doc, or fastaVN.me\u2014where VN is the Version Number).</p> <p>In the original format, a sequence was represented as a series of lines, each of which was no longer than 120 characters and usually did not exceed 80 characters. This probably was to allow for the preallocation of fixed line sizes in software: at the time most users relied on Digital Equipment Corporation (DEC) VT220 (or compatible) terminals which could display 80 or 132 characters per line.[5][6] Most people preferred the bigger font in 80-character modes and so it became the recommended fashion to use 80 characters or less (often 70) in FASTA lines. Also, the width of a standard printed page is 70 to 80 characters (depending on the font). Hence, 80 characters became the norm.[7]</p> <p>The first line in a FASTA file started either with a \"&gt;\" (greater-than) symbol or, less frequently, a \";\"[8] (semicolon) was taken as a comment. Subsequent lines starting with a semicolon would be ignored by software. Since the only comment used was the first, it quickly became used to hold a summary description of the sequence, often starting with a unique library accession number, and with time it has become commonplace to always use \"&gt;\" for the first line and to not use \";\" comments (which would otherwise be ignored).</p> <p>Following the initial line (used for a unique description of the sequence) was the actual sequence itself in the standard one-letter character string. Anything other than a valid character would be ignored (including spaces, tabulators, asterisks, etc...). It was also common to end the sequence with an \"*\" (asterisk) character (in analogy with use in PIR formatted sequences) and, for the same reason, to leave a blank line between the description and the sequence. Below are a few sample sequences:</p> <pre><code>;LCBO - Prolactin precursor - Bovine\n; a sample sequence in FASTA format\nMDSKGSSQKGSRLLLLLVVSNLLLCQGVVSTPVCPNGPGNCQVSLRDLFDRAVMVSHYIHDLSS\nEMFNEFDKRYAQGKGFITMALNSCHTSSLPTPEDKEQAQQTHHEVLMSLILGLLRSWNDPLYHL\nVTEVRGMKGAPDAILSRAIEIEEENKRLLEGMEMIFGQVIPGAKETEPYPVWSGLPSLQTKDED\nARYSAFYNLLHCLRRDSSKIDTYLKLLNCRIIYNNNC*\n\n&gt;MCHU - Calmodulin - Human, rabbit, bovine, rat, and chicken\nMADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTID\nFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREA\nDIDGDGQVNYEEFVQMMTAK*\n\n&gt;gi|5524211|gb|AAD44166.1| cytochrome b [Elephas maximus maximus]\nLCLYTHIGRNIYYGSYLYSETWNTGIMLLLITMATAFMGYVLPWGQMSFWGATVITNLFSAIPYIGTNLV\nEWIWGGFSVDKATLNRFFAFHFILPFTMVALAGVHLTFLHETGSNNPLGLTSDSDKIPFHPYYTIKDFLG\nLLILILLLLLLALLSPDMLGDPDNHMPADPLNTPLHIKPEWYFLFAYAILRSVPNKLGGVLALFLSIVIL\nGLMPFLHTSKHRSMMLRPLSQALFWTLTMDLLTLTWIGSQPVEYPYTIIGQMASILYFSIILAFLPIAGX\nIENY\n</code></pre> <p>A multiple-sequence FASTA format, or multi-FASTA format, would be obtained by concatenating several single-sequence FASTA files in one file. This does not imply a contradiction with the format as only the first line in a FASTA file may start with a \";\" or \"&gt;\", forcing all subsequent sequences to start with a \"&gt;\" in order to be taken as separate sequences (and further forcing the exclusive reservation of \"&gt;\" for the sequence definition line). Thus, the examples above would be a multi-FASTA file if taken together.</p> <p>Modern bioinformatics programs that rely on the FASTA format expect the sequence headers to be preceded by \"&gt;\". The sequence is generally represented as \"interleaved\", or on multiple lines as in the above example, but may also be \"sequential\", or on a single line. Running different bioinformatics programs may require conversions between \"sequential\" and \"interleaved\" FASTA formats.</p>"},{"location":"format_specifications/fasta/#description-line","title":"Description line","text":"<p>[ edit]</p> <p>The description line (defline) or header/identifier line, which begins with \"&gt;\", gives a name and/or a unique identifier for the sequence, and may also contain additional information. In a deprecated practice, the header line sometimes contained more than one header, separated by a ^A (Control-A) character. In the original Pearson FASTA format, one or more comments, distinguished by a semi-colon at the beginning of the line, may occur after the header. Some databases and bioinformatics applications do not recognize these comments and follow the NCBI FASTA specification. An example of a multiple sequence FASTA file follows:</p> <pre><code>&gt;SEQUENCE_1\nMTEITAAMVKELRESTGAGMMDCKNALSETNGDFDKAVQLLREKGLGKAAKKADRLAAEG\nLVSVKVSDDFTIAAMRPSYLSYEDLDMTFVENEYKALVAELEKENEERRRLKDPNKPEHK\nIPQFASRKQLSDAILKEAEEKIKEELKAQGKPEKIWDNIIPGKMNSFIADNSQLDSKLTL\nMGQFYVMDDKKTVEQVIAEKEKEFGGKIKIVEFICFEVGEGLEKKTEDFAAEVAAQL\n&gt;SEQUENCE_2\nSATVSEINSETDFVAKNDQFIALTKDTTAHIQSNSLQSVEELHSSTINGVKFEEYLKSQI\nATIGENLVVRRFATLKAGANGVVNGYIHTNGRVGVVIAAACDSAEVASKSRDLLRQICMH\n</code></pre>"},{"location":"format_specifications/fasta/#ncbi-identifiers","title":"NCBI identifiers","text":"<p>[ edit]</p> <p>The NCBI defined a standard for the unique identifier used for the sequence (SeqID) in the header line. This allows a sequence that was obtained from a database to be labelled with a reference to its database record. The database identifier format is understood by the NCBI tools like <code>makeblastdb</code> and <code>table2asn</code>. The following list describes the NCBI FASTA defined format for sequence identifiers.[9]</p> Type Format(s) Example(s) local (i.e. no database reference) <code>lcl|integer</code><code>lcl|string</code> <code>lcl|123</code><code>lcl|hmm271</code> GenInfo backbone seqid <code>bbs|integer</code> <code>bbs|123</code> GenInfo backbone moltype <code>bbm|integer</code> <code>bbm|123</code> GenInfo import ID <code>gim|integer</code> <code>gim|123</code> GenBank <code>gb|accession|locus</code> <code>gb|M73307|AGMA13GT</code> EMBL <code>emb|accession|locus</code> <code>emb|CAM43271.1|</code> PIR <code>pir|accession|name</code> <code>pir||G36364</code> SWISS-PROT <code>sp|accession|name</code> <code>sp|P01013|OVAX_CHICK</code> patent <code>pat|country|patent|sequence-number</code> <code>pat|US|RE33188|1</code> pre-grant patent <code>pgp|country|application-number|sequence-number</code> <code>pgp|EP|0238993|7</code> RefSeq <code>ref|accession|name</code> <code>ref|NM_010450.1|</code> general database reference(a reference to a database that's not in this list) <code>gnl|database|integer</code><code>gnl|database|string</code> <code>gnl|taxon|9606</code><code>gnl|PID|e1632</code> GenInfo integrated database <code>gi|integer</code> <code>gi|21434723</code> DDBJ <code>dbj|accession|locus</code> <code>dbj|BAC85684.1|</code> PRF <code>prf|accession|name</code> <code>prf||0806162C</code> PDB <code>pdb|entry|chain</code> <code>pdb|1I4L|D</code> third-party GenBank <code>tpg|accession|name</code> <code>tpg|BK003456|</code> third-party EMBL <code>tpe|accession|name</code> <code>tpe|BN000123|</code> third-party DDBJ <code>tpd|accession|name</code> <code>tpd|FAA00017|</code> TrEMBL <code>tr|accession|name</code> <code>tr|Q90RT2|Q90RT2_9HIV1</code> <p>The vertical bars (\"|\") in the above list are not separators in the sense of the Backus\u2013Naur form but are part of the format. Multiple identifiers can be concatenated, also separated by vertical bars.</p>"},{"location":"format_specifications/fasta/#sequence-representation","title":"Sequence representation","text":"<p>[ edit]</p> <p>Following the header line, the actual sequence is represented. Sequences may be protein sequences or nucleic acid sequences, and they can contain gaps or alignment characters (see sequence alignment). Sequences are expected to be represented in the standard IUB/IUPAC amino acid and nucleic acid codes, with these exceptions: lower-case letters are accepted and are mapped into upper-case; a single hyphen or dash can be used to represent a gap character; and in amino acid sequences, U and * are acceptable letters (see below). Numerical digits are not allowed but are used in some databases to indicate the position in the sequence. The nucleic acid codes supported are:[10][11][12]</p> Nucleic Acid Code Meaning Mnemonic A A A denine C C C ytosine G G G uanine T T T hymine U U U racil (i) i i nosine (non-standard) R A or G (I) pu R ine Y C, T or U p Y rimidines K G, T or U bases which are K etones M A or C bases with a M ino groups S C or G S trong interaction W A, T or U W eak interaction B not A (i.e. C, G, T or U) B comes after A D not C (i.e. A, G, T or U) D comes after C H not G (i.e., A, C, T or U) H comes after G V neither T nor U (i.e. A, C or G) V comes after U N A C G T U N ucleic acid - gap of indeterminate length <p>The amino acid codes supported (22 amino acids and 3 special codes) are:</p> Amino Acid Code Meaning A Alanine B Aspartic acid (D) or Asparagine (N) C Cysteine D Aspartic acid E Glutamic acid F Phenylalanine G Glycine H Histidine I Isoleucine J Leucine (L) or Isoleucine (I) K Lysine L Leucine M Methionine/ Start codon N Asparagine O Pyrrolysine (rare) P Proline Q Glutamine R Arginine S Serine T Threonine U Selenocysteine (rare) V Valine W Tryptophan Y Tyrosine Z Glutamic acid (E) or Glutamine (Q) X any * translation stop - gap of indeterminate length"},{"location":"format_specifications/fasta/#fasta-file","title":"FASTA file","text":"<p>[ edit]</p>"},{"location":"format_specifications/fasta/#filename-extension","title":"Filename extension","text":"<p>[ edit]</p> <p>There is no standard filename extension for a text file containing FASTA formatted sequences. The table below shows each extension and its respective meaning.</p> Extension Meaning Notes fasta, fas, fa[13] generic FASTA Any generic FASTA file fna FASTA nucleic acid Used generically to specify nucleic acids ffn FASTA nucleotide of gene regions Contains coding regions for a genome faa FASTA amino acid Contains amino acid sequences mpfa FASTA amino acids Contains multiple protein sequences frn FASTA non-coding RNA Contains non-coding RNA regions for a genome, e.g. tRNA, rRNA"},{"location":"format_specifications/fasta/#compression","title":"Compression","text":"<p>[ edit]</p> <p>The compression of FASTA files requires a specific compressor to handle both channels of information: identifiers and sequence. For improved compression results, these are mainly divided into two streams where the compression is made assuming independence. For example, the algorithm MFCompress[14] performs lossless compression of these files using context modelling and arithmetic encoding. Genozip,[15] a software package for compressing genomic files, uses an extensible context-based model. Benchmarks of FASTA file compression algorithms have been reported by Hosseini et al. in 2016,[16] and Kryukov et al. in 2020.[17]</p>"},{"location":"format_specifications/fasta/#encryption","title":"Encryption","text":"<p>[ edit]</p> <p>The encryption of FASTA files can be performed with various tools, including Cryfa and Genozip. Cryfa uses AES encryption and also enables data compression.[18][19] Similarly, Genozip can encrypt FASTA files with AES-256 during compression.[15]</p>"},{"location":"format_specifications/fasta/#extensions","title":"Extensions","text":"<p>[ edit]</p> <p>FASTQ format is a form of FASTA format extended to indicate information related to sequencing. It is created by the Sanger Centre in Cambridge.[3]</p> <p>A2M/A3M are a family of FASTA-derived formats used for sequence alignments. In A2M/A3M sequences, lowercase characters are taken to mean insertions, which are then indicated in the other sequences as the dot (\".\") character. The dots can be discarded for compactness without loss of information. As with typical FASTA files used in alignments, the gap (\"-\") is taken to mean exactly one position.[20] A3M is similar to A2M, with the added rule that gaps aligned to insertions can too be discarded.[21]</p>"},{"location":"format_specifications/fasta/#working-with-fasta-files","title":"Working with FASTA files","text":"<p>[ edit]</p> <p>A plethora of user-friendly scripts are available from the community to perform FASTA file manipulations. Online toolboxes, such as FaBox[22] or the FASTX-Toolkit within Galaxy servers, are also available.[23] These can be used to segregate sequence headers/identifiers, rename them, shorten them, or extract sequences of interest from large FASTA files based on a list of wanted identifiers (among other available functions). A tree-based approach to sorting multi-FASTA files (TREE2FASTA[24]) also exists based on the coloring and/or annotation of sequences of interest in the FigTree viewer. Additionally, the Bioconductor Biostrings package can be used to read and manipulate FASTA files in R.[25]</p> <p>Several online format converters exist to rapidly reformat multi-FASTA files to different formats (e.g. NEXUS, PHYLIP) for use with different phylogenetic programs, such as the converter available on phylogeny.fr.[26]</p>"},{"location":"format_specifications/fasta/#see-also","title":"See also","text":"<p>[ edit]</p> <ul> <li>The FASTQ format, used to represent DNA sequencer reads along with quality scores.</li> <li>The SAM and CRAM formats, used to represent genome sequencer reads that have been aligned to genome sequences.</li> <li>The GVF format (Genome Variation Format), an extension based on the GFF3 format.</li> </ul>"},{"location":"format_specifications/fastq/","title":"FASTQ format","text":"<p>FASTQ format is a text-based format for storing both a biological sequence (usually nucleotide sequence) and its corresponding quality scores. Both the sequence letter and quality score are each encoded with a single ASCII character for brevity.</p> <p>It was originally developed at the Wellcome Trust Sanger Institute to bundle a FASTA formatted sequence and its quality data, but has become the de facto standard for storing the output of high-throughput sequencing instruments such as the Illumina Genome Analyzer.[1]</p>"},{"location":"format_specifications/fastq/#format","title":"Format","text":"<p>[ edit]</p> <p>A FASTQ file has four line-separated fields per sequence:</p> <ul> <li>Field 1 begins with a '@' character and is followed by a sequence identifier and an optional description (like a FASTA title line).</li> <li>Field 2 is the raw sequence letters.</li> <li>Field 3 begins with a '+' character and is optionally followed by the same sequence identifier (and any description) again.</li> <li>Field 4 encodes the quality values for the sequence in Field 2, and must contain the same number of symbols as letters in the sequence.</li> </ul> <p>A FASTQ file containing a single sequence might look like this:</p> <pre><code>@SEQ_ID\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\n</code></pre> <p>The byte representing quality runs from 0x21 (lowest quality; '!' in ASCII) to 0x7e (highest quality; '~' in ASCII). Here are the quality value characters in left-to-right increasing order of quality ( ASCII):</p> <pre><code>!\"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n</code></pre> <p>The original Sanger FASTQ files split long sequences and quality strings over multiple lines, as is typically done for FASTA files. Accounting for this makes parsing more complicated due to the choice of \"@\" and \"+\" as markers (as these characters can also occur in the quality string). Multi-line FASTQ files (and consequently multi-line FASTQ parsers) are less common now that the majority of sequencing carried out is short-read Illumina sequencing, with typical sequence lengths of around 100bp.</p>"},{"location":"format_specifications/fastq/#illumina-sequence-identifiers","title":"Illumina sequence identifiers","text":"<p>[ edit]</p> <p>Sequences from the Illumina software use a systematic identifier:</p> <pre><code>@HWUSI-EAS100R:6:73:941:1973#0/1\n</code></pre> <p>| HWUSI-EAS100R | the unique instrument name | | 6 | flowcell lane | | 73 | tile number within the flowcell lane | | 941 | 'x'-coordinate of the cluster within the tile | | 1973 | 'y'-coordinate of the cluster within the tile | | #0 | index number for a multiplexed sample (0 for no indexing) | | /1 | the member of a pair, /1 or /2 (paired-end or mate-pair reads only) |</p> <p>Versions of the Illumina pipeline since 1.4 appear to use #NNNNNN instead of #0 for the multiplex ID, where NNNNNN is the sequence of the multiplex tag.</p> <p>With Casava 1.8 the format of the '@' line has changed:</p> <pre><code>@EAS139:136:FC706VJ:2:2104:15343:197393 1:Y:18:ATCACG\n</code></pre> <p>| EAS139 | the unique instrument name | | 136 | the run id | | FC706VJ | the flowcell id | | 2 | flowcell lane | | 2104 | tile number within the flowcell lane | | 15343 | 'x'-coordinate of the cluster within the tile | | 197393 | 'y'-coordinate of the cluster within the tile | | 1 | the member of a pair, 1 or 2 (paired-end or mate-pair reads only) | | Y | Y if the read is filtered (did not pass), N otherwise | | 18 | 0 when none of the control bits are on, otherwise it is an even number | | ATCACG | index sequence |</p> <p>Note that more recent versions of Illumina software output a sample number (defined by the order of the samples in the sample sheet) in place of an index sequence when an index sequence is not explicitly specified for a sample in the sample sheet. For example, the following header might appear in a FASTQ file belonging to the first sample of a batch of samples:</p> <pre><code>@EAS139:136:FC706VJ:2:2104:15343:197393 1:N:18:1\n</code></pre>"},{"location":"format_specifications/fastq/#ncbi-sequence-read-archive","title":"NCBI Sequence Read Archive","text":"<p>[ edit]</p> <p>FASTQ files from the INSDC Sequence Read Archive often include a description, e.g.</p> <pre><code>@SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=36\nGGGTGATGGCCGCTGCCGATGGCGTCAAATCCCACC\n+SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=36\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IG9IC\n</code></pre> <p>In this example there is an NCBI-assigned identifier, and the description holds the original identifier from Solexa/Illumina (as described above) plus the read length. Sequencing was performed in paired-end mode (~500bp insert size), see SRR001666. The default output format of fastq-dump produces entire spots, containing any technical reads and typically single or paired-end biological reads.</p> <pre><code>$ fastq-dump.2.9.0 -Z -X 2 SRR001666\nRead 2 spots for SRR001666\nWritten 2 spots for SRR001666\n@SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=72\nGGGTGATGGCCGCTGCCGATGGCGTCAAATCCCACCAAGTTACCCTTAACAACTTAAGGGTTTTCAAATAGA\n+SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=72\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IG9ICIIIIIIIIIIIIIIIIIIIIDIIIIIII&gt;IIIIII/\n@SRR001666.2 071112_SLXA-EAS1_s_7:5:1:801:338 length=72\nGTTCAGGGATACGACGTTTGTATTTTAAGAATCTGAAGCAGAAGTCGATGATAATACGCGTCGTTTTATCAT\n+SRR001666.2 071112_SLXA-EAS1_s_7:5:1:801:338 length=72\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII6IBIIIIIIIIIIIIIIIIIIIIIIIGII&gt;IIIII-I)8I\n</code></pre> <p>Modern usage of FASTQ almost always involves splitting the spot into its biological reads, as described in submitter-provided metadata:</p> <pre><code>$ fastq-dump -X 2 SRR001666 --split-3\nRead 2 spots for SRR001666\nWritten 2 spots for SRR001666\n$ head SRR001666_1.fastq  SRR001666_2.fastq\n==&gt; SRR001666_1.fastq &lt;==\n@SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=36\nGGGTGATGGCCGCTGCCGATGGCGTCAAATCCCACC\n+SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=36\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IG9IC\n@SRR001666.2 071112_SLXA-EAS1_s_7:5:1:801:338 length=36\nGTTCAGGGATACGACGTTTGTATTTTAAGAATCTGA\n+SRR001666.2 071112_SLXA-EAS1_s_7:5:1:801:338 length=36\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII6IBI\n\n==&gt; SRR001666_2.fastq &lt;==\n@SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=36\nAAGTTACCCTTAACAACTTAAGGGTTTTCAAATAGA\n+SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length=36\nIIIIIIIIIIIIIIIIIIIIDIIIIIII&gt;IIIIII/\n@SRR001666.2 071112_SLXA-EAS1_s_7:5:1:801:338 length=36\nAGCAGAAGTCGATGATAATACGCGTCGTTTTATCAT\n+SRR001666.2 071112_SLXA-EAS1_s_7:5:1:801:338 length=36\nIIIIIIIIIIIIIIIIIIIIIIGII&gt;IIIII-I)8I\n</code></pre> <p>When present in the archive, fastq-dump can attempt to restore read names to original format. NCBI does not store original read names by default:</p> <pre><code>$ fastq-dump -X 2 SRR001666 --split-3 --origfmt\nRead 2 spots for SRR001666\nWritten 2 spots for SRR001666\n$ head SRR001666_1.fastq  SRR001666_2.fastq\n==&gt; SRR001666_1.fastq &lt;==\n@071112_SLXA-EAS1_s_7:5:1:817:345\nGGGTGATGGCCGCTGCCGATGGCGTCAAATCCCACC\n+071112_SLXA-EAS1_s_7:5:1:817:345\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IG9IC\n@071112_SLXA-EAS1_s_7:5:1:801:338\nGTTCAGGGATACGACGTTTGTATTTTAAGAATCTGA\n+071112_SLXA-EAS1_s_7:5:1:801:338\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII6IBI\n\n==&gt; SRR001666_2.fastq &lt;==\n@071112_SLXA-EAS1_s_7:5:1:817:345\nAAGTTACCCTTAACAACTTAAGGGTTTTCAAATAGA\n+071112_SLXA-EAS1_s_7:5:1:817:345\nIIIIIIIIIIIIIIIIIIIIDIIIIIII&gt;IIIIII/\n@071112_SLXA-EAS1_s_7:5:1:801:338\nAGCAGAAGTCGATGATAATACGCGTCGTTTTATCAT\n+071112_SLXA-EAS1_s_7:5:1:801:338\nIIIIIIIIIIIIIIIIIIIIIIGII&gt;IIIII-I)8I\n</code></pre> <p>In the example above, the original read names were used rather than the accessioned read name. NCBI accessions runs and the reads they contain. Original read names, assigned by sequencers, are able to function as locally unique identifiers of a read, and convey exactly as much information as a serial number. The ids above were algorithmically assigned based upon run information and geometric coordinates. Early SRA loaders parsed these ids and stored their decomposed components internally. NCBI stopped recording read names because they are frequently modified from the vendors' original format in order to associate some additional information meaningful to a particular processing pipeline, and this caused name format violations that resulted in a high number of rejected submissions. Without a clear schema for read names, their function remains that of a unique read id, conveying the same amount of information as a read serial number. See various SRA Toolkit issues for details and discussions.</p> <p>Also note that fastq-dump converts this FASTQ data from the original Solexa/Illumina encoding to the Sanger standard (see encodings below). This is because the SRA serves as a repository for NGS information, rather than format. The various *-dump tools are capable of producing data in several formats from the same source. The requirements for doing so have been dictated by users over several years, with the majority of early demand coming from the 1000 Genomes Project.</p>"},{"location":"format_specifications/fastq/#variations","title":"Variations","text":"<p>[ edit]</p>"},{"location":"format_specifications/fastq/#quality","title":"Quality","text":"<p>[ edit]</p> <p>A quality value Q is an integer mapping of p (i.e., the probability that the corresponding base call is incorrect). Two different equations have been in use. The first is the standard Sanger variant to assess reliability of a base call, otherwise known as Phred quality score:</p> <p>Qsanger=\u221210log10\u2061p{\\displaystyle Q_{\\text{sanger}}=-10\\,\\log _{10}p}</p> <p>The Solexa pipeline (i.e., the software delivered with the Illumina Genome Analyzer) earlier used a different mapping, encoding the odds p/(1- p) instead of the probability p:</p> <p>Qsolexa-prior to v.1.3=\u221210log10\u2061p1\u2212p{\\displaystyle Q_{\\text{solexa-prior to v.1.3}}=-10\\,\\log _{10}{\\frac {p}{1-p}}}</p> <p>Although both mappings are asymptotically identical at higher quality values, they differ at lower quality levels (i.e., approximately p &gt; 0.05, or equivalently, Q &lt; 13).</p> <p> Relationship between Q and p using the Sanger (red) and Solexa (black) equations (described above). The vertical dotted line indicates p = 0.05, or equivalently, Q \u2248 13.</p> <p>At times there has been disagreement about which mapping Illumina actually uses. The user guide (Appendix B, page 122) for version 1.4 of the Illumina pipeline states that: \"The scores are defined as \u2060Q=10\u22c5log10\u2061p1\u2212p{\\displaystyle Q=10\\cdot \\log _{10}{\\tfrac {p}{1-p}}}\u2060 [ sic], where p is the probability of a base call corresponding to the base in question\".[2] In retrospect, this entry in the manual appears to have been an error. The user guide (What's New, page 5) for version 1.5 of the Illumina pipeline lists this description instead: \"Important Changes in Pipeline v1.3 [ sic]. The quality scoring scheme has changed to the Phred [i.e., Sanger] scoring scheme, encoded as an ASCII character by adding 64 to the Phred value. A Phred score of a base is: Qphred=\u221210log10\u2061e{\\displaystyle Q_{\\text{phred}}=-10\\log _{10}e}, where e is the estimated probability of a base being wrong.[3]</p>"},{"location":"format_specifications/fastq/#encoding","title":"Encoding","text":"<p>[ edit]</p> <ul> <li>Sanger format can encode a Phred quality score from 0 to 93 using ASCII 33 to 126 (although in raw read data the Phred quality score rarely exceeds 60, higher scores are possible in assemblies or read maps). Also used in SAM format.[4] Coming to the end of February 2011, Illumina's newest version (1.8) of their pipeline CASAVA will directly produce fastq in Sanger format, according to the announcement on seqanswers.com forum.[5]</li> <li>Element Biosciences AVITI reads are encoded following the Sanger convention: Phred quality scores from 0 to 93 are encoded using ASCII 33 to 126. Raw reads typically exhibit base quality scores in the range of [0, 55]. [6]</li> <li>PacBio HiFi reads, which are typically stored in SAM/BAM format, use the Sanger convention: Phred quality scores from 0 to 93 are encoded using ASCII 33 to 126. Raw PacBio subreads use the same convention but typically assign a placeholder base quality (Q0) to all bases in the read.[7]</li> <li>Oxford Nanopore Duplex reads, called using the dorado basecaller are typically stored in SAM/BAM format. After changing to a 16-bit internal quality representation, the reported base quality limit is q50 (S).[8]</li> <li>Solexa/Illumina 1.0 format can encode a Solexa/Illumina quality score from -5 to 62 using ASCII 59 to 126 (although in raw read data Solexa scores from -5 to 40 only are expected)</li> <li>Starting with Illumina 1.3 and before Illumina 1.8, the format encoded a Phred quality score from 0 to 62 using ASCII 64 to 126 (although in raw read data Phred scores from 0 to 40 only are expected).</li> <li>Starting in Illumina 1.5 and before Illumina 1.8, the Phred scores 0 to 2 have a slightly different meaning. The values 0 and 1 are no longer used and the value 2, encoded by ASCII 66 \"B\", is used also at the end of reads as a Read Segment Quality Control Indicator.[9] The Illumina manual[10] (page 30) states the following: If a read ends with a segment of mostly low quality (Q15 or below), then all of the quality values in the segment are replaced with a value of 2 (encoded as the letter B in Illumina's text-based encoding of quality scores)... This Q2 indicator does not predict a specific error rate, but rather indicates that a specific final portion of the read should not be used in further analyses. Also, the quality score encoded as \"B\" letter may occur internally within reads at least as late as pipeline version 1.6, as shown in the following example:</li> </ul> <pre><code>@HWI-EAS209_0006_FC706VJ:5:58:5894:21141#ATCACG/1\nTTAATTGGTAAATAAATCTCCTAATAGCTTAGATNTTACCTTNNNNNNNNNNTAGTTTCTTGAGATTTGTTGGGGGAGACATTTTTGTGATTGCCTTGAT\n+HWI-EAS209_0006_FC706VJ:5:58:5894:21141#ATCACG/1\nefcfffffcfeefffcffffffddf`feed]`]_Ba_^__[YBBBBBBBBBBRTT\\]][]dddd`ddd^dddadd^BBBBBBBBBBBBBBBBBBBBBBBB\n</code></pre> <p>An alternative interpretation of this ASCII encoding has been proposed.[11] Also, in Illumina runs using PhiX controls, the character 'B' was observed to represent an \"unknown quality score\". The error rate of 'B' reads was roughly 3 phred scores lower the mean observed score of a given run.</p> <ul> <li>Starting in Illumina 1.8, the quality scores have basically returned to the use of the Sanger format (Phred+33).</li> </ul> <p>For raw reads, the range of scores will depend on the technology and the base caller used, but will typically be up to 41 for recent Illumina chemistry. Since the maximum observed quality score was previously only 40, various scripts and tools break when they encounter data with quality values larger than 40. For processed reads, scores may be even higher. For example, quality values of 45 are observed in reads from Illumina's Long Read Sequencing Service (previously Moleculo).</p> <pre><code>  SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS.....................................................\n  ..........................XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX......................\n  ...............................IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII......................\n  .................................JJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ.....................\n  LLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL....................................................\n  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...........................................\n  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n  PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n \u00a0!\"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n  |                         |    |        |              |               |                     |\n 33                        59   64       73             88             104                   126\n  0........................26...31.......40\n                           -5....0........9.............................40\n                                 0........9.............................40\n                                    3.....9..............................41\n  0.2......................26...31........41\n  0..................20........30........40........50\n  0..................20........30........40........50...55\n  0..................20........30........40........50..........................................93\n</code></pre> <pre><code> S - Sanger        Phred+33,  raw reads typically (0, 40)\n X - Solexa        Solexa+64, raw reads typically (-5, 40)\n I - Illumina 1.3+ Phred+64,  raw reads typically (0, 40)\n J - Illumina 1.5+ Phred+64,  raw reads typically (3, 41)\n     with 0=unused, 1=unused, 2=Read Segment Quality Control Indicator (bold)\n     (Note: See discussion above).\n L - Illumina 1.8+ Phred+33,  raw reads typically (0, 41)\n N - Nanopore      Phred+33,  Duplex reads typically (0, 50)\n E - ElemBio AVITI Phred+33,  raw reads typically (0, 55)\n P - PacBio        Phred+33,  HiFi reads typically (0, 93)\n</code></pre>"},{"location":"format_specifications/fastq/#color-space","title":"Color space","text":"<p>[ edit]</p> <p>For SOLiD data, the format is modified to a color space FASTQ sequence (CSFASTQ), where bases in the sequence are combined with the numbers 0, 1, 2, and 3, indicating how bases are modified relative to the previous base in the sequence (0: no change; 1: transition; 2: non-complementary transversion; 3: complementary transversion).[1] This format matched the different sequencing chemistry used by SOLiD sequencers. Initial representations only used nucleotide bases at the start of the sequence, but later versions included bases embedded at periodic intervals to improve basecalling and mapping accuracy.</p> <p>The quality values for CSFASTQ are identical to those of the Sanger format. Alignment tools differ in their preferred version of the quality values: some include a quality score (set to 0, i.e. '!') for the leading nucleotide, others do not. The sequence read archive includes this quality score.</p>"},{"location":"format_specifications/fastq/#fast5-and-hdf5-evolutions","title":"FAST5 and HDF5 evolutions","text":"<p>[ edit]</p> <p>The FAST4 format was invented as a derivative of the FASTQ format where each of the 4 bases (A,C,G,T) had separate probabilities stored. It was part of the Swift basecaller, an open source package for primary data analysis on next-gen sequence data \"from images to basecalls\".</p> <p>The FAST5 format was invented as an extension of the FAST4 format. The FAST5 files are Hierarchical Data Format 5 (HDF5) files with a specific schema defined by Oxford Nanopore Technologies (ONT).[12]</p>"},{"location":"format_specifications/fastq/#simulation","title":"Simulation","text":"<p>[ edit]</p> <p>FASTQ read simulation has been approached by several tools.[13][14] A comparison of those tools can be seen here.[15]</p>"},{"location":"format_specifications/fastq/#compression","title":"Compression","text":"<p>[ edit]</p>"},{"location":"format_specifications/fastq/#general-compressors","title":"General compressors","text":"<p>[ edit]</p> <p>General-purpose tools such as Gzip and bzip2 regard FASTQ as a plain text file and result in suboptimal compression ratios. NCBI's Sequence Read Archive encodes metadata using the LZ-77 scheme. General FASTQ compressors typically compress distinct fields (read names, sequences, comments, and quality scores) in a FASTQ file separately; these include DSRC and DSRC2, FQC, LFQC, Fqzcomp, and Slimfastq.</p>"},{"location":"format_specifications/fastq/#reads","title":"Reads","text":"<p>[ edit]</p> <p>Having a reference genome around is convenient because then instead of storing the nucleotide sequences themselves, one can just align the reads to the reference genome and store the positions (pointers) and mismatches; the pointers can then be sorted according to their order in the reference sequence and encoded, e.g., with run-length encoding. When the coverage or the repeat content of the sequenced genome is high, this leads to a high compression ratio. Unlike the SAM/BAM formats, FASTQ files do not specify a reference genome. Alignment-based FASTQ compressors supports the use of either user-provided or de novo assembled reference: LW-FQZip uses a provided reference genome and Quip, Leon, k-Path and KIC perform de novo assembly using a de Bruijn graph-based approach.</p> <p>Explicit read mapping and de novo assembly are typically slow. Reordering-based FASTQ compressors first cluster reads that share long substrings and then independently compress reads in each cluster after reordering them or assembling them into longer contigs, achieving perhaps the best trade-off between the running time and compression rate. SCALCE is the first such tool, followed by Orcom and Mince. BEETL uses a generalized Burrows\u2013Wheeler transform for reordering reads, and HARC achieves better performance with hash-based reordering. AssemblTrie instead assembles reads into reference trees with as few total number of symbols as possible in the reference.[16][17]</p> <p>Benchmarks for these tools are available.[18]</p>"},{"location":"format_specifications/fastq/#quality-values","title":"Quality values","text":"<p>[ edit]</p> <p>Quality values account for about half of the required disk space in the FASTQ format (before compression), and therefore the compression of the quality values can significantly reduce storage requirements and speed up analysis and transmission of sequencing data. Both lossless and lossy compression are recently being considered in the literature. For example, the algorithm QualComp[19] performs lossy compression with a rate (number of bits per quality value) specified by the user. Based on rate-distortion theory results, it allocates the number of bits so as to minimize the MSE (mean squared error) between the original (uncompressed) and the reconstructed (after compression) quality values. Other algorithms for compression of quality values include SCALCE[20] and Fastqz.[21] Both are lossless compression algorithms that provide an optional controlled lossy transformation approach. For example, SCALCE reduces the alphabet size based on the observation that \u201cneighboring\u201d quality values are similar in general. For a benchmark, see.[22]</p> <p>As of the HiSeq 2500 Illumina gives the option to output qualities that have been coarse grained into quality bins. The binned scores are computed directly from the empirical quality score table, which is itself tied to the hardware, software and chemistry that were used during the sequencing experiment.[23]</p>"},{"location":"format_specifications/fastq/#file-extension","title":"File extension","text":"<p>[ edit]</p> <p>There is no standard file extension for a FASTQ file, but .fq and .fastq are commonly used.</p>"},{"location":"format_specifications/fastq/#format-converters","title":"Format converters","text":"<p>[ edit]</p> <ul> <li>Biopython version 1.51 onwards (interconverts Sanger, Solexa and Illumina 1.3+)</li> <li>EMBOSS version 6.1.0 patch 1 onwards (interconverts Sanger, Solexa and Illumina 1.3+)</li> <li>BioPerl version 1.6.1 onwards (interconverts Sanger, Solexa and Illumina 1.3+)</li> <li>BioRuby version 1.4.0 onwards (interconverts Sanger, Solexa and Illumina 1.3+)</li> <li>BioJava version 1.7.1 onwards (interconverts Sanger, Solexa and Illumina 1.3+)</li> </ul>"},{"location":"format_specifications/fastq/#see-also","title":"See also","text":"<p>[ edit]</p> <ul> <li>The FASTA format, used to represent genome sequences.</li> <li>The SAM and CRAM formats, used to represent genome sequencer reads that have been aligned to genome sequences.</li> <li>The GVF format (Genome Variation Format), an extension based on the GFF3 format.</li> </ul>"},{"location":"format_specifications/gff3/","title":"Gff3","text":""},{"location":"format_specifications/gff3/#generic-feature-format-version-3-gff3","title":"Generic Feature Format Version 3 (GFF3)","text":""},{"location":"format_specifications/gff3/#summary","title":"Summary","text":"<p>Author: Lincoln Stein Date: 18 August 2020 Version: 1.26</p> <p>Although there are many richer ways of representing genomic features via XML and in relational database schemas, the stubborn persistence of a variety of ad-hoc tab-delimited flat file formats declares the bioinformatics community's need for a simple format that can be modified with a text editor and processed with shell tools like grep. The GFF format, although widely used, has fragmented into multiple incompatible dialects. When asked why they have modified the published Sanger specification, bioinformaticists frequently answer that the format was insufficient for their needs, and they needed to extend it. The proposed GFF3 format addresses the most common extensions to GFF, while preserving backward compatibility with previous formats. The new format:</p> <ol> <li>Adds a mechanism for representing more than one level of hierarchical grouping of features and subfeatures.</li> <li>Separates the ideas of group membership and feature name/id.</li> <li>Constrains the feature type field to be taken from a controlled vocabulary.</li> <li>Allows a single feature, such as an exon, to belong to more than one group at a time.</li> <li>Provides an explicit convention for pairwise alignments.</li> <li>Provides an explicit convention for features that occupy disjunct regions.</li> </ol>"},{"location":"format_specifications/gff3/#gff3-validator","title":"GFF3 Validator","text":"<p>GFF3 validation tools are available at modENCODE-DCC</p>"},{"location":"format_specifications/gff3/#description-of-the-format","title":"Description of the Format","text":"<p>GFF3 files are nine-column, tab-delimited, plain text files. Literal use of tab, newline, carriage return, the percent (%) sign, and control characters must be encoded using RFC 3986 Percent-Encoding; no other characters may be encoded. Backslash and other ad-hoc escaping conventions that have been added to the GFF format are not allowed. The file contents may include any character in the set supported by the operating environment, although for portability with other systems, use of UTF-8 is recommended.</p> <ul> <li>tab (%09)</li> <li>newline (%0A)</li> <li>carriage return (%0D)</li> <li>% percent (%25)</li> <li>control characters (%00 through %1F, %7F)</li> </ul> <p>In addition, the following characters have reserved meanings in column 9 and must be escaped when used in other contexts:</p> <ul> <li>; semicolon (%3B)</li> <li>= equals (%3D)</li> <li>&amp; ampersand (%26)</li> <li>, comma (%2C)</li> </ul> <p>Note that unescaped spaces are allowed within fields, meaning that parsers must split on tabs, not spaces. Use of the \"+\" (plus) character to encode spaces is deprecated from early versions of the spec and is no longer allowed.</p> <p>Undefined fields are replaced with the \".\" character, as described in the original GFF spec.</p> Column 1: \"seqid\" The ID of the landmark used to establish the coordinate system for the current feature. IDs may contain any characters, but must escape any characters not in the set [a-zA-Z0-9.:^*$@!+_?-|]. In particular, IDs may not contain unescaped whitespace and must not begin with an unescaped \"&gt;\". Column 2: \"source\" The source is a free text qualifier intended to describe the algorithm or operating procedure that generated this feature. Typically this is the name of a piece of software, such as \"Genescan\" or a database name, such as \"Genbank.\" In effect, the source is used to extend the feature ontology by adding a qualifier to the type creating a new composite type that is a subclass of the type in the type column. Column 3: \"type\" The type of the feature (previously called the \"method\"). This is constrained to be either a term from the Sequence Ontology or an SO accession number. The latter alternative is distinguished using the syntax SO:000000. In either case, it must be sequence_feature (SO:0000110) or an is_a child of it. Columns 4 &amp; 5: \"start\" and \"end\" <p>The start and end coordinates of the feature are given in positive 1-based integer coordinates, relative to the landmark given in column one. Start is always less than or equal to end. For features that cross the origin of a circular feature (e.g. most bacterial genomes, plasmids, and some viral genomes), the requirement for start to be less than or equal to end is satisfied by making end = the position of the end + the length of the landmark feature.</p> <p>For zero-length features, such as insertion sites, start equals end and the implied site is to the right of the indicated base in the direction of the landmark.</p> Column 6: \"score\" The score of the feature, a floating point number. As in earlier versions of the format, the semantics of the score are ill-defined. It is strongly recommended that E-values be used for sequence similarity features, and that P-values be used for ab initio gene prediction features. Column 7: \"strand\" The strand of the feature. + for positive strand (relative to the landmark), - for minus strand, and . for features that are not stranded. In addition, ? can be used for features whose strandedness is relevant, but unknown. Column 8: \"phase\" <p>For features of type \"CDS\", the phase indicates where the next codon begins relative to the 5' end (where the 5' end of the CDS is relative to the strand of the CDS feature) of the current CDS feature. For clarification the 5' end for CDS features on the plus strand is the feature's start and and the 5' end for CDS features on the minus strand is the feature's end.  The phase is one of the integers 0, 1, or 2, indicating the number of bases forward from the start of the current CDS feature the next codon begins.  A phase of \"0\" indicates that a codon begins on the first nucleotide of the CDS feature (i.e. 0 bases forward), a phase of \"1\" indicates that the codon begins at the second nucleotide of this CDS feature and a phase of \"2\" indicates that the codon begins at the third nucleotide of this region. Note that \u2018Phase\u2019 in the context of a GFF3 CDS feature should not be confused with the similar concept of frame that is also a common concept in bioinformatics.  Frame is generally calculated as a value for a given base relative to the start of the complete open reading frame (ORF) or the codon (e.g.  modulo 3) while CDS phase describes the start of the next codon relative to a given CDS feature. <p>The phase is REQUIRED for all CDS features.</p> Column 9: \"attributes\" <p>A list of feature attributes in the format tag=value. Multiple tag=value pairs are separated by semicolons. URL escaping rules are used for tags or values containing the following characters: \",=;\". Spaces are allowed in this field, but tabs must be replaced with the %09 URL escape. Attribute values do not need to be and should not be quoted. The quotes should be included as part of the value by parsers and not stripped.</p> <p>These tags have predefined meanings:</p> ID Indicates the ID of the feature.   The ID attribute is required for  features that have children (e.g. gene and mRNAs), or for those that span multiple lines, but are optional for other features.  IDs for each feature must be unique within the scope of the GFF file. In the case of discontinuous features (i.e. a single feature that exists over multiple genomic locations) the same ID may appear on multiple lines. All lines that share an ID must collectively represent a single feature. Name Display name for the feature. This is the name to be displayed to the user. Unlike IDs, there is no requirement that the Name be unique within the file. Alias A secondary name for the feature. It is suggested that this tag be used whenever a secondary identifier for the feature is needed, such as locus names and accession numbers. Unlike ID, there is no requirement that Alias be unique within the file. Parent Indicates the parent of the feature. A parent ID can be used to group exons into transcripts, transcripts into genes, an so forth. A feature may have multiple parents. Parent can only be used to indicate a partof relationship. Target Indicates the target of a nucleotide-to-nucleotide or protein-to-nucleotide alignment. The format of the value is \"target_id start end [strand]\", where strand is optional and may be \"+\" or \"-\". If the target_id contains spaces, they must be escaped as hex escape %20. Gap The alignment of the feature to the target if the two are not collinear (e.g. contain gaps). The alignment format is inspired from the CIGAR format described in the Exonerate documentation. Derives_from Used to disambiguate the relationship between one feature and another when the relationship is a temporal one rather than a purely structural \"part of\" one. This is needed for polycistronic genes. See \"PATHOLOGICAL CASES\" for further discussion. Note A free text note. Dbxref A database cross reference. See the section \"Ontology Associations and Db Cross References\" for details on the format. Ontology_term A cross reference to an ontology term. See the section \"Ontology Associations and Db Cross References\" for details. Is_circular A flag to indicate whether a feature is circular. See extended discussion below. <p>Multiple attributes of the same type are indicated by separating the values with the comma \",\" character, as in:</p> <pre>Parent=AF2312,AB2812,abc-3</pre> <p>In addition to Parent, the Alias, Note, Dbxref and Ontology_term attributes can have multiple values.</p> <p>Note that attribute names are case sensitive. \"Parent\" is not the same as \"parent\".</p> <p>All attributes that begin with an uppercase letter are reserved for later use. Attributes that begin with a lowercase letter can be used freely by applications.</p>"},{"location":"format_specifications/gff3/#the-canonical-gene","title":"The Canonical Gene","text":"<p> FIGURE 1</p> <p>This section describes the representation of a protein-coding gene in GFF3. To illustrate how a canonical gene is represented, consider Figure 1 (figure1.png). This indicates a gene named EDEN extending from position 1000 to position 9000. It encodes three alternatively-spliced transcripts named EDEN.1, EDEN.2 and EDEN.3, the last of which has two alternative translational start sites leading to the generation of two protein coding sequences.</p> <p>There is also an identified transcriptional factor binding site located 50 bp upstream from the transcriptional start site of EDEN.1 and EDEN2.</p> <p>Here is how this gene should be described using GFF3:</p> <pre><code> 0  ##gff-version 3.1.26\n 1  ##sequence-region ctg123 1 1497228\n 2  ctg123 . gene            1000  9000  .  +  .  ID=gene00001;Name=EDEN\n 3  ctg123 . TF_binding_site 1000  1012  .  +  .  ID=tfbs00001;Parent=gene00001\n 4  ctg123 . mRNA            1050  9000  .  +  .  ID=mRNA00001;Parent=gene00001;Name=EDEN.1\n 5  ctg123 . mRNA            1050  9000  .  +  .  ID=mRNA00002;Parent=gene00001;Name=EDEN.2\n 6  ctg123 . mRNA            1300  9000  .  +  .  ID=mRNA00003;Parent=gene00001;Name=EDEN.3\n 7  ctg123 . exon            1300  1500  .  +  .  ID=exon00001;Parent=mRNA00003\n 8  ctg123 . exon            1050  1500  .  +  .  ID=exon00002;Parent=mRNA00001,mRNA00002\n 9  ctg123 . exon            3000  3902  .  +  .  ID=exon00003;Parent=mRNA00001,mRNA00003\n10  ctg123 . exon            5000  5500  .  +  .  ID=exon00004;Parent=mRNA00001,mRNA00002,mRNA00003\n11  ctg123 . exon            7000  9000  .  +  .  ID=exon00005;Parent=mRNA00001,mRNA00002,mRNA00003\n12  ctg123 . CDS             1201  1500  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1\n13  ctg123 . CDS             3000  3902  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1\n14  ctg123 . CDS             5000  5500  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1\n15  ctg123 . CDS             7000  7600  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1\n16  ctg123 . CDS             1201  1500  .  +  0  ID=cds00002;Parent=mRNA00002;Name=edenprotein.2\n17  ctg123 . CDS             5000  5500  .  +  0  ID=cds00002;Parent=mRNA00002;Name=edenprotein.2\n18  ctg123 . CDS             7000  7600  .  +  0  ID=cds00002;Parent=mRNA00002;Name=edenprotein.2\n19  ctg123 . CDS             3301  3902  .  +  0  ID=cds00003;Parent=mRNA00003;Name=edenprotein.3\n20  ctg123 . CDS             5000  5500  .  +  1  ID=cds00003;Parent=mRNA00003;Name=edenprotein.3\n21  ctg123 . CDS             7000  7600  .  +  1  ID=cds00003;Parent=mRNA00003;Name=edenprotein.3\n22  ctg123 . CDS             3391  3902  .  +  0  ID=cds00004;Parent=mRNA00003;Name=edenprotein.4\n23  ctg123 . CDS             5000  5500  .  +  1  ID=cds00004;Parent=mRNA00003;Name=edenprotein.4\n24  ctg123 . CDS             7000  7600  .  +  1  ID=cds00004;Parent=mRNA00003;Name=edenprotein.4\n</code></pre> <p>Lines beginning with '##' are directives (sometimes called pragmas or meta-data) and provide meta-information about the document as a whole. Blank lines should be ignored by parsers and lines beginning with a single '#' are used for human-readable comments and can be ignored by parsers. End-of-line comments (comments preceded by # at the end of and on the same line as a feature or directive line) are not allowed.</p> <p>Line 0 gives the GFF version using the ##gff-version pragma. Line 1 indicates the boundaries of the region being annotated (a 1,497,228 bp region named \"ctg123\") using the ##sequence-region pragma.</p> <p>Line 2 defines the boundaries of the gene. Column 9 of this line assigns the gene an ID of gene00001, and a human-readable name of EDEN. Because the gene is not part of a larger feature, it has no Parent.</p> <p>Line 3 annotates the transcriptional factor binding site. Since it is logically part of the gene, its Parent attribute is gene00001.</p> <p>Lines 4-6 define this gene's three spliced transcripts, one line for the full extent of each of the mRNAs. These features are necessary to act as parents for the four CDSs which derive from them, as well as the structural parents of the five exons in the alternative splicing set.</p> <p>Lines 7-11 identify the five exons. The Parent attributes indicate which mRNAs the exons belong to. Notice that several of the exons share the same parents, using the comma symbol to indicate multiple parentage.</p> <p>Lines 12-24 denote this gene's four CDSs. Each CDS belongs to one of the mRNAs. cds00003 and cds00004, which correspond to alternative start codons, belong to the same mRNA.</p> <p>Note that several of the features, including the gene, its mRNAs and the CDSs, all have Name attributes. This attributes assigns those features a public name, but is not mandatory. The ID attributes are only mandatory for those features that have children (the gene and mRNAs), or for those that span multiple lines. The IDs are not required to have meaning outside the file in which they reside. Hence, a slightly simplified version of this file would look like this:</p> <pre><code>##gff-version 3.1.26\n##sequence-region ctg123 1 1497228\nctg123 . gene            1000 9000  .  +  .  ID=gene00001;Name=EDEN\nctg123 . TF_binding_site 1000 1012  .  +  .  Parent=gene00001\nctg123 . mRNA            1050 9000  .  +  .  ID=mRNA00001;Parent=gene00001\nctg123 . mRNA            1050 9000  .  +  .  ID=mRNA00002;Parent=gene00001\nctg123 . mRNA            1300 9000  .  +  .  ID=mRNA00003;Parent=gene00001\nctg123 . exon            1300 1500  .  +  .  Parent=mRNA00003\nctg123 . exon            1050 1500  .  +  .  Parent=mRNA00001,mRNA00002\nctg123 . exon            3000 3902  .  +  .  Parent=mRNA00001,mRNA00003\nctg123 . exon            5000 5500  .  +  .  Parent=mRNA00001,mRNA00002,mRNA00003\nctg123 . exon            7000 9000  .  +  .  Parent=mRNA00001,mRNA00002,mRNA00003\nctg123 . CDS             1201 1500  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS             3000 3902  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS             5000 5500  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS             7000 7600  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS             1201 1500  .  +  0  ID=cds00002;Parent=mRNA00002\nctg123 . CDS             5000 5500  .  +  0  ID=cds00002;Parent=mRNA00002\nctg123 . CDS             7000 7600  .  +  0  ID=cds00002;Parent=mRNA00002\nctg123 . CDS             3301 3902  .  +  0  ID=cds00003;Parent=mRNA00003\nctg123 . CDS             5000 5500  .  +  1  ID=cds00003;Parent=mRNA00003\nctg123 . CDS             7000 7600  .  +  1  ID=cds00003;Parent=mRNA00003\nctg123 . CDS             3391 3902  .  +  0  ID=cds00004;Parent=mRNA00003\nctg123 . CDS             5000 5500  .  +  1  ID=cds00004;Parent=mRNA00003\nctg123 . CDS             7000 7600  .  +  1  ID=cds00004;Parent=mRNA00003\n</code></pre> NOTE 1 <p>SO or SOFA IDs: If using the SO (or SOFA) IDs rather than the short names1 (\"mRNA\" etc), use the following mappings:</p> gene SO:0000704 mRNA SO:0000234 exon SO:0000147 cds SO:0000316 <p>Other mRNA parts that you might wish to use are:</p> intron SO:0000188 (redundant with exon) polyA_sequence SO:0000610 (part of the three_prime_UTR) polyA_site SO:0000553 (part of the gene) five_prime_UTR SO:0000204 three_prime_UTR SO:0000205 NOTE 2 \"Orphan\" exons CDSs, and other features. Ab initio gene prediction programs call hypothetical exons and CDS's that are attached to the genomic sequence and not necessarily to a known transcript. To handle these features, you may either (1) create a placeholder mRNA and use it as the parent for the exon and CDS subfeatures; or (2) attach the exons and CDSs directly to the gene. This is allowed by SO because of the transitive nature of the part_of relationship. NOTE 3 UTRs, splice sites and translational start and stop sites. These are implied by the combination of exon and CDS and do not need to be explicitly annotated as part of the canonical gene. In the case of annotating predicted splice or translational start/stop sites independently of a particular gene, it is suggested that they be attached directly to the genomic sequence and not to a gene or a subpart of a gene. NOTE 4 CDS features MUST have have a defined phase field. Otherwise it is not possible to infer the correct polypeptides corresponding to partially annotated genes. NOTE 5 The START and STOP codons are included in the CDS. That is, if the locations of the start and stop codons are known, the first three base pairs of the CDS should correspond to the start codon and the last three correspond the stop codon."},{"location":"format_specifications/gff3/#circular-genomes","title":"Circular Genomes","text":"<p>For a circular genome, the landmark feature should include Is_circular=true in column 9. In the example below, from bacteriophage f1, gene II extends across the origin from positions 6477-831. The feature end is given as length of the landmark feature, J02448, plus the distance from the origin to the end of gene II (6407 + 831 = 7238).</p> <pre><code>##gff-version 3.1.26\n# organism Enterobacteria phage f1\n# Note Bacteriophage f1, complete genome.\nJ02448  GenBank region  1      6407    .       +       .       ID=J02448;Name=J02448;Is_circular=true;\nJ02448  GenBank CDS     6006   7238    .       +       0       ID=geneII;Name=II;Note=protein II;\n</code></pre>"},{"location":"format_specifications/gff3/#representing-spliced-non-coding-transcripts","title":"Representing Spliced Non-Coding Transcripts","text":"<p>For spliced non-coding transcripts, such as those produced by some processed snRNAs and viruses, use a parent feature of \"noncoding_transcript\" and a child of \"exon.\"</p>"},{"location":"format_specifications/gff3/#parent-part_of-relationships","title":"Parent (part_of) Relationships","text":"<p>The reserved Parent attribute can be used to establish a part-of relationship between two features. A feature that has the Parent attribute set is interpreted as asserting that it is a part of the specified Parent feature.</p> <p>Features must respect the Sequence Ontology Part-Of relationships. A Parent relationship between two features that is not one of the Part-Of relationships listed in SO should trigger a parse exception Similarly, a set of Parent relationships that would cause a cycle should also trigger an exception.</p> <p>The GFF3 format does not enforce a rule in which features must be wholly contained within the location of their parents, since some elements of the Sequence Ontology (e.g. enhancers in genes) allow for distant cis relationships.</p>"},{"location":"format_specifications/gff3/#the-gap-attribute","title":"The Gap Attribute","text":"<p>Protein and nucleotide alignment features typically consist of two sequences, the reference sequence and the \"target\", and are not always colinear. For example, consider the following alignment between an EST (\"EST23\") and a segment of the genome (\"chr3\"):</p> <pre><code>chr3  (reference)  1 CAAGACCTAAACTGGAT-TCCAAT  23\nEST23 (target)     1 CAAGACCT---CTGGATATCCAAT  21\n</code></pre> <p>Previous versions of the GFF format would represent this alignment as three colinear segments, but this made it difficult to reconstruct the gapped alignment. GFF3 recommends representing gapped alignments explicitly with the \"Gap\" attribute. The Gap attribute's format consists of a series of (operation,length) pairs separated by space characters, for example \"M8 D3 M6\". Each operation is a single-letter code:</p> Code Operation M match I insert a gap into the reference sequence D insert a gap into the target (delete from reference) F frameshift forward in the reference sequence R frameshift reverse in the reference sequence <p>In the alignment between EST23 and chr3 shown above, chr3 is the reference sequence referred to in the first column of the GFF3 file, and EST23 is the sequence referred to by the Target attribute. This gives a Gap string of \"M8 D3 M6 I1 M6\". The full GFF match line will read:</p> <pre><code>chr3 . Match 1 23 . . . ID=Match1;Target=EST23 1 21;Gap=M8 D3 M6 I1 M6\n</code></pre> <p>For protein to nucleotide matches, the M, I and D operations apply to amino acid residues in the target and nucleotide base pairs in the reference in a 1:3 residue. That is, \"M2\" means to match two amino residues in the target to six base pairs in the reference. Hence this alignment:</p> <pre><code>100 atgaaggag---gttattgcgaatgtcggcggt\n  1 M..K..E..V..V..I..-..N..V..G..G..\n</code></pre> <p>Corresponds to this GFF3 Line:</p> <pre><code>ctg123 . nucleotide_to_protein 100 129 . + . ID=match008;Target=p101 1 10;Gap=M3 I1 M2 D1 M4\n</code></pre> <p>In addition, the Gap attribute provides &lt;F&gt;orward and &lt;R&gt;everse frameshift operators to allow for frameshifts in the alignment. These are in nucleotide coordinates: a forward frameshift skips forward the indicated number of base pairs, while a reverse frameshift moves backwards. Examples:</p> <pre><code>100 atgaaggag---gttattgaatgtcggcggt     Gap=M3 I1 M2 F1 M4\n  1 M..K..E..V..V..I...\n                        N..V..G..G\n\n100 atgaaggag---gttataatgtcggcggt       Gap=M3 I1 M2 R1 M4\n  1 M..K..E..V..V..I.\n                      N..V..G..G\n</code></pre>"},{"location":"format_specifications/gff3/#alignments","title":"Alignments","text":"<p>In the SO, an alignment between the reference sequence and another sequence is called a \"match\". In addition to the generic \"match\" type, there are the subclasses:</p> <ul> <li>cDNA_match</li> <li>EST_match</li> <li>translated_nucleotide_match</li> <li>nucleotide_to_protein_match</li> <li>nucleotide_motif</li> </ul> <p>Matches typically contain gaps; matches broken up by large gaps are usually called \"HSPs\" (high-scoring segment pair), and previous incarnations of GFF have handled gapped alignments by breaking up the alignment into a series of ungapped HSPs.</p> <p>The SO does not have an HSP type. Instead, gapped matches are represented as a single feature that occupies a discontinuous location on the reference sequence. Figure 2 shows the same gene as before, but with a new track added showing an alignment of a sequenced cDNA to the genome. For the purposes of illustration, we have shown the regions of alignment to be exact across the three exons of the second spliced transcript (EDEN.2).</p> <p> FIGURE 2</p> <p>The recommended way to represent this alignment is with a single feature of type \"cDNA_match\" and a Gap attribute that indicates that the alignment is in three segments:</p> <pre><code>ctg123 . cDNA_match 1050  9000  6.2e-45  +  .    ID=match00001;Target=cdna0123 12 2964;Gap=M451 D3499 M501 D1499 M2001\n</code></pre> <p>Parsed out, the Target attribute indicates that the sequence named \"cdna0123\" between bases 12 and 2964 (in cdna coordinates) aligns to bases 1050 to 9000 of ctg123. The Gap attribute is easier to read when spaces are inserted:</p> M451 match 451 bases D3499 skip 3499 bases in the reference ctg123 sequence M501 match the next 501 bases D1499 skip 1499 bases in the reference ctg123 M2001 match the next 2001 bases <p>Note that the matched region is 2953 bases, which corresponds exactly to the matching subsequence [12,2964] of the target. Extra bases in the cDNA which would cause gaps in the reference sequence would be indicated using the CIGAR \"I\" notation.</p> <p>Another important item to note is that the ID corresponds to the Match and not to the target sequence. This avoids the confusion that has occurred in previous incarnations of GFF which made it impossible to distinguish between a particular alignment of a target sequence to the genome and all alignments of a target sequence to the genome.</p> <p>A limitation of the Gap representation is that the entire alignment shares the same score (column 6). To give each component of the match a separate score, it can be broken across multiple lines as shown here:</p> <pre><code>ctg123 . cDNA_match 1050  1500  5.8e-42 +  . ID=match00001;Target=cdna0123 12  462\nctg123 . cDNA_match 5000  5500  8.1e-43 +  . ID=match00001;Target=cdna0123 463 963\nctg123 . cDNA_match 7000  9000  1.4e-40 +  . ID=match00001;Target=cdna0123 964 2964\n</code></pre> <p>Notice that the ID is the same across each of the three lines, indicating that these lines all refer to a single feature, the Match. Each aligning segment, however has a distinct score and Target region.</p> <p>The two types of representations can be mixed, allowing large aligned segments to have their own GFF line and score, while small gaps within them are represented using a Gap attribute.</p> <p>Matches can align to either the + or the - strand of the reference sequence. This should be denoted in the seventh column of the GFF line and not by changing the order of the start and end positions in the Target attribute. To illustrate this, Figure 3 adds an EST pair to the annotation. The two ESTs, mjm1123.5 and mum1123.3 correspond to 5' and 3' EST reads from the same cDNA clone. The following GFF3 lines describe them:</p> <pre><code>ctg123 . EST_match 1200  3200  2.2e-30  +  .    ID=match00002;Target=mjm1123.5 5 506;Gap=M301 D1499 M201\nctg123 . EST_match 7000  9000  7.4e-32  -  .    ID=match00003;Target=mjm1123.3 1 502;Gap=M101 D1499 M401\n</code></pre> <p>Please note that the subsequence indicated by the Target always uses the coordinate system of the EST, regardless of the direction of the alignment. For the 3' EST, the seventh column contains a \"-\" to indicate that the match is to the reverse complement of ctg123. The Gap attribute does not change as a consequence of this reverse complementation, and is read from left to right in the usual manner.</p> <p>An application may wish to group the EST pair into a single feature. This can be accomplished by creating an implied cDNA_match that extends from the left end of the first EST to the right end of the last EST, and indicating that this cDNA match is the Parent of the two ESTs. The parts of the match use the SO \"match_part\" term. A match_part can be used as a subpart of any type of match.</p> <pre><code>ctg123 . cDNA_match  1200  9000  .        .  .    ID=cDNA00001\nctg123 . match_part  1200  3200  2.2e-30  +  .    ID=match00002;Parent=cDNA00001;Target=mjm1123.5 5 506;Gap=M301 D1499 M201\nctg123 . match_part  7000  9000  7.4e-32  -  .    ID=match00003;Parent=cDNA00001;Target=mjm1123.3 1 502;Gap=M101 D1499 M401\n</code></pre> <p> FIGURE 3</p>"},{"location":"format_specifications/gff3/#transcript-relative-alignments","title":"Transcript-Relative Alignments","text":"<p>The representation of strandedness in nucleotide-to-nucleotide and protein-to-nucleotide alignments is a common source of confusion in GFF files. This section will attempt to explain it.</p>"},{"location":"format_specifications/gff3/#case-1-alignment-to-a-strand-transcript","title":"Case #1: alignment to a + strand transcript","text":"<p>Consider a pair of EST matches to the genome:</p> <pre><code>=============================  genome\n    -------------------&gt;       transcript\n    ------&gt;        &lt;----\n     EST_A (5')    EST_B (3')\n</code></pre> <p>EST_A is a 5' EST and its sequence (as represented in a FASTA file, for example) is in the same strand as the genomic sequence. It is represented as:</p> <pre><code>ctg123 . EST_match 1000 1500 . + . ID=match001;Target=EST_A 1 500 +\n</code></pre> <p>The strand field in column #7 is \"+\" indicating that the match is to the forward strand of the genome. The optional strand field in the Target attribute is also +, indicating that the alignment is to the plus strand of the implied underlying transcript.</p> <p>Let us now consider EST_B, which is a 3' EST. Its sequence as represented in the FASTA file aligns to the reverse complement of the genomic sequence. It is represented as:</p> <pre><code>ctg123 . EST_match 2000 2500 . + . ID=match002;Target=EST_B 1 500 -\n</code></pre> <p>The strand field in column #7 is \"+\" indicating that the match is to a transcript feature on the forward of the genome. The strand field in the Target attribute is -, indicating that the EST sequence should be reverse complemented in order to align to the underlying transcript.</p>"},{"location":"format_specifications/gff3/#case-2-alignment-to-a-strand-transcript","title":"Case #2: alignment to a - strand transcript","text":"<p>Here is the opposite case:</p> <pre><code>=============================  genome\n&lt;--------------------          transcript\n ------&gt;        &lt;----\n EST_D (3')  EST_C (5')\n</code></pre> <p>In this case, the 5' EST_C aligns to the reverse complement of the forward strand of the genome, while the 3' EST_D aligns to the forward strand directly. These are represented as follows:</p> <pre><code>ctg123 . EST_match  2000 2500 . - . ID=match001;Target=EST_C 1 500 +\nctg123 . EST_match  1000 1500 . - . ID=match001;Target=EST_D 1 500 -\n</code></pre> <p>The first line indicates that the transcript is on the - strand of the genome, and that EST_C aligns to the transcripts forward strand. The second line uses - in the 7th column to indicate that the transcript is on the minus strand, and - in the Target field to indicate that EST_D aligns to the minus strand of the transcript.</p> <p>Confused? Just remember that for purposes of display, the source and target strands will be multiplied together. A +/+ or -/- alignment indicates that the reference sequence and the target sequence can be aligned directly. A +/- or -/+ alignment indicates that the target must be reverse complemented in order to align to the plus strand of the reference sequence.</p> <p>A similar rule applies to TBLASTX alignments, which rely on matching the six-frame translation of the source to the six-frame translation of the target. Consider the case of two genomes that align together in the forward direction, whose alignment is supported by translations of genes A and B, one of which is on the plus strand, and the other on the minus strand:</p> <pre><code>=============================&gt;  genome X\n     ------&gt;        &lt;----\n     gene A          gene B\n=============================&gt; genome Y\n</code></pre> <p>These two alignments will be represented as:</p> <pre><code>X TBLASTX translated_nucleotide_match 1000 1500 . + . ID=matchA;Target=Y 500  1000 +\nX TBLASTX translated_nucleotide_match 2000 2500 . - . ID=matchB;Target=Y 1500 2000 -\n</code></pre> <p>Note that the first alignment is +/+ and the second is -/-. Both indicate that the sequences of genomes X and Y can be aligned directly.</p> <p>Now we look at the case of two genomes that align in the antiparallel direction:</p> <pre><code>=============================&gt; genome X\n     ------&gt;        &lt;----\n     gene A          gene B\n&lt;============================= genome Y\n</code></pre> <p>These two alignments will be represented as:</p> <pre><code>X TBLASTX translated_nucleotide_match 1000 1500 . + . ID=matchA;Target=Y 500  1000 -\nX TBLASTX translated_nucleotide_match 2000 2500 . - . ID=matchB;Target=Y 1500 2000 +\n</code></pre> <p>The first match indicates that a plus strand feature of genome X aligns to a minus strand feature of genome Y. The second match indicates that a minus strand feature of genome X aligns to a plus strand feature of genome Y. In both cases, the result is to align the plus strand of genome X to the minus strand of genome Y.</p>"},{"location":"format_specifications/gff3/#ontology-associations-and-db-cross-references","title":"Ontology Associations and DB Cross References","text":"<p>Two reserved attributes, Ontology_term and Dbxref, can be used to establish links between a GFF3 feature and a data record contained in another database. Ontology_term is reserved for associations to ontologies, such as the Gene Ontology. Dbxref is used for all other cross references. While there is no firm boundary line between these two concepts, curators tend to treat ontology associations differently and hence ontology terms have been given their own reserved attribute label.</p> <p>The value of both Ontology_term and Dbxref is the ID of the cross referenced object in the form \"DBTAG:ID\". The DBTAG indicates which database the referenced object can be found in, and ID indicates the identifier of the object within that database. IDs can contain unescaped colons but DBTAGs cannot, so parsing code should split on the first colon encountered in the attribute value.</p> <p>The format of each type of ID varies from database to database. An authoritative list of databases, their DBTAGs, and the URL transformation rules that can be used to fetch the objects given their IDs can be found at this location: ftp://ftp.geneontology.org/pub/go/doc/GO.xrf_abbs</p> <p>Further details can be found here: ftp://ftp.geneontology.org/pub/go/doc/GO.xrf_abbs_spec</p> <p>Here are some common examples:</p> a dbxref to an EMBL sequence accession number: Dbxref=\"EMBL:AA816246\" a dbxref to an NCBI gi number: Dbxref=\"NCBI_gi:10727410\" an Ontology_term referring to a GO association Ontology_term=\"GO:0046703\""},{"location":"format_specifications/gff3/#other-syntax","title":"Other Syntax","text":"<p>Comment lines begin with the '#' symbol. End-of-line comments (comments preceded by '#' at the end of and on the same line as a feature or directive line) are not allowed. Directive lines (sometimes referred to as pragmas or meta-data) are preceded by '##'. Application specific directives are allowed, but are not required to be supported by parsers. The following directives are specified:</p> ##gff-version 3.1.26 The GFF version follows the format of 3.#.# in this spec. This directive must be present, must be the topmost line of the file. The version number always begins with 3, the second and third numbers are optional and indicate a major revision and a minor revision respectively. ##sequence-region seqid start end The sequence segment referred to by this file, in the format \"seqid start end\". This element is optional, but strongly encouraged because it allows parsers to perform bounds checking on features. There may be multiple ##sequence-region directives, each corresponding to one of the reference sequences referred to in the body of the file, however only one ##sequence-region directive may be given for any given seqid. While a ##sequence-region pragma is not required for any or all landmark features when one is given all features on that landmark feature (having that seqid) must be contained within the range defined by that ##sequence-region directive. An exception to this rule is allowed when a landmark feature is marked with the Is_circular attribute. In that case the features contained on that landmark may extend their coordinates beyond the boundary as described above. ##feature-ontology URI <p>This directive indicates that the GFF3 file uses the ontology of feature types located at the indicated URI or URL. Multiple URIs may be added, in which case they are merged (or raise an exception if they cannot be merged). The URIs for the released sequence ontologies are:</p> <ul> <li>                 Release 1: 5/12/2004                 http://song.cvs.sourceforge.net/*checkout*/song/ontology/sofa.obo?revision=1.6             </li> <li>                 Release 2: 5/16/2005                 http://song.cvs.sourceforge.net/*checkout*/song/ontology/sofa.obo?revision=1.12i             </li> <li>                 Release 2.4.3 06/01/2010                 <ul> <li>                         SO:                         http://song.cvs.sourceforge.net/viewvc/*checkout*/song/ontology/so.obo?revision=1.263                     </li> <li>                         SOFA:                         http://song.cvs.sourceforge.net/viewvc/*checkout*/song/ontology/sofa.obo?revision=1.217                     </li> </ul> <p>Releases occur every two months for SO and SOFA.</p> <p>The repository for SO releases is here: http://sourceforge.net/projects/song/files/Sequence%20Ontology/</p> <p>The repository for SOFA releases is here: http://sourceforge.net/projects/song/files/SO_Feature_Annotation/</p> <p>This directive may occur several times per file. If no feature ontology is specified, then the most recent release of the Sequence Ontology is assumed.</p> <p>If multiple directives are given and a feature type is matched by multiple ontologies, the matching ontology included by the directive highest in the file wins the reference. The Sequence Ontology itself is always referenced last.</p> <p>The content referenced by URI must be in OBO or DAG-Edit format.</p> </li> </ul> ##attribute-ontology URI This directive indicates that the GFF3 uses the ontology of attribute names located at the indicated URI or URL. This directive may appear multiple times to load multiple URIs, in which case they are merged (or raise an exception if merging is not possible). Currently no formal attribute ontologies exist, so this attribute is for future extension. ##source-ontology URI This directive indicates that the GFF3 uses the ontology of source names located at the indicated URI or URL. This directive may appear multiple times to load multiple URIs, in which case they are merged (or raise an exception if merging is not possible). Currently no formal source ontologies exist, so this attribute is for future extension. ##species NCBI_Taxonomy_URI          This directive indicates the species that the annotations apply to. The preferred format is a NCBI URL that points to the relevant species page in either of the following formats:         <ul> <li>http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=6239</li> <li>http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?name=Caenorhabditis+elegans</li> </ul> ##genome-build source buildName <p>The genome assembly build name used for the coordinates given in the file. Please specify the source of the assembly as well as its name. Examples (the parentheses are comments):</p> <pre>\n##genome-build NCBI B36           (human)\n##genome-build WormBase ws110     (worm)\n##genome-build FlyBase r4.1       (drosophila)</pre> ### This directive (three # signs in a row) indicates that all forward references to feature IDs that have been seen to this point have been resolved. After seeing this directive, a program that is processing the file serially can close off any open objects that it has created and return them, thereby allowing iterative access to the file. Otherwise, software cannot know that a feature has been fully populated by its subfeatures until the end of the file has been reached. It is recommended that complex features, such as the canonical gene, be terminated with the ### notation. ##FASTA <p>This notation indicates that the annotation portion of the file is at an end and that the remainder of the file contains one or more sequences (nucleotide or protein) in FASTA format. This allows features and sequences to be bundled together. All FASTA sequences included in the file must be included together at the end of the file and may not be interspersed with the features lines. Once a ##FASTA section is encountered no other content beyond valid FASTA sequence is allowed.</p> <p>Example:</p> <pre>\n##gff-version 3.1.26\n##sequence-region ctg123 1 1497228\nctg123 . gene               1000  9000  .  +  .  ID=gene00001;Name=EDEN\nctg123 . TF_binding_site    1000  1012  .  +  .  ID=tfbs00001;Parent=gene00001\nctg123 . mRNA               1050  9000  .  +  .  ID=mRNA00001;Parent=gene00001;Name=EDEN.1\nctg123 . five_prime_UTR     1050  1200  .  +  .  Parent=mRNA00001\nctg123 . CDS                1201  1500  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS                3000  3902  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS                5000  5500  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . CDS                7000  7600  .  +  0  ID=cds00001;Parent=mRNA00001\nctg123 . three_prime_UTR    7601  9000  .  +  .  Parent=mRNA00001\nctg123 . cDNA_match         1050  1500  5.8e-42  +  . ID=match00001;Target=cdna0123+12+462\nctg123 . cDNA_match         5000  5500  8.1e-43  +  . ID=match00001;Target=cdna0123+463+963\nctg123 . cDNA_match         7000  9000  1.4e-40  +  . ID=match00001;Target=cdna0123+964+2964\n##FASTA\n&gt;ctg123\ncttctgggcgtacccgattctcggagaacttgccgcaccattccgccttg\ntgttcattgctgcctgcatgttcattgtctacctcggctacgtgtggcta\ntctttcctcggtgccctcgtgcacggagtcgagaaaccaaagaacaaaaa\naagaaattaaaatatttattttgctgtggtttttgatgtgtgttttttat\naatgatttttgatgtgaccaattgtacttttcctttaaatgaaatgtaat\ncttaaatgtatttccgacgaattcgaggcctgaaaagtgtgacgccattc\ngtatttgatttgggtttactatcgaataatgagaattttcaggcttaggc\nttaggcttaggcttaggcttaggcttaggcttaggcttaggcttaggctt\naggcttaggcttaggcttaggcttaggcttaggcttaggcttaggcttag\naatctagctagctatccgaaattcgaggcctgaaaagtgtgacgccattc\n...\n&gt;cnda0123\nttcaagtgctcagtcaatgtgattcacagtatgtcaccaaatattttggc\nagctttctcaagggatcaaaattatggatcattatggaatacctcggtgg\naggctcagcgctcgatttaactaaaagtggaaagctggacgaaagtcata\ntcgctgtgattcttcgcgaaattttgaaaggtctcgagtatctgcatagt\ngaaagaaaaatccacagagatattaaaggagccaacgttttgttggaccg\ntcaaacagcggctgtaaaaatttgtgattatggttaaagg</pre> <p>For backward-compatibility with the GFF version output by the Artemis tool, a GFF line that begins with the character &gt; creates an implied ##FASTA directive.</p>"},{"location":"format_specifications/gff3/#pathological-cases","title":"Pathological Cases","text":"<p>The following section discusses how to represent \"pathological\" cases that arise in prokaryotic and eukaryotic genetics. Most of these have to do with organisms' endlessly creative ways of processing transcripts.</p> Single exon genes <p>This is the case in which a single unspliced transcript encodes a single CDS.</p> <pre>-----&gt;XXXXXXX*------&gt;</pre> <p>The preferred representation is to create a gene, a transcript, an exon and a CDS:</p> <pre>\nchrX  . gene XXXX YYYY  .  +  . ID=gene01;name=resA\nchrX  . mRNA XXXX YYYY  .  +  . ID=tran01;Parent=gene01\nchrX  . exon XXXX YYYY  .  +  . Parent=tran01\nchrX  . CDS  XXXX YYYY  .  +  . Parent=tran01</pre> <p>Some groups will find this redundant. A valid alternative is to omit the exon feature:</p> <pre>\nchrX  . gene XXXX YYYY  .  +  . ID=gene01;name=resA\nchrX  . mRNA XXXX YYYY  .  +  . ID=tran01;Parent=gene01\nchrX  . CDS  XXXX YYYY  .  +  . Parent=tran01</pre> <p>It is not recommended to parent the CDS directly onto the gene, because this will make it impossible to determine the UTRs (since the gene may validly include untranscribed regulatory regions).</p> <p>Also note that mixing the two styles, as in the case of an organism with both spliced and unspliced transcripts, is liable to lead to the confusion of people working with the GFF3 file.</p> Polycistronic transcripts <p>This is the case in which a single (possibly spliced) transcript encodes multiple open reading frames that generate independent protein products.</p> <pre>-----&gt;XXXXXXX*--&gt;BBBBBB*---&gt;ZZZZ*--&gt;AAAAAA*-----</pre> <p>Since the single transcript corresponds to multiple genes that can be identified by genetic analysis, the recommended solution here is to create four \"gene\" objects and make them the parent for a single transcript. The transcript will contain a single exon (in the unspliced case) and four separate CDSs:</p> <pre>\nchrX  . gene XXXX YYYY  .  +  . ID=gene01;name=resA\nchrX  . gene XXXX YYYY  .  +  . ID=gene02;name=resB\nchrX  . gene XXXX YYYY  .  +  . ID=gene03;name=resX\nchrX  . gene XXXX YYYY  .  +  . ID=gene04;name=resZ\nchrX  . mRNA XXXX YYYY  .  +  . ID=tran01;Parent=gene01,gene02,gene03,gene04\nchrX  . exon XXXX YYYY  .  +  . ID=exon00001;Parent=tran01\nchrX  . CDS  XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene01\nchrX  . CDS  XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene02\nchrX  . CDS  XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene03\nchrX  . CDS  XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene04</pre> <p>To disambiguate the relationship between which genes encode which CDSs, you may use the Derives_from relationship.</p> Gene containing an intein <p>An intein occurs when a portion of the protein is spliced out and the two polypeptide fragments are rejoined to become a functional protein. The portion that is spliced out is called the \"intein,\" and it may itself have intrinsic molecular activity:</p> <pre>\n-----&gt;XXXXXXyyyyyyyyyyXXXXXXX*-------\n(yyyyyy is the intein)</pre> <p>The preferred representation is to create one gene, one transcript, one exon, and one CDS. The CDS produces a pre-polypeptide using the \"Derives_from\" tag, and this polypeptide in turn gives rise to two mature_polypeptides, one each for the intein and the flanking protein:</p> <pre>\nchrX  . gene               XXXX YYYY  .  +  . ID=gene01;name=resA\nchrX  . mRNA               XXXX YYYY  .  +  . ID=tran01;Parent=gene01\nchrX  . exon               XXXX YYYY  .  +  . Parent=tran01\nchrX  . CDS                XXXX YYYY  .  +  . ID=cds01;Parent=tran01\nchrX  . polypeptide        XXXX YYYY  .  +  . ID=poly01;Derives_from=cds01\nchrX  . mature_polypeptide XXXX YYYY  .  +  . ID=poly02;Parent=poly01\nchrX  . mature_polypeptide XXXX YYYY  .  +  . ID=poly02;Parent=poly01\nchrX  . intein             XXXX YYYY  .  +  . ID=poly03;Parent=poly01</pre> <p>Because the flanking mature_polypeptide has discontinuous coordinates on the genome, it appears twice with the same ID.</p> <p>If the intein is immediately degraded, you may not wish to annotate it explicitly, and its line would be deleted from the example. However, if it has molecular activity, it may correspond to a gene, in which case:</p> <pre>\nchrX  . gene               XXXX YYYY  .  +  . ID=gene01;name=resA\nchrX  . gene               XXXX YYYY  .  +  . ID=gene02;name=inteinA\nchrX  . mRNA               XXXX YYYY  .  +  . ID=tran01;Parent=gene01,gene02\nchrX  . exon               XXXX YYYY  .  +  . Parent=tran01\nchrX  . CDS                XXXX YYYY  .  +  . ID=cds01;Parent=tran01\nchrX  . polypeptide        XXXX YYYY  .  +  . ID=poly01;Derives_from=cds01\nchrX  . mature_polypeptide XXXX YYYY  .  +  . ID=poly02;Parent=poly01;Derives_from=gene01\nchrX  . mature_polypeptide XXXX YYYY  .  +  . ID=poly02;Parent=poly01;Derives_from=gene01\nchrX  . intein             XXXX YYYY  .  +  . ID=poly03;Parent=poly01;Derives_from=gene02</pre> <p>The term \"polypeptide\" is part of SO. The terms \"mature_polypeptide\" and \"intein\" are slated to be added in a pending release.</p> Trans-spliced transcript <p>This occurs when two genes contribute to a processed transcript via a trans-splicing reaction:</p> <pre>\nspliced\nleader\n=======&gt;-----&gt;XXXXXXX*------&gt;</pre> <p>The simplest way to represent this is to show the mRNA as being split across two discontinuous genomic locations:</p> <pre>\nchrX  . gene               XXXX YYYY  .  +  . ID=gene01;name=my_gene\nchrX  . mRNA               XXXX YYYY  .  +  . ID=tran01;Parent=gene01\nchrX  . mRNA               XXXX YYYY  .  +  . ID=tran01;Parent=gene01\nchrX  . exon               XXXX YYYY  .  +  . Parent=tran01\nchrX  . CDS                XXXX YYYY  .  +  . ID=cds01;Parent=tran01</pre> <p>However, this does not indicate which part of the transcript comes from the spliced leader. A preferred representation explicitly adds features for the spliced leader gene, the primary_transcript and the spliced_leader_RNA:</p> <pre>\nchrX  . gene               XXXX YYYY  .  +  . ID=gene01;name=my_gene\nchrX  . gene               XXXX YYYY  .  +  . ID=gene02;name=leader_gene\nchrX  . mRNA               XXXX YYYY  .  +  . ID=tran01;Parent=gene01,gene02\nchrX  . mRNA               XXXX YYYY  .  +  . ID=tran01;Parent=gene01,gene02\nchrX  . primary_transcript XXXX YYYY  .  +  . ID=pt01;Parent=tran01;Derives_from=gene01\nchrX  . spliced_leader_RNA XXXX YYYY  .  +  . ID=sl01;Parent=tran01;Derives_from=gene02\nchrX  . exon               XXXX YYYY  .  +  . Parent=tran01\nchrX  . CDS                XXXX YYYY  .  +  . ID=cds01;Parent=tran01</pre> <p>As shown here, the mRNA derives from two genes (\"my_gene\" and the leader gene) and occupies disjunct coordinates on the genome. The primary_transcript, which encodes the body of the mRNA, is part of (has as its Parent) this mRNA. The same relationship applies to the spliced leader RNA. The Derives_from relationship is used to indicate which genes produced the primary transcript and spliced leader respectively.</p> <p>The exon and CDS features follow in the normal fashion.</p> Programmed frameshift <p>This event occurs when the ribosome performs a programmed frameshift during translation in order to skip over an in-frame stop codon. The frameshift may occur forward or backward.</p> <pre>\n-------------------------&gt; mRNA\n==========\n          ============*  CDS</pre> <p>The representation of this is to make the CDS discontinuous:</p> <pre>\nchrX  . gene               XXXX   YYYY .  +  . ID=gene01;name=my_gene\nchrX  . mRNA               XXXX   YYYY .  +  . ID=tran01;Parent=gene01;Ontology_term=SO:1000069\nchrX  . exon               XXXX   YYYY .  +  . Parent=tran01\nchrX  . CDS                XXXX   YYYY .  +  0 ID=cds01;Parent=tran01\nchrX  . CDS                YYYY-1 ZZZZ .  +  0 ID=cds01;Parent=tran01</pre> <p>The CDS segment that represent the new reading frame will always has a phase of 0 since the ribosome is moving and thus redefining the codon.</p> <p>It is suggested that the mRNA be tagged with the appropriate SO transcript attributes such as \"minus_1_translational_frameshift\" (SO:1000069). This will allow all such programmed frameshift mRNAs to be recovered with a query. The accession for \"plus_1_translational_frameshift\" is SO:1001263.</p> An operon <p>A classic operon occurs when the genes in a polycistronic transcript are co-regulated by cis-regulatory element(s):</p> <pre>\nregulatory element\n* ================================================&gt; operon\n-----&gt;XXXXXXX*--&gt;BBBBBB*---&gt;ZZZZ*--&gt;AAAAAA*-----</pre> <p>It can be indicated in GFF3 in this way:</p> <pre>\nchrX  . operon   XXXX YYYY  .  +  . ID=operon01;name=my_operon\nchrX  . promoter XXXX YYYY  .  +  . Parent=operon01\nchrX  . gene     XXXX YYYY  .  +  . ID=gene01;Parent=operon01;name=resA\nchrX  . gene     XXXX YYYY  .  +  . ID=gene02;Parent=operon01;name=resB\nchrX  . gene     XXXX YYYY  .  +  . ID=gene03;Parent=operon01;name=resX\nchrX  . gene     XXXX YYYY  .  +  . ID=gene04;Parent=operon01;name=resZ\nchrX  . mRNA     XXXX YYYY  .  +  . ID=tran01;Parent=gene01,gene02,gene03,gene04\nchrX  . exon     XXXX YYYY  .  +  . ID=exon00001;Parent=tran01\nchrX  . CDS      XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene01\nchrX  . CDS      XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene02\nchrX  . CDS      XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene03\nchrX  . CDS      XXXX YYYY  .  +  . Parent=tran01;Derives_from=gene04</pre> <p>The regulatory element (\"promoter\" in this example) is part of the operon via the Parent tag. The four genes are part of the operon, and the resulting mRNA is multiply-parented by the four genes, as in the earlier example.</p> <p>At the time of this writing, promoters and other cis-regulatory elements cannot be part_of an operon, but this restriction is being reconsidered.</p> miRNA extension <p>mirGFF3 format is adapted from the GFF3 definition to contain miRNA/isomiRs information from miRNA-seq data. The main difference is at the Attributes column, where these fields are mandatory: Variant, Cigar, Hits, Expression and Filter. To understand more about each one, please visit the main repository https://github.com/miRTop/mirGFF3</p>"},{"location":"format_specifications/gff3/#change-log","title":"Change Log","text":"1.26 Tue 18 Aug 2020 <ul> <li>More internal links (thanks to Juke34).</li> <li>Switched to the actual GFF3 version number in examples.</li> <li>Standardized date format in changelog.</li> <li>Fixed typos (thanks to lbergelson) and formatting.</li> <li>UTF-8 is now the only recommended character encoding.</li> </ul> 1.25 Tue 24 Sep 2019 <ul> <li>Added clarifications to CDS phase based on discussions with jbethune.</li> </ul> 1.24 Mon 15 Jul 2019 <ul> <li>Added miRNA extension to the pathological cases.</li> </ul> 1.23 Fri 3 Oct 2016 <ul> <li>Added SO:0000110 sequence_feature as allowable under Column 3: \"type\".</li> </ul> 1.22 Mon 2 May 2016 <ul> <li>Converted from HTML to Markdown.</li> </ul> 1.21 Tue 26 Feb 2013 <ul> <li>Clarification of escaping conventions.</li> <li>Explicit requirement that the value of start and end be one-based positive integers.</li> <li>Clarification to the use of quotes in attribute values.</li> <li>Clarification of lines beginning with # and exclusion of inline comments.</li> <li>Clarification that the ##gff-version pragma only appears once in a file.</li> <li>Clarification to the ##sequence-region pragma.</li> </ul> 1.20 Wed 15 Dec 2010 <ul> <li>Added language to the description of the ID attribute to clarify that discontinuous features can exist on multiple lines and share the same ID.</li> </ul> 1.19 Tue 6 Jul 2010 <ul> <li>Fixed coordinate errors in the EST_match and match_part examples in the 'Alignments' section.</li> <li>Constrained multiple attribute values to the Parent, Alias, Note, Dbxref and Ontology_term attributes.</li> </ul> 1.18 Thu 24 Jun 2010 <ul> <li>Added the sections regarding circular genomes to the spec.</li> </ul> 1.17 Wed 2 Jun 2010 <ul> <li>Changed the spec to include Sequence Ontology (SO) sequence_feature terms in column 3 as well as SOFA terms. (SOFA is a subset of SO).</li> </ul> 1.16 Tue 25 May 2010 <ul> <li>Fixed more incorrect CDS phases throughout.</li> <li>Changed (three|five)_prime_utr to (three|five)_prime_UTR throughout.</li> <li>Changed (3'|5')-UTR to (three|five)_prime_UTR throughout.</li> <li>Added ID attributes to CDS features (required for multiline features) in the FASTA pragma example.</li> </ul> 1.15 Mon 31 Aug 2009 <ul> <li>Fixed incorrect CDS phases in the canonical gene example.</li> </ul> 1.14 Mon 25 Aug 2008 <ul> <li>Add meta-directives for species and build number.</li> </ul> 1.13 Wed 23 May 2007 <ul> <li>Insist that CDS include the start and end codon.</li> </ul> 1.12 Thu 5 Apr 2007 <ul> <li>Use \"match_part\" as the subpart of cDNA_match in the paired EST example.</li> <li>Phase is required for all CDS features.</li> </ul> 1.11 Fri 1 Dec 2006 <ul> <li>Clarified definition of phase relative to reverse strand features.</li> </ul> 1.10 Thu 14 Sep 2006 <ul> <li>Reformatted for new SO web site.</li> </ul> 1.09 Wed 6 Sep 2006 <ul> <li>Information about the GFF3 validator.</li> </ul> 1.08 Tue 18 Jul 2006 <ul> <li>Added URLs for SO releases.</li> </ul> 1.07 Wed 24 May 2006 <ul> <li>Fixed description of phase (temporarily lost due to CVS glitches).</li> </ul> 1.06 Wed 24 May 2006 <ul> <li>Relaxed escaping rules.</li> <li>Fixed typos found by Gordon Gremme.</li> </ul> 1.05 Tue 23 May 2006 <ul> <li>Fixed all IDs in the examples to make them internally consistent. Previously, some examples did not validate because of inconsistent numbers of zeroes in the identifiers (mRNA00001 vs mRNA0001).</li> </ul>"},{"location":"format_specifications/gff_2/","title":"GFF2","text":"<p>Reference: https://gmod.org/wiki/GFF2</p> <p>GFF2 is a supported format in GMOD, but it is now deprecated and if you have a choice you should use GFF3. Unfortunately, data is sometimes only available in GFF2 format. GFF2 has a number of shortcomings compared to GFF3. GFF2 can only represent 2 level feature hierarchies, while GFF3 can support arbitrary levels. GFF2 also does not require that column 3, the feature type, be part of the sequence ontology. It can be any string. This often led to quality control and data exchange problems.</p>"},{"location":"format_specifications/gff_2/#contents-anchor","title":"Contents Anchor","text":"<ul> <li>1GFF2 is\\ Deprecated!</li> <li>1.1Why GFF2\\     is harmful to your\\     health</li> <li>2The GFF2 File\\ Format</li> <li>2.1Creating a\\     GFF2 table<ul> <li>2.1.1Using\\   the Group field for simple\\   features</li> <li>2.1.2Using\\   the Group field to group features that belong\\   together</li> <li>2.1.3Using\\   the Group field to add a\\   note</li> <li>2.1.4Using\\   the Group field to add an alternative\\   name</li> </ul> </li> <li>2.2Identifying the reference\\     sequence</li> <li>2.3Sequence\\     alignments</li> <li>2.4Dense\\     quantitative data</li> <li>2.5Loading\\     the GFF file into the\\     database</li> <li>2.6Aggregators</li> <li>3Converting\\ GFF2 to GFF3</li> <li>3.1Column 3:\\     Feature Type</li> <li>3.2Column 9:\\     Group / Attributes</li> </ul>"},{"location":"format_specifications/gff_2/#gff2-is-deprecated-anchor","title":"GFF2 is Deprecated! Anchor","text":"<p>The GFF file format stands for \u201cGene Finding Format\u201d or or \u201cGeneral Feature Format\u201d and was invented at the Sanger Centre. It is easy to use, but it suffers from two main limitations (see the box).</p>"},{"location":"format_specifications/gff_2/#why-gff2-is-harmful-to-your-health-anchor","title":"Why GFF2 is harmful to your health Anchor","text":"<p>One of GFF2\u2019s problems is that it is only able to represent one level of nesting of features. This is mainly a problem when dealing with genes that have multiple alternatively-spliced transcripts. GFF2 is unable to deal with the three-level hierarchy of gene \u2192 transcript \u2192 exon. Most people get around this by declaring a series of transcripts and giving them similar names to indicate that they come from the same gene. The second limitation is that while GFF2 allows you to create two-level hierarchies, such as transcript \u2192 exon, it doesn\u2019t have any concept of the direction of the hierarchy. So it doesn\u2019t know whether the exon is a subfeature of the transcript, or vice-versa. This means you have to use \u201caggregators\u201d to sort out the relationships. This is a major pain in the neck. For this reason, GFF2 format has been deprecated in favor of GFF3 format databases.</p> <p>See GFF3 for more on the current version of GFF.</p>"},{"location":"format_specifications/gff_2/#the-gff2-file-format-anchor","title":"The GFF2 File Format Anchor","text":"<p>The GFF format is a flat tab-delimited file, each line of which corresponds to an annotation, or feature. Each line has nine columns and looks like this:</p> <pre><code>Chr1  curated  CDS 365647  365963  .  +  1  Transcript \"R119.7\"\n</code></pre> <p>The 9 columns are as follows:</p> <p>reference sequence</p> <p>This is the ID of the sequence that is used to establish the coordinate system of the annotation. In the example above, the reference sequence is \u201cChr1\u201d.</p> <p>source</p> <p>The source of the annotation. This field describes how the annotation was derived. In the example above, the source is \u201ccurated\u201d to indicate that the feature is the result of human curation. The names and versions of software programs are often used for the source field, as in \u201ctRNAScan-SE/1.2\u201d.</p> <p>method</p> <p>The annotation method, also known as type. This field describes the type of the annotation, such as \u201cCDS\u201d. Together the method and source describe the annotation type.</p> <p>start position</p> <p>The start of the annotation relative to the reference sequence.</p> <p>stop position</p> <p>The stop of the annotation relative to the reference sequence. Start is always less than or equal to stop.</p> <p>score</p> <p>For annotations that are associated with a numeric score (for example, a sequence similarity), this field describes the score. The score units are completely unspecified, but for sequence similarities, it is typically percent identity. Annotations that do not have a score can use \u201c.\u201d</p> <p>strand</p> <p>For those annotations which are strand-specific, this field is the strand on which the annotation resides. It is \u201c+\u201d for the forward strand, \u201c-\u201c for the reverse strand, or \u201c.\u201d for annotations that are not stranded.</p> <p>phase</p> <p>For annotations that are linked to proteins, this field describes the phase of the annotation on the codons. It is a number from 0 to 2, or \u201c.\u201d for features that have no phase.</p> <p>group</p> <p>GFF provides a simple way of generating annotation hierarchies (\u201cis composed of\u201d relationships) by providing a group field. The group field contains the class and ID of an annotation which is the logical parent of the current one. In the example given above, the group is the Transcript named \u201cR119.7\u201d.</p> <p>The group field is also used to store information about the target of sequence similarity hits, and miscellaneous notes. See the next section for a description of how to describe similarity targets.</p> <p>The sequences used to establish the coordinate system for annotations can correspond to sequenced clones, clone fragments, contigs or super-contigs.</p> <p>In addition to a group ID, the GFF format allows annotations to have a group class. This makes sure that all groups are unique even if they happen to share the same name. For example, you can have a GenBank accession named AP001234 and a clone named AP001234 and distinguish between them by giving the first one a class of Accession and the second a class of Clone.</p> <p>You should use double-quotes around the group name or class if it contains white space.</p>"},{"location":"format_specifications/gff_2/#creating-a-gff2-table-anchor","title":"Creating a GFF2 table Anchor","text":"<p>The first 8 fields of the GFF2 format are easy to understand. The group field is a challenge. It is used in several distinct ways:</p> <ul> <li>to group together a single sequence feature that spans a discontinuous range, such as a gapped alignment.</li> <li>to name a feature, allowing it to be retrieved by name.</li> <li>to add one or more notes to the annotation.</li> <li>to add an alternative name</li> </ul>"},{"location":"format_specifications/gff_2/#using-the-group-field-for-simple-features-anchor","title":"Using the Group field for simple features Anchor","text":"<p>For a simple feature that spans a single continuous range, choose a name and class for the object and give it a line in the GFF2 file that refers to its start and stop positions.</p> <pre><code>Chr3   giemsa heterochromatin  4500000 6000000 . . .   Band 3q12.1\n</code></pre>"},{"location":"format_specifications/gff_2/#using-the-group-field-to-group-features-that-belong-together-anchor","title":"Using the Group field to group features that belong together Anchor","text":"<p>For a group of features that belong together, such as the exons in a transcript, choose a name and class for the object. Give each segment a separate line in the GFF2 file but use the same name for each line. For example:</p> <pre><code>IV     curated exon    5506900 5506996 . + .   Transcript B0273.1\nIV     curated exon    5506026 5506382 . + .   Transcript B0273.1\nIV     curated exon    5506558 5506660 . + .   Transcript B0273.1\nIV     curated exon    5506738 5506852 . + .   Transcript B0273.1\n</code></pre> <p>These four lines refer to a biological object of class \u201cTranscript\u201d and name B0273.1. Each of its parts uses the method \u201cexon\u201d, source \u201ccurated\u201d. Once loaded, the user will be able to search the genome for this object by asking the browser to retrieve \u201cTranscript:B0273.1\u201d. The browser can also be configured to allow the Transcript: prefix to be omitted.</p> <p>You can extend the idiom for objects that have heterogeneous parts, such as a transcript that has 5\u2019 and 3\u2019 UTRs</p> <pre><code>IV     curated  mRNA   5506800 5508917 . + .   Transcript B0273.1; Note \"Zn-Finger\"\nIV     curated  5'UTR  5506800 5508999 . + .   Transcript B0273.1\nIV     curated  exon   5506900 5506996 . + .   Transcript B0273.1\nIV     curated  exon   5506026 5506382 . + .   Transcript B0273.1\nIV     curated  exon   5506558 5506660 . + .   Transcript B0273.1\nIV     curated  exon   5506738 5506852 . + .   Transcript B0273.1\nIV     curated  3'UTR  5506852 5508917 . + .   Transcript B0273.1\n</code></pre> <p>In this example, there is a single feature with method \u201cmRNA\u201d that spans the entire range. It is grouped with subparts of type 5\u2019UTR, 3\u2019UTR and exon. They are all grouped together into a Transcript named B0273.1. Furthermore the mRNA feature has a note attached to it.</p> <p>NOTE: The subparts of a feature are in absolute (chromosomal or contig) coordinates. It is not currently possible to define a feature in absolute coordinates and then to load its subparts using coordinates that are relative to the start of the feature.</p> <p>Some annotations do not need to be individually named. For example, it is probably not useful to assign a unique name to each ALU repeat in a vertebrate genome. For these, just leave the Group field empty.</p>"},{"location":"format_specifications/gff_2/#using-the-group-field-to-add-a-note-anchor","title":"Using the Group field to add a note Anchor","text":"<p>The group field can be used to add one or more notes to an annotation. To do this, place a semicolon after the group name and add a Note field:</p> <pre><code>Chr3 giemsa heterochromatin 4500000 6000000 . . . Band 3q12.1\u00a0; Note \"Marfan's syndrome\"\n</code></pre> <p>You can add multiple Notes. Just separate them by semicolons:</p> <pre><code> Band 3q12.1\u00a0; Note \"Marfan's syndrome\"\u00a0; Note \"dystrophic dysplasia\"\n</code></pre> <p>The Note should come AFTER the group type and name.</p>"},{"location":"format_specifications/gff_2/#using-the-group-field-to-add-an-alternative-name-anchor","title":"Using the Group field to add an alternative name Anchor","text":"<p>If you want the feature to be quickly searchable by an alternative name, you can add one or more Alias tags. A feature can have multiple aliases, and multiple features can share the same alias:</p> <pre><code>Chr3 giemsa heterochromatin 4500000 6000000 . . . Band 3q12.1\u00a0; Alias MFX\n</code></pre> <p>Searches for aliases will be both faster and more reliable than searches for keywords in notes, since the latter relies on whole-text search methods that vary somewhat from DBMS to DBMS.</p>"},{"location":"format_specifications/gff_2/#identifying-the-reference-sequence-anchor","title":"Identifying the reference sequence Anchor","text":"<p>Each reference sequence in the GFF table must itself have an entry. This is necessary so that the length of the reference sequence is known.</p> <p>For example, if \u201cChr1\u201d is used as a reference sequence, then the GFF file should have an entry for it similar to this one:</p> <pre><code>Chr1 assembly chromosome 1 14972282 . + . Sequence Chr1\n</code></pre> <p>This indicates that the reference sequence named \u201cChr1\u201d has length 14972282 bp, method \u201cchromosome\u201d and source \u201cassembly\u201d. In addition, as indicated by the group field, Chr1 has class \u201cSequence\u201d and name \u201cChr1\u201d.</p> <p>It is suggested that you use \u201cSequence\u201d as the class name for all reference sequences, since this is the default class used by the Bio::DB::GFF module when no more specific class is requested. If you use a different class name, then be sure to indicate that fact with the \u201creference class\u201d option (see below).</p>"},{"location":"format_specifications/gff_2/#sequence-alignments-anchor","title":"Sequence alignments Anchor","text":"<p>There are several cases in which an annotation indicates the relationship between two sequences. One common one is a similarity hit, where the annotation indicates an alignment. A second common case is a map assembly, in which the annotation indicates that a portion of a larger sequence is built up from one or more smaller ones.</p> <p>Both cases are indicated by using the Target tag in the group field. For example, a typical similarity hit will look like this:</p> <pre><code>Chr1 BLASTX similarity 76953 77108 132 + 0 Target Protein:SW:ABL_DROME 493 544\n</code></pre> <p>Here, the group field contains the Target tag, followed by an identifier for the biological object. The GFF format uses the notation Class:Name for the biological object, and even though this is stylistically inconsistent, that\u2019s the way it\u2019s done. The object identifier is followed by two integers indicating the start and stop of the alignment on the target sequence.</p> <p>Unlike the main start and stop columns, it is possible for the target start to be greater than the target end. The previous example indicates that the the section of Chr1 from 76,953 to 77,108 aligns to the protein SW:ABL_DROME starting at position 493 and extending to position 544.</p> <p>A similar notation is used for sequence assembly information as shown in this example:</p> <pre><code>Chr1        assembly Link   10922906 11177731 . . . Target Sequence:LINK_H06O01 1 254826\nLINK_H06O01 assembly Cosmid 32386    64122    . . . Target Sequence:F49B2       6 31742\n</code></pre> <p>This indicates that the region between bases 10922906 and 11177731 of Chr1 are composed of LINK_H06O01 from bp 1 to bp 254826. The region of LINK_H0601 between 32386 and 64122 is, in turn, composed of the bases 5 to 31742 of cosmid F49B2.</p>"},{"location":"format_specifications/gff_2/#dense-quantitative-data-anchor","title":"Dense quantitative data Anchor","text":"<p>If you have dense quantitative data, such as tiling array data, microarray expression data, ChIP-chip or ChIP-seq chromatin immunoprecipitation data, then you will probably want to create \u201cWiggle\u201d format binary files, which represent the quantitative data in a compact format in external files. Use the <code>wiggle2gff3.pl</code> script, included in this distribution, to format and load this data. Run <code>wiggle2gff3.pl -h</code> for instructions.</p>"},{"location":"format_specifications/gff_2/#loading-the-gff-file-into-the-database-anchor","title":"Loading the GFF file into the database Anchor","text":"<p>Use the BioPerl script utilities <code>bp_bulk_load_gff.pl</code>, <code>bp_load_gff.pl</code> or (if you are brave) <code>bp_fast_load_gff.pl</code> to load the GFF file into the database. For example, if your database is a MySQL database on the local host named \u201cdicty\u201d, you can load it into an empty database using <code>bp_bulk_load_gff.pl</code> like this:</p> <pre><code> bp_bulk_load_gff.pl -c -d dicty my_data.gff\n</code></pre> <p>To update existing databases, use either <code>bp_load_gff.pl</code> or <code>bp_fast_load_gff.pl</code>. The latter is somewhat experimental, so use with care.</p>"},{"location":"format_specifications/gff_2/#aggregators-anchor","title":"Aggregators Anchor","text":"<p>It is not necessary to use aggregators with the Chado, BioSQL, or Bio::DB::SeqFeature::Store GBrowse\\ Adaptors, or any other adaptor that is based on GFF3.</p> <p>The Bio::DB::GFF adaptor (and only Bio::DB::GFF!) has a feature known as \u201caggregators\u201d. These are small software packages that recognize certain common feature types and convert them into complex biological objects. These aggregators make it possible to develop intelligent graphical representations of annotations, such as a gene that draws confirmed exons differently from predicted ones.</p> <p>An aggregator typically creates a new composite feature with a different method than any of its components. For example, the standard \u201calignment\u201d aggregator takes multiple alignments of method \u201csimilarity\u201d, groups them by their name, and returns a single feature of method \u201calignment\u201d.</p> <p>The various aggregators are described in detail in the Bio::DB::GFF perldoc page. It is easy to write new aggregators, and also possible to define aggregators on the fly in the GBrowse configuration file. It is suggested that you use the sample GFF2 files from the yeast, drosophila and C. elegans projects to see what methods to use to achieve the desired results.</p> <p>In addition to the standard aggregators that are distributed with BioPerl, GBrowse distributes several experimental and/or special-purpose aggregators:</p> <p>match_gap</p> <p>This aggregator is used for GFF3 style gapped alignments, in which there is a single feature of method \u2018match\u2019 with a \u2018Gap\u2019 attribute. This aggregator was contributed by Dmitri Bichko.</p> <p>orf</p> <p>This aggregator aggregates raw \u201cORF\u201d features into \u201ccoding\u201d features. It is basically identical to the \u201ccoding\u201d aggregator, except that it looks for features of type \u201cORF\u201d rather than \u201ccds\u201d.</p> <p>reftranscript</p> <p>This aggregator was written to make the compound feature, \u201creftranscript\u201d for use with GBrowse editing software developed outside of the GMOD development group. It can be used to aggregate \u201creftranscripts\u201d from \u201crefexons\u201d, loaded as second copy features. These features, in contrast to \u201ctranscripts\u201d, are usually implemented as features which cannot be edited and serve as starting point references for annotations added using GBrowse for feature visualization. Adding features to the compound feature, \u201creftranscript\u201d, can be done by adding to the \u201cpart_names\u201d call (i.e. \u201crefCDS\u201d).</p> <p>waba_alignment</p> <p>This aggregator handles the type of alignments produced by Jim Kent\u2019s WABA program, and was written to be compatible with the C. elegans GFF2 files. It aggregates the following feature types into an aggregate type of \u201cwaba_alignment\u201d:</p> <ul> <li>nucleotide_match:waba_weak</li> <li>nucleotide_match:waba_strong</li> <li>nucleotide_match:waba_coding</li> </ul> <p>wormbase_gene</p> <p>This aggregator was written to be compatible with the C. elegans GFF2 files distributed by the Sanger Institute. It aggregates raw \u201cCDS\u201d, \u201c5\u2019UTR\u201d, \u201c3\u2019UTR\u201d, \u201cpolyA\u201d and \u201cTSS\u201d features into \u201ctranscript\u201d features. For compatibility with the idiosyncrasies of the Sanger GFF2 format, it expects that the full range of the transcript is contained in a main feature of type \u201cSequence\u201d.</p> <p>It is strongly recommended that for mirroring C. elegans annotations, you use the \u201cprocessed_transcript\u201d aggregator in conjunction with the GFF3 files found at:</p> <p>ftp://ftp.wormbase.org/pub/wormbase/genomes/elegans/genome_feature_tables/GFF3</p>"},{"location":"format_specifications/gff_2/#converting-gff2-to-gff3-anchor","title":"Converting GFF2 to GFF3 Anchor","text":"<p>Converting a file from GFF2 to GFF3 format is problematic for several reasons. However, there are several GFF2 to GFF3 converters available on the web, but each makes specific assumptions about the GFF2 data that limit its applicability. GMOD does not endorse (or disparage) any particular converter. If you have GFF2 data from an external source, and they don\u2019t also provide it in GFF3 format, then you may be stuck with GFF2.</p> <p>Some areas that need to be addressed by any GFF2 to GFF3 converter:</p>"},{"location":"format_specifications/gff_2/#column-3-feature-type-anchor","title":"Column 3: Feature Type Anchor","text":"<p>If the GFF2 file does not use Sequence Ontology terms in column 3 then some sort of translation will need to be done on the types in the GFF2 to convert them to be SO terms.</p>"},{"location":"format_specifications/gff_2/#column-9-group-attributes-anchor","title":"Column 9: Group / Attributes Anchor","text":"<p>Column 9 has a slightly different format and is much more tightly defined in GFF3 than GFF2. Both require attention. GFF2 does not have any reserved attribute names, uses C style encoding/escaping of special characters, and has many other small differences.</p> <p>Another big problem is that GFF2 supports only one level of feature nesting. While you can certainly reproduce this minimal nesting in GFF3, it would be better to also convert your feature representations to be multi-level at the time you migrate the data to GFF3. This is non-trivial.</p> <p>Categories:</p> <ul> <li>Annotation</li> <li>Computing</li> </ul>"},{"location":"format_specifications/gff_2/#navigation-menu-anchor","title":"Navigation menu Anchor","text":""},{"location":"format_specifications/gff_2/#navigation-anchor","title":"Navigation Anchor","text":"<ul> <li>GMOD Home</li> <li>Software</li> <li>Categories /\\ Tags</li> </ul>"},{"location":"format_specifications/gff_2/#documentation-anchor","title":"Documentation Anchor","text":"<ul> <li>Overview</li> <li>FAQs</li> <li>HOWTOs</li> <li>Glossary</li> </ul>"},{"location":"format_specifications/gff_2/#community-anchor","title":"Community Anchor","text":"<ul> <li>GMOD News</li> <li>Training /\\ Outreach</li> <li>Support</li> <li>GMOD Promotion</li> <li>Meetings</li> <li>Calendar</li> </ul>"},{"location":"format_specifications/gff_2/#tools-anchor","title":"Tools Anchor","text":"<ul> <li> <p>Browse properties</p> </li> <li> <p>Last updated at 13:27 on 21 April 2017.</p> </li> <li>Content is available under a GNU Free Documentation License unless otherwise noted.</li> </ul>"},{"location":"format_specifications/gff_parser_architecture/","title":"PyGnome GFF/GTF Parser Architecture","text":"<p>This document outlines the architecture for the PyGnome GFF/GTF parser library, which provides a flexible and efficient way to read genomic annotation files in GFF2, GFF3, and GTF formats.</p>"},{"location":"format_specifications/gff_parser_architecture/#core-components","title":"Core Components","text":""},{"location":"format_specifications/gff_parser_architecture/#1-base-parser-with-format-specific-implementations","title":"1. Base Parser with Format-Specific Implementations","text":"<p>The parser follows a hierarchical design with a base abstract parser class and format-specific implementations:</p> <pre><code>classDiagram\n    class BaseParser {\n        &lt;&lt;abstract&gt;&gt;\n        +parse(file_path) Iterator~Record~\n        +detect_format(file_path) str\n        #_parse_line(line) Record\n        #_validate_record(record) bool\n    }\n\n    class GffParser {\n        +parse(file_path) Iterator~Record~\n        #_parse_line(line) Record\n        #_parse_attributes(attr_string) dict\n    }\n\n    class Gff3Parser {\n        +parse(file_path) Iterator~Record~\n        #_parse_line(line) Record\n        #_parse_attributes(attr_string) dict\n    }\n\n    class GtfParser {\n        +parse(file_path) Iterator~Record~\n        #_parse_line(line) Record\n        #_parse_attributes(attr_string) dict\n    }\n\n    BaseParser &lt;|-- GffParser\n    BaseParser &lt;|-- Gff3Parser\n    BaseParser &lt;|-- GtfParser\n</code></pre>"},{"location":"format_specifications/gff_parser_architecture/#2-record-class-for-feature-representation","title":"2. Record Class for Feature Representation","text":"<p>The <code>Record</code> class represents a single feature/annotation line from a GFF/GTF file, providing methods to access attributes and convert to different formats.</p>"},{"location":"format_specifications/gff_parser_architecture/#3-feature-hierarchy-for-parent-child-relationships","title":"3. Feature Hierarchy for Parent-Child Relationships","text":"<p>The <code>FeatureHierarchy</code> class provides a way to work with parent-child relationships in GFF3, built on-demand (lazy loading) when needed.</p>"},{"location":"format_specifications/gff_parser_architecture/#4-main-interface-file-reading-context-manager","title":"4. Main Interface: File Reading Context Manager","text":"<p>The <code>Gff</code> class serves as the main interface, implemented as a context manager for reading GFF/GTF files:</p> <pre><code>classDiagram\n    class Gff {\n        &lt;&lt;context manager&gt;&gt;\n        -file_path str\n        -format str\n        -parser BaseParser\n        -file_handle File\n        -records list~Record~\n        -_hierarchy FeatureHierarchy\n        +__init__(file_path, format=None)\n        +__enter__() self\n        +__exit__(exc_type, exc_val, exc_tb)\n        +__iter__() Iterator~Record~\n        +get_features_by_type(type) list~Record~\n        +get_features_by_location(seqid, start, end) list~Record~\n        +get_features_by_attribute(attr_name, attr_value) list~Record~\n        +build_hierarchy() FeatureHierarchy\n    }\n\n    Gff --&gt; BaseParser\n    Gff --&gt; FeatureHierarchy\n</code></pre>"},{"location":"format_specifications/gff_parser_architecture/#usage-examples","title":"Usage Examples","text":""},{"location":"format_specifications/gff_parser_architecture/#basic-file-reading-with-context-manager","title":"Basic File Reading with Context Manager","text":"<pre><code># Using the context manager to read a GFF/GTF file\nwith Gff('example.gff3') as gff:\n    for record in gff:\n        print(f\"{record.seqid}\\t{record.type}\\t{record.start}-{record.end}\")\n</code></pre> <p>This example shows how the <code>Gff</code> class functions as a context manager for reading GFF/GTF files. The context manager handles:</p> <ol> <li>Opening the file</li> <li>Auto-detecting the format (if not specified)</li> <li>Creating the appropriate parser</li> <li>Providing an iterator interface for the records</li> <li>Properly closing the file when done</li> </ol>"},{"location":"format_specifications/gff_parser_architecture/#filtering-features","title":"Filtering Features","text":"<pre><code># Using the context manager with filtering capabilities\nwith Gff('example.gff3') as gff:\n    # Consume the iterator to populate the records\n    list(gff)\n\n    # Get all genes\n    genes = gff.get_features_by_type('gene')\n    for gene in genes:\n        print(f\"Gene: {gene.get_attribute('ID')}\")\n\n    # Get features in a specific region\n    region_features = gff.get_features_by_location('chr1', 1000, 2000)\n    print(f\"Found {len(region_features)} features in region\")\n</code></pre>"},{"location":"format_specifications/gff_parser_architecture/#working-with-hierarchical-features","title":"Working with Hierarchical Features","text":"<pre><code># Using the context manager with hierarchical feature access\nwith Gff('example.gff3') as gff:\n    # Consume the iterator to populate the records\n    list(gff)\n\n    # Build the hierarchy (lazy loading)\n    hierarchy = gff.build_hierarchy()\n\n    # Get all genes and their transcripts\n    genes = gff.get_features_by_type('gene')\n    for gene in genes:\n        gene_id = gene.get_attribute('ID')\n        transcripts = hierarchy.get_children(gene_id)\n        print(f\"Gene {gene_id} has {len(transcripts)} transcripts\")\n</code></pre>"},{"location":"format_specifications/gff_parser_architecture/#key-features","title":"Key Features","text":"<ol> <li>File Reading Context Manager: The <code>Gff</code> class is explicitly designed as a context manager for reading GFF/GTF files, handling file opening/closing automatically</li> <li>Format Auto-detection: Automatically detects GFF2, GFF3, or GTF format</li> <li>Efficient Parsing: Uses iterators for memory-efficient processing of large files</li> <li>Flexible Filtering: Filter features by type, location, or attributes</li> <li>Lazy Hierarchy Building: Flat records by default with on-demand hierarchy construction</li> <li>Extensible Design: Easy to add new formats or functionality</li> </ol>"},{"location":"format_specifications/gff_parser_architecture/#extension-points","title":"Extension Points","text":"<p>The architecture is designed to be extensible in several ways:</p> <ol> <li>New Format Support: Add new parser classes by extending <code>BaseParser</code></li> <li>Additional Feature Types: The <code>Record</code> class can be extended or specialized for specific feature types</li> <li>Advanced Filtering: Add more sophisticated query methods</li> <li>Output Formats: Add converters to other formats (BED, JSON, etc.)</li> <li>Visualization: Integrate with plotting libraries for visualization</li> </ol>"},{"location":"format_specifications/gtf_2.2/","title":"Gtf 2.2","text":"<p>GTF2.2: A Gene Annotation Format (Revised Ensembl GTF) Contents</p> <p>Reference: http://mblab.wustl.edu/GTF22.html</p> <ul> <li>Introduction</li> <li>GTF Field Definitions</li> <li>Examples</li> <li>Scripts and Resources</li> </ul> <p>Introduction GTF stands for Gene transfer format. It borrows from  GFF, but has additional structure that warrants a separate definition and format name.</p> <p>Structure is as GFF, so the fields are:</p> <p> <p>  [attributes] [comments] <p>Here is a simple example with 3 translated exons. Order of rows is not important.</p> <pre><code>381 Twinscan\u00a0 CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 380\u00a0\u00a0 401\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 0\u00a0 gene_id \"001\"; transcript_id \"001.1\";\n381 Twinscan\u00a0 CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 501\u00a0\u00a0 650\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 2\u00a0 gene_id \"001\"; transcript_id \"001.1\";\n381 Twinscan\u00a0 CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 700\u00a0\u00a0 707\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 2\u00a0 gene_id \"001\"; transcript_id \"001.1\";\n381 Twinscan\u00a0 start_codon\u00a0 380\u00a0\u00a0 382\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 0\u00a0 gene_id \"001\"; transcript_id \"001.1\";\n381 Twinscan\u00a0 stop_codon\u00a0\u00a0 708\u00a0\u00a0 710\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 0\u00a0 gene_id \"001\"; transcript_id \"001.1\";\n</code></pre> <p>The whitespace in this example is provided only for readability. In GTF, fields must be separated by a single TAB and no white space.</p> <p>Top</p> <p>GTF Field Definitions <p>The name of the sequence. Commonly, this is the chromosome ID or contig ID. Note that the coordinates used must be unique within each sequence name in all GTFs for an annotation set.</p> <p></p> <p>The source column should be a unique label indicating where the annotations came from --- typically the name of either a prediction program or a public database.</p> <p> <p>The following feature types are required: \"CDS\", \"start_codon\", \"stop_codon\". The features \"5UTR\", \"3UTR\", \"inter\", \"inter_CNS\", \"intron_CNS\" and \"exon\" are optional. All other features will be ignored. The types must have the correct capitalization shown here.</p> <p>CDS represents the coding sequence starting with the first translated codon and proceeding to the last translated codon. Unlike Genbank annotation, the stop codon is not included in the CDS for the terminal exon. The optional feature \"5UTR\" represents regions from the transcription start site or beginning of the known 5' UTR to the base before the start codon of the transcript. If this region is interrupted by introns then each exon or partial exon is annotated as a separate 5UTR feature. Similarly, \"3UTR\" represents regions after the stop codon and before the polyadenylation site or end of the known 3' untranslated region. Note that the UTR features can only be used to annotate portions of mRNA genes, not non-coding RNA genes.</p> <p>The feature \"exon\" more generically describes any transcribed exon. Therefore, exon boundaries will be the transcription start site, splice donor, splice acceptor and poly-adenylation site. The start or stop codon will not necessarily lie on an exon boundary.</p> <p>The \"start_codon\" feature is up to 3bp long in total and is included in the coordinates for the \"CDS\" features. The \"stop_codon\" feature similarly is up to 3bp long and is excluded from the coordinates for the \"3UTR\" features, if used.</p> <p>The \"start_codon\" and \"stop_codon\" features are not required to be atomic; they may be interrupted by valid splice sites. A split start or stop codon appears as two distinct features. All \"start_codon\" and \"stop_codon\" features must have a 0,1,2 in the  field indicating which part of the codon is represented by this feature. Contiguous start and stop codons will always have frame 0. <p>The \"inter\" feature describes an intergenic region, one which is by almost all accounts not transcribed. The \"inter_CNS\" feature describes an intergenic conserved noncoding sequence region. All of these should have an empty transcript_id attribute, since they are not transcribed and do not belong to any transcript. The \"intron_CNS\" feature describes a conserved noncoding sequence region within an intron of a transcript, and should have a transcript_id associated with it.</p> <p> <p>Integer start and end coordinates of the feature relative to the beginning of the sequence named in .\u00a0  must be less than or equal to . Sequence numbering starts at 1. Values of  and  that extend outside the reference sequence are technically acceptable, but they are discouraged. <p> <p>The score field indicates a degree of confidence in the feature's existence and coordinates. The value of this field has no global scale but may have relative significance when the  field indicates the prediction program used to create this annotation. It may be a floating point number or integer, and not necessary and may be replaced with a dot.</p> <p> <p>0 indicates that the feature begins with a whole codon at the 5' most base. 1 means that there is one extra base (the third base of a codon) before the first whole codon and 2 means that there are two extra bases (the second and third bases of the codon) before the first codon. Note that for reverse strand features, the 5' most base is the  coordinate. <p>Here are the details excised from the  GFF\\ spec. Important: Note comment on reverse strand.</p> <p>'0' indicates that the specified region is in frame, i.e. that its first base corresponds to the first base of a codon. '1' indicates that there is one extra base, i.e. that the second base of the region corresponds to the first base of a codon, and '2' means that the third base of the region is the first base of a codon. If the strand is '-', then the first base of the region is value of , because the corresponding coding region will run from  to  on the reverse strand. <p>Frame is calculated as (3 - ((length-frame) mod 3)) mod 3.</p> <ul> <li> <p>(length-frame) is the length of the previous feature starting at the first whole codon (and thus the frame subtracted out).</p> </li> <li> <p>(length-frame) mod 3 is the number of bases on the 3' end beyond the last whole codon of the previous feature.</p> </li> <li> <p>3-((length-frame) mod 3) is the number of bases left in the codon after removing those that are represented at the 3' end of the feature.</p> </li> <li> <p>(3-((length-frame) mod 3)) mod 3 changes a 3 to a 0, since three bases makes a whole codon, and 1 and 2 are left unchanged.</p> </li> </ul> <p>[attributes]</p> <p>All nine features have the same two mandatory attributes at the end of the record:</p> <ul> <li>gene_id value;\u00a0\u00a0\u00a0\u00a0 A globally unique identifier   for the genomic locus of the transcript. If empty, no gene is associated with this feature.</li> <li>transcript_id value;\u00a0\u00a0\u00a0\u00a0 A globally unique identifier   for the predicted transcript. If empty, no transcript is associated with this feature.</li> </ul> <p>These attributes are designed for handling multiple transcripts from the same genomic region. Any other attributes or comments must appear after these two and will be ignored.</p> <p>Attributes must end in a semicolon which must then be separated from the start of any subsequent attribute by exactly one space character (NOT a tab character).</p> <p>Textual attributes should be surrounded by doublequotes.</p> <p>These attributes are required even for non-mRNA transcribed regions such as \"inter\" and \"inter_CNS\" features.</p> <p>[comments]</p> <p>Comments begin with a hash ('#') and continue to the end of the line. Nothing beyond a hash will be parsed. These may occur anywhere in the file, including at the end of a feature line.</p> <p>Top</p> <p>Examples Here is an example of a gene on the negative strand including UTR regions. Larger coordinates are 5' of smaller coordinates. Thus, the start codon is 3 bp with largest coordinates among all those bp that fall within the CDS regions. Note that the stop codon lies between the 3UTR and the CDS</p> <p><code>140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0inter\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a05141\u00a0\u00a0\u00a0\u00a0\u00a08522\u00a0\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"\";\u00a0transcript_id\u00a0\"\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0inter_CNS\u00a0\u00a0\u00a0\u00a0\u00a08523\u00a0\u00a0\u00a0\u00a0\u00a09711\u00a0\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"\";\u00a0transcript_id\u00a0\"\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0inter\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a09712\u00a0\u00a0\u00a0\u00a0\u00a013182\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"\";\u00a0transcript_id\u00a0\"\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a03UTR\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a065149\u00a0\u00a0\u00a0\u00a065487\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a03UTR\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a066823\u00a0\u00a0\u00a0\u00a066992\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0stop_codon\u00a0\u00a0\u00a0\u00a066993\u00a0\u00a0\u00a0\u00a066995\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a066996\u00a0\u00a0\u00a0\u00a066999\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0intron_CNS\u00a0\u00a0\u00a0\u00a070103\u00a0\u00a0\u00a0\u00a070151\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a070207\u00a0\u00a0\u00a0\u00a070294\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a071696\u00a0\u00a0\u00a0\u00a071807\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0start_codon\u00a0\u00a0\u00a071805\u00a0\u00a0\u00a0\u00a071806\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0start_codon\u00a0\u00a0\u00a073222\u00a0\u00a0\u00a0\u00a073222\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a0CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a073222\u00a0\u00a0\u00a0\u00a073222\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\"; 140\u00a0\u00a0\u00a0\u00a0Twinscan\u00a0\u00a0\u00a0\u00a05UTR\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a073223\u00a0\u00a0\u00a0\u00a073504\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0gene_id\u00a0\"140.000\";\u00a0transcript_id\u00a0\"140.000.1\";</code></p> <p>Note the frames of the coding exons. For example:</p> <ol> <li>The first CDS (from 71807 to 71696) always has frame zero.</li> <li>Frame of the 1st CDS =0, length =112.\u00a0 (3-((length - frame) mod 3)) mod 3\u00a0 =    2, the frame of the 2nd CDS.</li> <li>Frame of the 2nd CDS=2, length=88. (3-((length - frame) mod 3)) mod 3\u00a0 = 1, the    frame of the terminal CDS.</li> <li>Alternatively, the frame of terminal CDS can be calculated without the    rest of the gene. Length of the terminal CDS=4. length mod 3 =1, the frame    of the terminal CDS.</li> </ol> <p>Note the split start codon. The second start codon region has a frame of 2, since it is the second base, and has an accompanying CDS feature, since CDS always includes the start codon.</p> <p>Here is an example in which the \"exon\" feature is used. It is a 5 exon gene with 3 translated exons.</p> <p><code>381 Twinscan\u00a0 exon 150\u00a0\u00a0 200\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 .\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 exon 300\u00a0\u00a0 401\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 .\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 CDS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 380\u00a0\u00a0 401\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 0\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 exon 501\u00a0\u00a0 650\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 .\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 CDS 501\u00a0\u00a0 650\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 2\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 exon 700\u00a0\u00a0 800\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 .\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 CDS 700\u00a0\u00a0 707\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 2\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 exon 900\u00a0 1000\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 .\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 start_codon\u00a0 380\u00a0\u00a0 382 .\u00a0\u00a0 +\u00a0\u00a0 0\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\"; 381 Twinscan\u00a0 stop_codon\u00a0\u00a0 708 710\u00a0\u00a0 .\u00a0\u00a0 +\u00a0\u00a0 0\u00a0 gene_id \"381.000\"; transcript_id \"381.000.1\";</code></p> <p>Top</p> <p>Scripts and Resources Several Perl scripts have been written for checking, parsing, correcting, and comparing GTF-formatted annotations. Most of the important ones are included the Eval package, which comes equipped with a GTF parsing Perl package GTF.pm.</p> <ul> <li>Eval Software</li> <li>Eval Documentation</li> </ul> <p>The Eval documentation contains a complete code-level documentation of GTF.pm, suitable for able Perl programmers to create and parse GTF files.</p> <p>The script <code>validate_gtf.pl</code> included in the Eval package is particularly useful for checking that your GTF annotation is consistent and well-formed.</p> <p>Here are some more useful links:</p> <ul> <li>GFF Specification at Sanger</li> <li>Brent Lab Homepage</li> </ul> <p>Top</p>"},{"location":"format_specifications/vcf/","title":"Vcf","text":"<p>Below is the content of pages\u202f4\u201316 of the VCF\u202f4.5 PDF, faithfully converted into Markdown. Section and subsection numbers match the PDF.</p>"},{"location":"format_specifications/vcf/#1-the-vcf-specification","title":"1\u202fThe VCF specification","text":"<p>Reference: https://samtools.github.io/hts-specs/VCFv4.5.pdf</p>"},{"location":"format_specifications/vcf/#11-an-example","title":"1.1\u202fAn example","text":"<pre><code>##fileformat=VCFv4.5\n##fileDate=20090805\n##source=myImputationProgramV3.1\n##reference=file:///seq/references/1000GenomesPilot-NCBI36.fasta\n##contig=&lt;ID=20,length=62435964,assembly=B36,md5=f126cdf8a6e0c7f379d618ff66beb2da,species=\"Homo sapiens\",taxonomy=x&gt;\n##phasing=partial\n##INFO=&lt;ID=NS,Number=1,Type=Integer,Description=\"Number of Samples With Data\"&gt;\n##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=\"Total Depth\"&gt;\n##INFO=&lt;ID=AF,Number=A,Type=Float,Description=\"Allele Frequency\"&gt;\n##INFO=&lt;ID=AA,Number=1,Type=String,Description=\"Ancestral Allele\"&gt;\n##INFO=&lt;ID=DB,Number=0,Type=Flag,Description=\"dbSNP membership, build 129\"&gt;\n##INFO=&lt;ID=H2,Number=0,Type=Flag,Description=\"HapMap2 membership\"&gt;\n##FILTER=&lt;ID=q10,Description=\"Quality below 10\"&gt;\n##FILTER=&lt;ID=s50,Description=\"Less than 50% of samples have data\"&gt;\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=\"Genotype\"&gt;\n##FORMAT=&lt;ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\"&gt;\n##FORMAT=&lt;ID=DP,Number=1,Type=Integer,Description=\"Read Depth\"&gt;\n##FORMAT=&lt;ID=HQ,Number=2,Type=Integer,Description=\"Haplotype Quality\"&gt;\n#CHROM POS      ID          REF ALT    QUAL FILTER INFO                       FORMAT        NA00001         NA00002        NA00003\n20     14370    rs6054257   G   A      29   PASS   NS=3;DP=14;AF=0.5;DB;H2     GT:GQ:DP:HQ   0|0:48:1:51,51   1|0:48:8:51,51  1/1:43:5:.,.  \n20     17330    .           T   A      3    q10    NS=3;DP=11;AF=0.017           GT:GQ:DP:HQ   0|0:49:3:58,50   0|1:3:5:65,3    0/0:41:3     \n20     1110696 rs6040355   A   G,T    67   PASS   NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ 1|2:21:6:23,27   2|1:2:0:18,2    2/2:35:4     \n20     1230237 .           T   .      47   PASS   NS=3;DP=13;AA=T               GT:GQ:DP:HQ   0|0:54:7:56,60   0|0:48:4:51,51  0/0:61:2    \n20     1234567 microsat1    GTC G,GTCT 50   PASS   NS=3;DP=9;AA=G              GT:GQ:DP      0/1:35:4       0/2:17:2       1/1:40:3    \n</code></pre> <p>This shows a simple SNP, a filtered\u2011out SNP, a multi\u2011allelic site, a monomorphic reference site, and a microsatellite with two alternate alleles; genotype columns illustrate phased vs. unphased calls and per\u2011sample quality/depth/HQ .</p>"},{"location":"format_specifications/vcf/#12-character-encoding-non-printable-characters-and-special-characters","title":"1.2\u202fCharacter encoding, non-printable characters and special characters","text":"<p>VCF files must be UTF\u20118 encoded (no byte\u2011order mark) and may use either LF (<code>\\n</code>) or CR+LF (<code>\\r\\n</code>) as line separators. Non\u2011printable characters U+0000\u2013U+0008, U+000B\u2013U+000C, and U+000E\u2013U+001F are disallowed. Characters with special meaning (e.g. <code>;</code>, <code>:</code>, <code>=</code>, <code>%</code>, <code>,</code>) within fields must be percent\u2011encoded as follows:</p> Encoding Character <code>%3A</code> <code>:</code> <code>%3B</code> <code>;</code> <code>%3D</code> <code>=</code> <code>%25</code> <code>%</code> <code>%2C</code> <code>,</code> <code>%0D</code> CR <code>%0A</code> LF <code>%09</code> TAB"},{"location":"format_specifications/vcf/#13-data-types","title":"1.3\u202fData types","text":"<p>Supported VCF data types (applies to both INFO and FORMAT fields) are:</p> <ul> <li>Integer (32\u2011bit signed; values \u2264\u202f\u00b12\u00b3\u00b9\u20131)</li> <li>Float (32\u2011bit IEEE\u2011754; regex <code>^[-+]?[0-9]*\\.?[0-9]+([eE][-+]?[0-9]+)?$</code> or <code>^[-+]?(INF|INFINITY|NAN)$</code>)</li> <li>Flag (present/absent, Number=0)</li> <li>Character (single\u2010character string)</li> <li>String (arbitrary string) </li> </ul>"},{"location":"format_specifications/vcf/#14-metainformation-lines","title":"1.4\u202fMeta\u2011information lines","text":"<p>Meta\u2011information lines begin with <code>##</code> and must come before the single header line (<code>#CHROM ...</code>). They are either:</p> <ul> <li>Unstructured: <code>##key=value</code></li> <li>Structured: <code>##key=&lt;key1=val1,key2=val2,...&gt;</code>   \u2013 All structured lines require a unique <code>ID=</code> field inside the <code>&lt;...&gt;</code> .</li> </ul>"},{"location":"format_specifications/vcf/#141-file-format","title":"1.4.1\u202fFile format","text":"<p>A required first line specifying the VCF version:</p> <pre><code>##fileformat=VCFv4.5\n``` :contentReference[oaicite:4]{index=4}\n\n#### 1.4.2\u202fInformation field format\n\nDefines INFO keys:\n```vcf\n##INFO=&lt;ID=ID,Number=&lt;number&gt;,Type=&lt;type&gt;,Description=\"...\",Source=\"...\",Version=\"...\"&gt;\n</code></pre> <ul> <li><code>Type</code> \u2208 {Integer, Float, Flag, Character, String}</li> <li> <p><code>Number</code> \u2208 \u2115 or:</p> </li> <li> <p><code>A</code>: one value per ALT allele</p> </li> <li><code>R</code>: one value per allele (REF + ALTs)</li> <li><code>G</code>: one value per genotype (see\u202f1.6.2)</li> <li><code>.</code>: unknown/unbounded</li> <li><code>Flag</code> fields have <code>Number=0</code> and no <code>=value</code> part .</li> </ul>"},{"location":"format_specifications/vcf/#143-filter-field-format","title":"1.4.3\u202fFilter field format","text":"<p>Defines FILTER codes:</p> <pre><code>##FILTER=&lt;ID=ID,Description=\"...\"&gt;\n``` :contentReference[oaicite:6]{index=6}\n\n#### 1.4.4\u202fIndividual format field format\n\nDefines per\u2011sample FORMAT keys:\n```vcf\n##FORMAT=&lt;ID=ID,Number=&lt;number&gt;,Type=&lt;type&gt;,Description=\"...\"&gt;\n</code></pre> <ul> <li>Same types as INFO</li> <li> <p>Additional <code>Number</code> codes:</p> </li> <li> <p><code>LA</code>, <code>LR</code>, <code>LG</code>: allele\u2010subset variants</p> </li> <li><code>P</code>: one value per allele in GT</li> <li><code>M</code>: one value per possible base modification (see spec) .</li> </ul>"},{"location":"format_specifications/vcf/#145-alternative-allele-field-format","title":"1.4.5\u202fAlternative allele field format","text":"<p>Defines symbolic ALT alleles (e.g., structural variants or ambiguity codes):</p> <pre><code>##ALT=&lt;ID=type,Description=\"...\"&gt;\n</code></pre> <ul> <li>Recommended types: <code>DEL</code>, <code>INS</code>, <code>DUP</code>, <code>INV</code>, <code>CNV</code>, with subtypes like <code>CNV:TR</code>, <code>DUP:TANDEM</code>, etc.</li> <li>IUPAC codes as ALT can be declared (e.g. <code>ID=R</code> for A/G) .</li> </ul>"},{"location":"format_specifications/vcf/#146-assembly-field-format","title":"1.4.6\u202fAssembly field format","text":"<p>(Optional) link to FASTA for breakend assemblies:</p> <pre><code>##assembly=url\n``` :contentReference[oaicite:9]{index=9}\n\n#### 1.4.7\u202fContig field format\n\nDefines contigs and optional metadata:\n```vcf\n##contig=&lt;ID=ctg1,length=...,md5=...,URL=...&gt;\n</code></pre> <ul> <li><code>ID</code>: name matching <code>[!-~]</code> except certain punctuation</li> <li>Optional <code>length</code>, <code>md5</code>, <code>URL</code> fields .</li> </ul>"},{"location":"format_specifications/vcf/#148-sample-field-format","title":"1.4.8\u202fSample field format","text":"<p>Defines sample metadata:</p> <p><pre><code>##SAMPLE=&lt;ID=Sample1,Assay=WholeGenome,Ethnicity=AFR,...,Description=\"...\"&gt;\n</code></pre>  :contentReference[oaicite:11]{index=11}</p>"},{"location":"format_specifications/vcf/#149-pedigree-field-format","title":"1.4.9\u202fPedigree field format","text":"<p>Defines pedigree relationships: <pre><code>##PEDIGREE=&lt;ID=ChildID,Father=FatherID,Mother=MotherID&gt;\n##pedigreeDB=url\n</code></pre> :contentReference[oaicite:12]{index=12}</p>"},{"location":"format_specifications/vcf/#15-header-line-syntax","title":"1.5\u202fHeader line syntax","text":"<p>The single header line names the fixed columns (tab\u2011delimited, no trailing tab):</p> <pre><code>#CHROM POS ID REF ALT QUAL FILTER INFO [FORMAT [&lt;sampleID&gt;...]]\n</code></pre>"},{"location":"format_specifications/vcf/#16-data-lines","title":"1.6\u202fData lines","text":"<p>All data lines are tab\u2011delimited, no trailing tab, and end with a newline. Missing values are <code>.</code>.</p>"},{"location":"format_specifications/vcf/#161-fixed-fields","title":"1.6.1\u202fFixed fields","text":"<p>Each record has 8 mandatory fields:</p> <ol> <li>CHROM (String): reference contig or <code>&lt;ID&gt;</code>; entries for one CHROM must be contiguous.  </li> <li>POS (Integer): 1\u2011based reference position; telomeres at 0 or N+1.  </li> <li>ID (String): semicolon\u2011sep. unique IDs or <code>.</code>.  </li> <li>REF (String): one or more bases (<code>A,C,G,T,N</code>), padded for indels at start; case-insensitive.  </li> <li>ALT (String): comma\u2011sep. alternate alleles (<code>A,C,G,T,N</code>, <code>*</code>, <code>.</code>, <code>&lt;ID&gt;</code>, <code>&lt;*&gt;</code>, breakends).  </li> <li>QUAL (Float): phred-scaled quality (<code>\u201310\u202flog\u2081\u2080</code>\u202ferror\u202fprob.), or <code>.</code>.  </li> <li>FILTER (String): <code>PASS</code> or semicolon\u2011sep. filter IDs; <code>.</code> if not applied.  </li> <li>INFO (String): semicolon\u2011sep. <code>key[=value[,...]]</code> entries or <code>.</code>; values may use percent\u2010encoding.  </li> </ol> <p>Reserved INFO keys are detailed in Table\u202f1 below. :contentReference[oaicite:14]{index=14}</p>"},{"location":"format_specifications/vcf/#162-genotype-fields","title":"1.6.2\u202fGenotype fields","text":"<p>If genotypes are present, a <code>FORMAT</code> column lists per\u2011sample keys (colon\u2011delimited), followed by one column per sample.  </p> <ul> <li>The first key must be <code>GT</code> if present; local\u2011allele fields require <code>LAA</code>.  </li> <li>Missing values use <code>.</code>; trailing fields may be omitted except <code>GT</code>.  </li> </ul> <p>Common reserved FORMAT keys (Table\u202f2) include <code>AD</code>, <code>DP</code>, <code>FT</code>, <code>GL</code>, <code>GP</code>, <code>GQ</code>, <code>GT</code>, <code>HQ</code>, <code>PL</code>, <code>PS</code>, and many more (including base\u2011mod Modification keys M... and their depths; see spec) :contentReference[oaicite:15]{index=15}.</p>"},{"location":"format_specifications/vcf/#table-1-reserved-info-keys-excerpt","title":"Table\u202f1: Reserved INFO keys (excerpt)","text":"Key Number Type Description AA 1 String Ancestral allele AC A Integer Allele count per ALT allele AF A Float Allele frequency per ALT allele AN 1 Integer Total number of alleles called DP 1 Integer Combined depth across samples MQ 1 Float RMS mapping quality ... ... ... ..."},{"location":"format_specifications/vcf/#table-2-reserved-formatgenotype-keys-excerpt","title":"Table\u202f2: Reserved FORMAT/Genotype keys (excerpt)","text":"Field Number Type Description GT 1 String Genotype (0=REF, 1...=ALTs; phasing <code>/</code> or <code>|</code>) GQ 1 Integer Conditional genotype quality DP 1 Integer Read depth AD R Integer Read depth per allele PL G Integer Phred\u2010scaled genotype likelihoods ... ... ... ... <p>For full lists and detailed definitions, see Sections\u00a03\u20135 and Tables\u00a01\u20132 in the spec.</p>"},{"location":"format_specifications/vcf/#2-understanding-the-vcf-format-and-the-haplotype-representation","title":"2 Understanding the VCF format and the haplotype representation","text":"<p>VCF records use a simple haplotype representation to describe variant alleles at a locus.  A VCF record holds all segregating alleles\u2014both reference and alternate\u2014as well as, optionally, genotypes for multiple individuals at that locus.  ALT haplotypes are constructed from the REF haplotype by replacing the reference bases at POS with the alternate bases.  In essence, the VCF record specifies a-REF-t and the alternative haplotypes are a-ALT-t for each ALT allele. </p>"},{"location":"format_specifications/vcf/#21-vcf-tag-naming-conventions","title":"2.1\u202fVCF tag naming conventions","text":"<p>Implementation\u2011defined tags should follow these suffix/prefix conventions: </p> <ul> <li><code>L</code> suffix \u2014 log\u2081\u2080\u2010likelihood (e.g., <code>GL</code>, <code>CNL</code>): log\u2081\u2080\u202fPr(Data|Model), negative numbers.</li> <li><code>P</code> suffix \u2014 linear\u2010scale posterior probability (e.g., <code>GP</code>, <code>CNP</code>): Pr(Model|Data).</li> <li><code>Q</code> suffix \u2014 phred\u2010scaled quality: \u221210\u202flog\u2081\u2080\u202fPr(Data|Model) (e.g., <code>GQ</code>, <code>CNQ</code>); the fixed site\u2010level QUAL field uses the same scale.</li> <li><code>L</code> prefix \u2014 \u201clocal\u2010allele\u201d equivalent of a Number=A, R, or G field (see\u00a01.6.2).</li> </ul>"},{"location":"format_specifications/vcf/#3-info-keys-used-for-structural-variants","title":"3\u202fINFO keys used for structural variants","text":"<p>The following INFO keys are reserved for encoding structural variants.  Values for imprecise variants should be best estimates.  When per\u2011allele values are required, they must be provided for all ALT alleles (including non\u2011structural alleles), using the missing\u2010value placeholder (<code>.</code>) where appropriate. </p> <pre><code>##INFO=&lt;ID=IMPRECISE,Number=0,Type=Flag,Description=\"Imprecise structural variation\"&gt;\n##INFO=&lt;ID=NOVEL,Number=0,Type=Flag,Description=\"Indicates a novel structural variation\"&gt;\n##INFO=&lt;ID=END,Number=1,Type=Integer,Description=\"Deprecated. Present for backwards compatibility\"&gt;\n##INFO=&lt;ID=SVTYPE,Number=1,Type=String,Description=\"Type of structural variant\"&gt;\n##INFO=&lt;ID=SVLEN,Number=A,Type=Integer,Description=\"Length of structural variant\"&gt;\n##INFO=&lt;ID=CIPOS,Number=.,Type=Integer,Description=\"Confidence interval around POS\"&gt;\n</code></pre> <ul> <li>IMPRECISE (Flag): marks an imprecise structural\u2010variant ALT.  If a record is marked IMPRECISE, <code>CIPOS</code> (or <code>CIEND</code>) must be present (even if <code>0,0</code>).</li> <li>NOVEL (Flag): indicates a novel structural variant.</li> <li>END (Integer): deprecated in favor of <code>SVLEN</code> (and <code>LEN</code> in FORMAT).</li> <li>SVTYPE (String): deprecated (redundant with symbolic <code>ALT</code> alleles); see\u00a01.4.5 for valid ALT symbols (e.g., <code>&lt;DEL&gt;</code>, <code>&lt;DUP&gt;</code>, <code>&lt;INV&gt;</code>).</li> <li>SVLEN (Integer, one per ALT): variant length.  For <code>&lt;DEL&gt;</code>, <code>&lt;INS&gt;</code>, <code>&lt;DUP&gt;</code>, <code>&lt;INV&gt;</code> alleles, the number of bases deleted/inserted/etc.; for <code>&lt;CNV&gt;</code>, the segment length.  Use <code>.</code> for other ALT alleles.</li> <li>CIPOS (Integer list): confidence interval around POS; twice as many entries as ALT alleles, giving start/end offsets for each.</li> </ul>"},{"location":"format_specifications/vcf/#4-format-keys-used-for-structural-variants","title":"4\u202fFORMAT keys used for structural variants","text":"<p>Reserved per\u2011sample FORMAT keys for structural variants include (among others): </p> <pre><code>##FORMAT=&lt;ID=CN,Number=1,Type=Float,Description=\"Copy number\"&gt;\n##FORMAT=&lt;ID=PSL,Number=.,Type=Integer,Description=\"Phase set list for structural variants\"&gt;\n##FORMAT=&lt;ID=PSO,Number=.,Type=Integer,Description=\"Phase set offsets\"&gt;\n</code></pre> <ul> <li>CN (Float): estimated per\u2011sample copy number.</li> <li>PSL/PSO (Integer lists): phase sets and offsets, used to indicate phasing of SNVs with structural events (see\u00a02.1).</li> </ul>"},{"location":"format_specifications/vcf/#5-representing-variation-in-vcf-records","title":"5\u202fRepresenting variation in VCF records","text":""},{"location":"format_specifications/vcf/#51-creating-vcf-entries-for-snps-and-small-indels","title":"5.1\u202fCreating VCF entries for SNPs and small indels","text":"<p>VCF entries for simple variants are constructed by aligning REF and ALT haplotypes:</p>"},{"location":"format_specifications/vcf/#511-example-1","title":"5.1.1\u202fExample\u00a01","text":"<p>Single\u00a0SNP at position 100:</p> <pre><code>chr1 100 . A G 50 PASS . GT 0/1\n</code></pre>"},{"location":"format_specifications/vcf/#512-example-2","title":"5.1.2\u202fExample\u00a02","text":"<p>Two\u2010base insertion at position\u00a0200:</p> <pre><code>chr1 200 . AT ATG 60 PASS . GT 1|0\n</code></pre>"},{"location":"format_specifications/vcf/#513-example-3","title":"5.1.3\u202fExample\u00a03","text":"<p>Two\u2010base deletion at position\u00a0300:</p> <pre><code>chr1 300 . AT A 70 PASS . GT 0/1\n</code></pre>"},{"location":"format_specifications/vcf/#52-decoding-vcf-entries-for-snps-and-small-indels","title":"5.2\u202fDecoding VCF entries for SNPs and small indels","text":"<p>Given a REF/ALT and genotype, one reconstructs the haplotypes:</p> <ul> <li>5.2.1\u00a0SNP \u2014 replace the single base at POS.</li> <li>5.2.2\u00a0Insertion \u2014 pad REF to first base, ALT contains inserted bases.</li> <li>5.2.3\u00a0Deletion \u2014 REF longer than ALT; ALT is the deleted\u2010bases string.</li> <li>5.2.4\u00a0Mixed (microsatellite) \u2014 multiple ALT alleles of varying lengths.</li> </ul>"},{"location":"format_specifications/vcf/#53-encoding-structural-variants","title":"5.3\u202fEncoding Structural Variants","text":"<p>Symbolic alleles (e.g., <code>&lt;DEL&gt;</code>, <code>&lt;INS&gt;</code>, <code>&lt;DUP&gt;</code>) are used in ALT, with companion INFO/FORMAT fields (<code>SVTYPE</code>, <code>SVLEN</code>, <code>CIPOS</code>, <code>CN</code>, etc.) to capture imprecision, length, confidence intervals, copy\u2010number, and phasing information.</p>"},{"location":"format_specifications/vcf/#54-specifying-complex-rearrangements-with-breakends","title":"5.4\u202fSpecifying complex rearrangements with breakends","text":"<p>Breakend notation allows representation of arbitrary rearrangements:</p> <ul> <li>5.4.1\u202fInserted Sequence \u2014 specify sequence within <code>[]</code> brackets.</li> <li>5.4.2\u202fLarge Insertions \u2014 use symbolic <code>&lt;INS&gt;</code> + <code>SVLEN</code>.</li> <li>5.4.3\u202fMultiple mates \u2014 list multiple breakend records for multi\u2010way events.</li> <li>5.4.4\u202fExplicit partners \u2014 include partner chromosome/position within the ALT string.</li> <li>5.4.5\u202fTelomeres \u2014 use <code>&lt;T&gt;</code> symbolic allele for telomeric breakends.</li> <li>5.4.6\u202fEvent modifiers \u2014 flags like <code>IMPRECISE</code>, <code>NOVEL</code>.</li> <li>5.4.7\u202fInversions \u2014 <code>&lt;INV&gt;</code> with <code>SVLEN</code>.</li> <li>5.4.8\u202fUncertainty around breakend location \u2014 use <code>CIPOS</code> and <code>CIEND</code>.</li> <li>5.4.9\u202fSingle breakends \u2014 breakend with no defined partner.</li> </ul> <p>For full details and all sub\u2011cases (e.g. nested inversions, sample mixtures), see Sections\u00a05.4.1\u20135.4.9 in the spec. </p>"},{"location":"format_specifications/vcf_design/","title":"VCF Reader Implementation Design","text":"<p>Based on the VCF format specification, this document outlines the implementation for a Python library to handle VCF files with lazy parsing techniques. The implementation will use zero-based indexing and half-open intervals as required.</p>"},{"location":"format_specifications/vcf_design/#core-classes","title":"Core Classes","text":""},{"location":"format_specifications/vcf_design/#1-vcfreader","title":"1. <code>VcfReader</code>","text":"<p>The main class responsible for reading and parsing VCF files.</p> <ul> <li>Responsibilities:</li> <li>Open and read VCF files</li> <li>Parse header information</li> <li>Iterate through records</li> <li>Provide access to metadata</li> <li> <p>Support indexing for random access</p> </li> <li> <p>Key methods:</p> </li> <li><code>__init__(file_path)</code>: Initialize with file path</li> <li><code>parse_header()</code>: Parse header lines</li> <li><code>__iter__()</code>: Iterate through records</li> <li><code>fetch(chrom, start, end)</code>: Get records in a region (requires indexing)</li> </ul>"},{"location":"format_specifications/vcf_design/#2-vcfheader","title":"2. <code>VcfHeader</code>","text":"<p>Represents the VCF file header.</p> <ul> <li>Responsibilities:</li> <li>Store meta-information lines</li> <li>Parse and provide access to metadata (contigs, INFO fields, FORMAT fields, etc.)</li> <li> <p>Validate record fields against header definitions</p> </li> <li> <p>Key methods:</p> </li> <li><code>get_info_field_definition(id)</code>: Get definition for an INFO field</li> <li><code>get_format_field_definition(id)</code>: Get definition for a FORMAT field</li> <li><code>get_contigs()</code>: Get list of contigs</li> </ul>"},{"location":"format_specifications/vcf_design/#3-vcfrecord","title":"3. <code>VcfRecord</code>","text":"<p>Represents a single VCF record with lazy parsing.</p> <ul> <li>Responsibilities:</li> <li>Store raw record data</li> <li>Provide access to fixed fields (CHROM, POS, etc.)</li> <li>Lazily parse INFO and FORMAT fields only when requested</li> <li> <p>Convert between 1-based VCF positions and 0-based internal positions</p> </li> <li> <p>Key methods:</p> </li> <li><code>get_chrom()</code>, <code>get_pos()</code>, etc.: Access fixed fields</li> <li><code>get_info(field_id)</code>: Lazily parse and return specific INFO field</li> <li><code>get_format(field_id, sample_idx)</code>: Lazily parse and return FORMAT field for a sample</li> <li><code>get_genotypes()</code>: Lazily parse and return genotype data</li> </ul>"},{"location":"format_specifications/vcf_design/#4-infofield","title":"4. <code>InfoField</code>","text":"<p>Represents an INFO field with type-specific parsing.</p> <ul> <li>Responsibilities:</li> <li>Parse INFO field values according to their type</li> <li> <p>Convert between string representation and Python types</p> </li> <li> <p>Key methods:</p> </li> <li><code>parse(value, field_type, number)</code>: Parse value according to type and number</li> </ul>"},{"location":"format_specifications/vcf_design/#5-formatfield","title":"5. <code>FormatField</code>","text":"<p>Represents a FORMAT field with type-specific parsing.</p> <ul> <li>Responsibilities:</li> <li>Parse FORMAT field values according to their type</li> <li> <p>Handle per-sample data</p> </li> <li> <p>Key methods:</p> </li> <li><code>parse(values, field_type, number)</code>: Parse values according to type and number</li> </ul>"},{"location":"format_specifications/vcf_design/#6-variantfactory","title":"6. <code>VariantFactory</code>","text":"<p>Factory class for creating Variant objects from VCF records.</p> <ul> <li>Responsibilities:</li> <li>Determine variant types (SNP, insertion, deletion, etc.)</li> <li>Create appropriate Variant objects from VCF record data</li> <li> <p>Handle complex variant type detection logic</p> </li> <li> <p>Key methods:</p> </li> <li><code>is_snp()</code>, <code>is_indel()</code>, <code>is_structural_variant()</code>: Static variant type detection methods</li> <li><code>get_variant_type()</code>: Determine the VariantType enum for a variant</li> <li><code>create_variants_from_record()</code>: Create Variant objects from a VcfRecord</li> </ul>"},{"location":"format_specifications/vcf_design/#7-vcfvariant","title":"7. <code>VcfVariant</code>","text":"<p>Higher-level representation of a variant.</p> <ul> <li>Responsibilities:</li> <li>Provide a more user-friendly interface to variant data</li> <li>Convert between VCF coordinates (1-based) and internal coordinates (0-based)</li> <li> <p>Represent structural variants, SNPs, indels, etc.</p> </li> <li> <p>Key methods:</p> </li> <li><code>get_alleles()</code>: Get reference and alternate alleles</li> <li><code>get_genotypes()</code>: Get genotypes for all samples</li> </ul>"},{"location":"format_specifications/vcf_design/#8-vcfindex","title":"8. <code>VcfIndex</code>","text":"<p>Provides indexing for random access to VCF files.</p> <ul> <li>Responsibilities:</li> <li>Build or load index for VCF file</li> <li> <p>Support querying by genomic region</p> </li> <li> <p>Key methods:</p> </li> <li><code>build_index()</code>: Create index for VCF file</li> <li><code>query(chrom, start, end)</code>: Get file positions for records in region</li> </ul>"},{"location":"format_specifications/vcf_design/#lazy-parsing-implementation","title":"Lazy Parsing Implementation","text":"<p>The key to efficient VCF parsing is to avoid parsing fields that aren't needed. Here's how lazy parsing will be implemented:</p> <ol> <li>Record Level Laziness:</li> <li>When iterating through a VCF file, only parse the fixed fields (CHROM, POS, etc.)</li> <li>Store the raw string for INFO and FORMAT fields</li> <li> <p>Only parse these fields when explicitly requested</p> </li> <li> <p>INFO Field Laziness:</p> </li> <li>Store the raw INFO string in the VcfRecord</li> <li>When <code>get_info(field_id)</code> is called, parse only that specific field</li> <li> <p>Cache parsed results to avoid re-parsing</p> </li> <li> <p>FORMAT Field Laziness:</p> </li> <li>Store the raw FORMAT string and sample data in the VcfRecord</li> <li>When <code>get_format(field_id, sample_idx)</code> is called, parse only that specific field for that sample</li> <li> <p>Cache parsed results to avoid re-parsing</p> </li> <li> <p>Genotype Laziness:</p> </li> <li>Only parse genotype data (GT field) when explicitly requested</li> <li>Cache parsed genotypes</li> </ol>"},{"location":"format_specifications/vcf_design/#example-usage","title":"Example Usage","text":"<pre><code># Open a VCF file\nvcf_reader = VcfReader(\"example.vcf.gz\")\n\n# Iterate through records\nfor record in vcf_reader:\n    # Access fixed fields (parsed immediately)\n    chrom = record.get_chrom()\n    pos = record.get_pos()  # 0-based position\n\n    # Lazy parsing of INFO fields - only parses AF when requested\n    if record.has_info(\"AF\"):\n        allele_freq = record.get_info(\"AF\")\n\n    # Lazy parsing of genotypes - only parses when requested\n    genotypes = record.get_genotypes()\n\n    # Lazy parsing of FORMAT fields - only parses DP for sample 0 when requested\n    if record.has_format(\"DP\"):\n        depth = record.get_format(\"DP\", 0)\n</code></pre>"},{"location":"format_specifications/vcf_design/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>File Reading:</li> <li>Support both plain text and gzipped VCF files</li> <li> <p>Use buffered reading for better performance</p> </li> <li> <p>Memory Management:</p> </li> <li>Avoid loading the entire file into memory</li> <li>Use generators for iteration</li> <li> <p>Implement record caching for frequently accessed records</p> </li> <li> <p>Parsing Efficiency:</p> </li> <li>Use specialized parsers for different field types</li> <li>Cache parsed results to avoid re-parsing</li> <li> <p>Use string splitting and regular expressions efficiently</p> </li> <li> <p>Indexing:</p> </li> <li>Support tabix indexing for compressed VCF files</li> <li>Implement simple indexing for uncompressed files</li> </ol> <p>This design provides a flexible and efficient framework for working with VCF files, with lazy parsing to minimize unnecessary computation and memory usage.</p>"}]}